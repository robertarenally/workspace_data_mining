data,target
"b'Semantic scene classification, automatically categorizing images\ninto a discrete set of classes such as beach, sunset, or field,\nis a difficult problem. Current classifiers rely on low-level image\nfeatures, such as color, texture, or edges, and achieve limited success\non constrained image sets. However, the domain of unconstrained consumer\nphotographs requires the use of new features and techniques.\n \nOne source of information that can help classification is the\ncontext associated with the image. We have explored three types\nof context. First, spatial context enables the use of scene\nconfigurations (identities of regions and the spatial relationships\nbetween the regions) for classification purposes. Second,\ntemporal context allows us to use information contained in\nneighboring images to classify an image. We exploit elapsed time\nbetween images to help determine which neighboring images are most\nclosely related. Third, image capture condition context in the form of\ncamera parameters (e.g., flash, exposure time, and subject distance)\nrecorded at the time the photo was taken provides cues that are\neffective at distinguishing certain scene types.\n \nWe developed and used graphical models to incorporate image content\nwith these three types of context. These systems are highly modular\nand allow for probabilistic input, output, and inference based on\nthe statistics of large image collections. We demonstrate the\neffectiveness of each context model on several classification problems.'",1
"b""Using results from the field of robust statistics, we derive a class of\nKalman filters that are robust to structured and unstructured noise in the\ninput data stream. Each filter from this class maintains robust optimal\nestimates of the input process's hidden state by allowing the measurement\ncovariance matrix to be a non-linear function of the prediction errors.\nThis endows the filter with the ability to reject outliers in the input\nstream. Simultaneously, the filter also learns an internal model of input\ndynamics by adapting its measurement and state transition matrices using\ntwo additional Kalman filter-based adaptation rules. We present experimental\nresults demonstrating the efficacy of such filters in mediating\nappearance-based segmentation and recognition of objects and image sequences\nin the presence of varying degrees of occlusion, clutter, and noise.""",1
"b'We address the problem of domain-dependence in semantic role labeling\nsystems by attempting to bootstrap from unlabeled data in new domains.\nWe explore a variety of methods for bootstrapping, and compare two\nmachine learning techniques, decision lists and maximum entropy.'",0
"b""A selective vision system sequentially collects evidence\nto support a specified hypothesis about a scene,\nas long as the additional evidence is worth the effort of obtaining it.\nEfficiency comes from processing the scene only where necessary,\nto the level of detail necessary, and with only the necessary operators.\nKnowledge representation and sequential decision-making\nare central issues for selective vision, which takes advantage of\nprior knowledge of a domain's abstract and geometrical structure\nand models for the expected performance and cost of visual operators.\n\nThe TEA-1 selective vision system uses Bayes nets for representation\nand benefit-cost analysis for control of visual and non-visual actions.\nIt is the high-level control for an active vision system,\nenabling purposive behavior, the use of qualitative vision modules\nand a pointable multiresolution sensor. TEA-1 demonstrates that\nBayes nets and decision theoretic techniques provide a general,\nre-usable framework for constructing computer vision systems\nthat are selective perception systems, and that Bayes nets provide\na general framework for representing visual tasks.\nControl, or decision making, is the most important issue in a selective\nvision system. TEA-1's decisions about what to do next are based on\ngeneral hand-crafted ``goodness functions'' constructed around core\ndecision theoretic elements. Several goodness functions\nfor different decisions are presented and evaluated.\n\nThe TEA-1 system solves a version of the T-world problem,\nan abstraction of a large set of domains and tasks.\nSome key factors that affect the success of selective perception\nare analyzed by examining how each factor affects\nthe overall performance of TEA-1 when solving ensembles of\nrandomly produced, simulated T-world domains and tasks.\nTEA-1's decision making algorithms are also evaluated in this manner.\nExperiments in the lab for one specific T-world domain,\ntable settings, are also presented.""",1
"b""Bloom filters are compact set representations that \nsupport set membership queries with small, one-sided error \nprobabilities.  Standard Bloom filters are oblivious to \nobject popularity in sets and membership queries.  However,\nsets and queries in many distributed applications follow \nknown, stable, highly skewed distributions (e.g., \nZipf-like).  This paper studies the problem of minimizing \nthe false-positive probability of a Bloom filter by \nadapting the number of hashes used for each data object to \nits popularity in sets and membership queries.  We model\nthe problem as a constrained nonlinear integer program and \npropose two polynomial-time solutions with bounded \napproximation ratios --- one is a 2-approximation algorithm \nwith O(N^c) running time (c&gt;=6 in practice); the other is a \n(2+e)-approximation algorithm with running time O(N^2/e), \ne&gt;0.  Here N denotes the total number of distinct data \nobjects that appear in sets or queries.  We quantitatively \nevaluate our proposed approach on two distributed\napplications (cooperative caching and full-text keyword \nsearching) driven by real-life data traces.  Compared to \nstandard Bloom filters, our data popularity-conscious Bloom \nfilters achieve up to 24 and 27 times false-positive \nprobability reduction for the two applications respectively.\nThe quantitative evaluation also validates our solution's \nbounded approximation ratio to the optimal.""",2
"b'We have modified the public-domain Quake II game to support research\nand teaching. Our research is in multi-agent control and supporting\nhuman-computer interfaces. Teaching applications have so far been in an\nundergraduate Artificial Intelligence class and include natural language\nunderstanding, machine learning, computer vision, and production system\ncontrol. The motivation for this report is mainly to document our system\ndevelopment and interface. Only early results are in, but they appear\npromising. Our source code and user-level documentation is available on\nthe web. The information document is a somewhat motion-blurred snapshot\nof the situation in September 2004.'",1
"b'The safety of speculative parallelization depends on monitoring all\nprogram access to shared data.  Automatic solutions use either\nprogram instrumentation, which can be costly, or hardware-based\ntriggering,  which incurs false sharing.  In addition, not all access requires\nmonitoring. It is worth considering a manual approach in which\nprogrammers  insert access annotations to reduce the cost and increase the\nprecision of program monitoring.\n\nThis report first presents an execution model and its interface for\naccess annotation.  The semantics of an annotated program is defined \nby the output of a (sequential) canonical execution.  The report\nthen describes a quadratic-time checker that can verify the safety of\nannotations, that is, whether a speculative execution always produces\nthe canonical output.  The report demonstrates the usability of the\nannotation interface by safely parallelizing a number of code\nfragments that have uncertain parallelism.'",2
"b""In robot skill learning the robot must obtain data for training by\nexecuting expensive practice trials and recording their results.  The thesis\nis that the high cost of acquiring training data is the limiting factor\nin the performance of skill learners.  Since the data is obtained from\npractice trials, it is important that the system make intelligent\nchoices about what actions to attempt while practicing. \nIn this dissertation we present several algorithms\nfor intelligent experimentation in skill learning.\n\nIn open-loop skills the execution goal is presented and the controller\nmust then choose all the control signals for the duration of the task.\nLearning is a high-dimensional search problem.  The system must associate\na sequence of actions with each commandable goal. We propose an algorithm\nthat selects practice actions most likely to improve performance by\nmaking use of information gained on previous trials. On the problem of\nlearning to throw a ball using a robot with a flexible link, the algorithm\ntakes only 100 trials to find a ``whipping'' motion for long throws.\n\nMost closed loop learners improve their performance by gradient descent on\na cost function.  The main drawback of this method is convergence to\nnon-optimal local minima.  We introduce the concept of cooperation as a\nmeans of escaping these local minima. We assume the existence of several\ncoaches that each improve some aspect of the controller's performance.\nSwitching training between coaches can help the controller avoid locally\nminimal solutions. On the task of curve tracing with an inverted pendulum the\ncooperative algorithm learns to track faster than with a traditional method.\n\nIn an integrated system with scarce sensor resources it is preferable to\nperform tasks without sensing.  We observe that closed loop learning\ncan function as an efficient search technique for open-loop control. \nOur system starts with closed loop learning.  As it improves its ability\nto control the plant, it replaces sensor information with estimates. \nThe result is a controller that tracks long segments of a\nreference curve open loop.""",1
"b'State of the art plan recognition for use in natural language dialogue\nsystems has progressed in coverage of discourse phenomena and plan\nnavigation strategies. Most systems, however, suffer from several\ndeficiencies, namely, they do not have a specific strategy for the\n(inevitable) case where they make an incorrect hypothesis inference\nand they cannot handle interleaved plan navigation, where a user jumps\nback and forth between several plans.  In addition, most plan recognition\nsystems cannot handle the rich variety of possible natural language\nutterances a dialogue system may receive as input, especially the case\nwhere a language utterance corresponds to several actions that the system\nconsiders to be atomic.  We discuss previous work in plan recognition,\nespecially in the area of dialogues systems.  We then describe a plan\nrecognition system that can recover from incorrect inferences, handles\ninterleaved plan navigation, and handles several linguistic phenomena,\nincluding support for natural language multi-action paraphrase.'",0
"b'Proceedings of a workshop held in conjunction with the 12th International\nInternational Conference on Machine Learning in July 1995 in Tahoe City, CA.'",0
"b""There has been considerable recent interest in the support of\ntransactional memory (TM) in both hardware and software. We present\nan intermediate approach, in which hardware is used to accelerate\na TM implementation controlled fundamentally by software. Our hardware\nsupport reduces the overhead of common TM tasks, namely, conflict\ndetection and data isolation, for bounded transactions. Software\ncontrol allows policy flexibility for conflict detection,\ncontention management, and data granularity, in addition to\nenabling transactions unbounded in space and time. Our hardware\nconsists of 1) an alert-on-update mechanism for fast event-based\ncommunication, used for software-controlled conflict detection;\nand 2) support for programmable data isolation, allowing multiple\nconcurrent transactional readers and writers at the software's\nbehest, along with fast data commit and abort support (using only\na few cycles of completely local operation).\n\nOur results show that for common-case bounded transactions,\nthe proposed hardware mechanisms eliminate data copying and\ndramatically reduce the overhead of bookkeeping and validation\n(resulting in a factor of 2 improvement in performance on average).\nMoreover, RTM shows good scalability as the number of threads is\nincreased and graceful degradation in performance when transactions\noverflow available hardware support. Detecting conflicts eagerly\n(on first access) or lazily (at commit time), enabled by the ability\nto handle multiple concurrent transactional writers and readers,\ncan result in differences in performance in either direction\ndepending on the application access pattern (up to two orders\nof magnitude at 16 threads for one workload), demonstrating\nthe need for policy flexibility.""",2
"b'This paper describes the performance evaluation of six temporal reasoning\nsystems. We show that if you are working with large temporal datasets\nwhere information is added incrementally throughout the execution\nof the program, systems using incompletely connected graphs (i.e., TMM,\nTimeGraph and TimeGraph-II) seem the best option.\nWhile they do not offer the constant query time of systems using\nfully connected graphs (i.e., the systems based on constraint satisfaction),\nthe savings at assertion time are so substantial that the relatively small\nperformance penalty for queries is a reasonable tradeoff.\nOf course, these systems do not offer the expressivity of the\ninterval-based systems as they only handle point-based relations.\nOf the three, TimeGraph-II offers a wider range of qualitative relations\nas it handles point inequality. It does not currently handle metric\ninformation, however, as do TMM and TimeGraph. Thus decisions\nbetween these three may be more determined by the reasoning capabilities\nrequired rather than raw performance.'",0
"b'We describe implementation details of an activity detection system\nwhose function is to detect small image regions (pixels) that are\ninconsistent with a learned and adaptive background model. The system \nis based on a classic multiple Gaussian model approach, but contains\nadditional model elements to deal with phenomena characteristic of\noutdoor environment such as wind-blown foliage and moving cloud \nshadows.'",1
"b""We argue for transactions as the synchronization primitive of an\nordering-based memory consistency model.  Rather than define\ntransactions in terms of locks, our model defines locks, conditions,\nand atomic/volatile variables in terms of transactions.  A\ntraditional critical section, in particular, is a region of code,\nbracketed by transactions, in which certain data have been\nprivatized.  Our memory model, originally published at OPODIS'08, is\nbased on the database notion of strict serializability (SS). In an\nexplicit analogy to the DRF0 of Adve and Hill, we demonstrated that\nSS provides the appearance of transactional sequential consistency\n(TSC) for programs that are transactional data-race free (TDRF).\nWe argue against relaxation of the total order on transactions, but\nshow that selective relaxation of the relationship between program\norder and transaction order (selective strict serializability - SSS)\ncan allow the implementation of transaction-based locks to be as\nefficient as conventional locks.  We also show that condition\nsynchronoication (in the form of the transaction retry primitive) can\nbe accommodated in our model without explicit mention of speculation,\nopacity, or aborted transactions.  Finally, we compare SS and SSS to\nthe notion of strong isolation (SI), arguing the SI is neither\nsufficient for TSC nor necessary in programs that are TDRF.""",2
"b'This paper presents a computational model of how conversational \nparticipants collaborate in order to make a referring action successful.\nThe model is based on the view of language as goal-directed behavior.\nWe propose that the content of a referring expression can be accounted for\nby the planning paradigm. Not only does this approach allow the processes\nof building referring expressions and identifying their referents to be\ncaptured by plan construction and plan inference, it also allows us\nto account for how participants clarify a referring expression by\nusing meta-actions that reason about and manipulate the plan derivation\nthat corresponds to the referring expression. To account for how\nclarification goals arise and how inferred clarification plans affect \nthe agent, we propose that the agents are in a certain state of mind, and\nthat this state includes an intention to achieve the goal of referring\nand a plan that the agents are currently considering.\nIt is this mental state that sanctions the adoption of goals\nand the acceptance of inferred plans, and so acts as a link between\nunderstanding and generation.'",0
"b'A Personalized System of Instruction (PSI) is a student-paced method\nof teaching in which students progress by displaying mastery of written\nmaterial. Cooperative Learning is a method of instruction in which students\nwork in groups to help each other study. In the Fall of 1996, a computer\nliteracy course in which half of the students followed a PSI curriculum\nand the other half followed a Cooperative Learning curriculum was offered.\nData from this experiment showed several statistically significant\ndifferences between the two curricula in student satisfaction as measured\nby end-of-the-semester course evaluation forms. These questionnaires\nindicated that students felt that the PSI classes increased their knowledge\nat the 99\\% confidence level. They also indicated that students felt that\nthe PSI course procedures better supported course objectives, that the PSI\ncourse required more work, and that it was easier to get answers from the TAs\nin the PSI classes at the 95\\% confidence level. The data also showed\nstatistically significant evidence that students learned more from the PSI\ncurriculum as measured by exams. Analysis of rosters from the programming\nclass offered the following semester showed no statistically significant\ndifference between the proportion of the PSI students who took the\nprogramming class and the proportion of the cooperative learning students\nwho took the programming class.'",0
"b'Unger studied the balanced leaf languages defined via poly-logarithmically sparse leaf pattern sets.  Unger shows that $\\np$-complete sets are not polynomial-time many-one reducible to such balanced leaf language unless the polynomial hierarchy collapses to Theta^p_2 and that Sigam^p_2-complete sets are not polynomial-time bounded-truth-table reducible (respectively, polynomial-time Turing reducible) to any such balanced leaf language unless the polynomial hierarchy collapses to Delta^p_2 (respectively, Sigma^p_4).\n\nThis paper studies the complexity of the class of such balanced leaf languages, which will be denoted by VSLL.  In particular, the following tight upper and lower bounds of VSLL are shown:\n\n1. coNP is included in VSLL and VSLL is included in coNP/poly (the former inclusion is already shown by Unger).\n\n2. coNP/1 is not included in VSLL unless PH collapses to Theta^p_2.\n\n3.  For no constant c&gt;0, VSLL is included coNP/n^c.\n\n4.  P/(loglog(n) + O(1)) is included in VSLL.\n\n5.  For no h(n) = loglog(n) + omega(1), P/h is included in VSLL.'",3
"b'A characteristic feature of the mammalian visual cortex is the reciprocity\nof connections between cortical areas. While corticocortical feedforward\nconnections have been well studied, the computational function of the\ncorresponding feedback projections has remained relatively unclear.\nWe have modelled the visual cortex as a hierarchical predictor wherein\nfeedback projections carry predictions for lower areas and\nfeedforward projections carry the difference between the predictions\nand the actual internal state. The activities of model neurons and their\nsynaptic strength are continually adapted using a hierarchical Kalman filter\nthat minimizes errors in prediction. The model generalizes several\npreviously proposed encoding schemes and allows functional interpretations\nof a number of well-known psychophysical and neurophysiological phenomena.\nHere, we present simulation results suggesting that the classical phenomenon\nof endstopping in cortical neurons may be viewed as an emergent property\nof the cortex implementing a hierarchical Kalman filter-like prediction\nmechanism for efficient encoding and recognition.'",0
"b""A Polhemus 3Space Isotrak sensor system is used on the\nVPL Research DataGlove Model 2 to detect the glove's absolute\nposition and orientation. The sensor system has two components:\nthe Polhemus sensor and the Polhemus source.\nThe sensor is attached to the back of the DataGlove.\nThe sensor sends to the DataGlove Control Unit analog signals,\nwhich are converted into the Polhemus data--six parameters that\nrepresent the position and orientation of the sensor\nrelative to the source. This document describes how\nthe Polhemus devices work and how the Polhemus data should be interpreted.\nIt also describes the transformation of the Polhemus output\ninto the (X, Y, Z, O, A, T) space of the robot in the\nUniversity of Rochester Robotics Laboratory.\nThis transformation allows teleoperation of the robot\nthrough the use of the Polhemus devices.""",1
"b""Control and bribery are settings in which an external agent seeks\nto influence the outcome of an election.  Constructive control of\nelections refers to attempts by an agent to, via such actions as\naddition/deletion/partition of candidates or voters, ensure that a\ngiven candidate wins [BTT92].  Destructive control refers to attempts\nby an agent to, via the same actions, preclude a given candidate's\nvictory [HHR07a].  An election system in which an agent can sometimes\naffect the result and it can be determined in polynomial time on which\ninputs the agent can succeed is said to be vulnerable to the given\ntype of control.  An election system in which an agent can sometimes\naffect the result, yet in which it is NP-hard to recognize the inputs\non which the agent can succeed, is said to be resistant to the given\ntype of control.\n\nAside from election systems with an NP-hard winner problem, the only\nsystems previously known to be resistant to all the standard control\ntypes were highly artificial election systems created by hybridization\n[HHR07b].  This paper studies a parameterized version of Copeland\nvoting, denoted by Copeland^\\alpha, where the parameter \\alpha is a\nrational number between 0 and 1 that specifies how ties are valued in\nthe pairwise comparisons of candidates.  In every previously studied\nconstructive or destructive control scenario, we determine which of\nresistance or vulnerability holds for Copeland^\\alpha for each\nrational \\alpha, 0 \\leq \\alpha \\leq 1.  In particular, we prove that\nCopeland^{0.5}, the system commonly referred to as ``Copeland\nvoting,'' provides full resistance to constructive control, and we\nprove the same for Copeland^\\alpha, for all rational \\alpha, 0 &lt;\n\\alpha &lt; 1.  Among systems with a polynomial-time winner problem,\nCopeland voting is the first natural election system proven to have\nfull resistance to constructive control.  In addition, we prove that\nboth Copeland^0 and Copeland^1 (interestingly, Copeland^1 is an\nelection system developed by the thirteenth-century mystic Ramon\nLlull) are resistant to all standard types of constructive control\nother than one variant of addition of candidates.  Moreover, we show\nthat for each rational \\alpha, 0 \\leq \\alpha \\leq 1, Copeland^\\alpha\nvoting is fully resistant to bribery attacks, and we establish\nfixed-parameter tractability of bounded-case control for\nCopeland^\\alpha.\n\nWe also study Copeland^\\alpha elections under more flexible models\nsuch as microbribery and extended control, we integrate the potential\nirrationality of voter preferences into many of our results, and we\nprove our results in both the unique-winner model and the\nnonunique-winner model.  Our vulnerability results for microbribery\nare proven via a novel technique involving min-cost network flow.""",3
"b""David Lowe's influential and classic algorithm for tracking objects\nwith known geometry is formulated with certain simplifying assumptions. A\nversion implemented by Ishii et al. makes different simplifying assumptions.\nWe formulate a full projective solution and apply the same algorithm (Newton's\nmethod). We report results of extensive testing of these three algorithms.\nWe compute two image--space and six pose--space error metrics to quantify the\neffects of object pose, errors in initial solutions, and image noise levels.\nWe consider several scenaria, from relatively unconstrained conditions to\nthose that mirror real--world and real--time constraints. The conclusion is\nthat the full projective formulation makes the algorithm orders of magnitude\nmore accurate and gives it super--exponential convergence properties with\narguably better computation--time properties.""",1
"b'Recent neurophysiological experiments appear to indicate that the\nresponses of visual cortical neurons in a monkey freely viewing a\nnatural scene can sometimes differ substantially from those obtained when\nthe same image subregions are flashed during a conventional fixation task.\nThese new findings attain significance from the fact that\nneurophysiological research in the past has been based predominantly\non cell recordings obtained during fixation tasks, under the\nassumption that these data would be useful in predicting responses\nin more general situations. We describe a hierarchical model of\nvisual memory that reconciles the two differing experimental results\nmentioned above by predicting neural responses in both\nfixating and free-viewing conditions.\nThe model dynamically combines input-driven bottom-up\nsignals with expectation-driven top-down signals to achieve optimal\nestimation of current state using a Kalman filter based framework.\nThe architecture of the model posits a role for the reciprocal\nconnections between adjoining visual cortical areas\nin determining neural response properties.'",0
"b""Temporal projection is a crucial task in planning.\nIn order to achieve its goals, the planner must be able to reason about\nthe consequences of its actions.  In the real world, the planner does\nnot have complete information about the environment or even the\nconsequences of its actions.\nThe planner thus must be able to reason about the probabilistic nature of\nthe world and the probabilistic effects of its action.\n\nInteractions between actions and events in the world are not only\nprobabilistic; they also are temporally complex.  Simultaneous events\ncan interact in many different ways depending on their temporal\nproperties.  An action's temporal relation to its preconditions and\neffects can also become quite complex.\n\nExisting projection systems are weak in their representations of\ntemporally complex actions and events in a probabilistic world.\nThose that can handle probabilistic situations have a limited\nrepresentation of temporal relations, while those that can handle\ncomplex temporal relations generally assume the world to be completely\ndeterministic.  Moreover, the speed of existing probabilistic projection\nsystems are low.  These systems are impractical to scale up to larger\nproblems. In this thesis, we propose a practical projection system that can\nhandle both the probabilistic nature of the world and the temporally complex\nnature of actions. The projection is based on simulation methods.\nProjection is done by simulating possible courses of events, one at a time.\nThe simulation traces are then collected and processed by a projection\nmodule front-end, which provides the planner and the execution monitor\nwith probabilistic estimates of propositions' values. \nThe representation allowed by the system is rich in both the temporal\nand the probabilistic aspects.""",0
"b'Augmented Reality (AR) systems insert graphics objects into the images\nof real scenes. Geometric and photometric consistency has to be achieved\nto make AR systems effective and bring photorealism to the augmented\ngraphics. Particularly, global illumination effects between the\ngraphics objects and scene objects need to be simulated. This thesis\ninvestigates ways to improve AR rendering by creating cast shadows\nbetween the real and graphics objects. This requires knowledge about\nthe scene lighting and the scene structure. We first give novel methods of\nrecovering the light sources from the input images. For indoor scenes,\nwe take advantage of scene regularities such as parallel and orthogonal\nwalls. For outdoor scenes and indoor scenes where the lights can be\napproximated by a directional light source, we show a method of finding\nthe light source from cast shadows present in the real scene.\n\nBesides the light source structure, we also need to know the 3D\nstructure of the scene so that we can render the shadow cast on a\nreal object by a graphics object. Using spheres as primitives,\nwe develop an algorithm to approximate the shape of the scene objects\nfrom multiple silhouettes.\n\nWith all the above components, one can build an AR system that\ninfers necessary information of the scene from shadows and inserts\ngraphics object with convincing shadows. To justify our endeavor\nin terms of shadows being important in human spatial perception, we\ninvestigate shadow perceptions in the context of cue integration.'",1
"b'TEA-1 is a selective vision system that uses Bayes nets\nfor representation and benefit-cost analysis for control of visual\nand nonvisual actions. TEA-1 solves T-world problems, a class of problems\ninvolving static two-dimensional scenes. For example, TEA-1 has been\ndemonstrated to answer questions about scenes of dinner tables.\n\nThis paper presents dTEA-1, an extension to TEA-1 that allows tasks\nto be performed on dynamic scenes. Currently, dTEA-1 successfully\nperforms a task on a simulated train scene.\nThe objects in the scene include a train on a track and a herd of cows,\nbut the domain may be extended to include static objects\nand other classifications of moving objects. The task is to keep track\nof the locations of objects, and the system intelligently allocates\nits effort to keep uncertainty and cost to a minimum.'",1
"b'To describe phenomena that occur at different time scales,\ncomputational models of the brain necessarily must incorporate\ndifferent levels of abstraction.\nWe argue that at time scales of approximately one-third of a second,\norienting movements of the body play a crucial role in cognition and\nform a useful computational level, termed the embodiment level.\nAt this level, the constraints of the body determine the nature of\ncognitive operations, since the natural sequentiality of body movements\ncan be matched to the natural computational economies of sequential\ndecision systems. The way this is done is through a system of implicit\nreference termed deictic, whereby pointing movements are used to bind\nobjects in the world to cognitive programs. We show how deictic bindings\nenable the solution of natural tasks and argue that one of the central\nfeatures of cognition, working memory, can be related to moment-by-moment\ndispositions of body features such as eye movements and hand movements.'",0
"b'Using a combination of techniques from visual representations,\nview synthesis, and visual-motor transfer function estimation, we present\na method for animating movements of an active agent (e.g., robot),\nwithout the use of any prior models or explicit 3d information.\nThe information needed to generate simulated images can be acquired\neither on or off line, by watching the agent doing an arbitrary,\npossibly unrelated task. We present experimental results synthesizing\nimage sequences of the movement of a simulated PUMA 760 robot arm,\nusing both joint space and Cartesian world coordinate control.\nWe have created a user interface, where a user can input a robot movement\nprogram, and then upon execution, view movies of the (simulated) robot\nexecuting the program, along with the instantaneous dynamic variables\nfrom the simulated robot.'",1
"b""Scoring protocols are a broad class of voting systems.  Each is\ndefined by a vector $(\\alpha_1,\\alpha_2,\\ldots,\\alpha_m)$, $\\alpha_1\n\\geq \\alpha_2 \\geq \\cdots \\geq \\alpha_m$, of integers such that each\nvoter contributes $\\alpha_1$ points to his/her first choice,\n$\\alpha_2$ points to his/her second choice, and so on, and any\ncandidate receiving the most points is a winner.\n\nWhat is it about scoring-protocol election systems that makes some\nhave the desirable property of being NP-complete to manipulate, while\nothers can be manipulated in polynomial time?  We find the complete,\ndichotomizing answer: Diversity of dislike.  Every scoring-protocol\nelection system having two or more point values assigned to candidates\nother than the favorite---i.e., having $||\\{\\alpha_i \\condition 2 \\leq\ni \\leq m\\}||\\geq 2$---is NP-complete to manipulate.  Every other\nscoring-protocol election system can be manipulated in polynomial\ntime.  In effect, we show that---other than trivial systems (where all\ncandidates alway tie), plurality voting, and plurality voting's\ntransparently disguised translations---\\emph{every} scoring-protocol\nelection system is NP-complete to manipulate.""",3
"b'We study the behavior of Range Voting and Normalized Range Voting\nwith respect to electoral control. Electoral control encompasses attempts\nfrom an election chair to alter the structure of an election in order\nto change the outcome. We show that a voting system resists a case of\ncontrol by proving that performing that case of control is\ncomputationally infeasible.  Range Voting is a natural extension of\napproval voting, and Normalized Range Voting is a simple variant which\nalters each vote to maximize the potential impact of each voter.  We\nshow that Normalized Range Voting has among the largest number of\ncontrol resistances among natural voting systems.'",3
"b'While a conventional program uses exactly as much memory as it\nneeds, the memory use of a garbage-collected program can be adjusted\nby changing the size of the heap used by the garbage collector. This\ndifference can allow applications to adapt their memory demands in\nresponse to the changing amount of available memory in a shared\nenvironment, which is increasingly important for today\xc3\xa2\xc2\x80\xc2\x99s multicore,\nmultiprocessor machines.\nWe present a memory performance model that better addresses issues\nthat occur with the more changeable memory demands of\ngarbage-collected applications. Traditional locality models are not\ndirectly applicable because the application demand may change based on\nthe available memory size. We describe time-memory curves, which can\nbe used to derive optimal static memory allocation a shared\nenvironment. For dynamic environments, however, more will be needed.\nIn this work, we describe Poor Richard\xc3\xa2\xc2\x80\xc2\x99s Memory Manager, a lightweight\nsystem to reduce paging costs that can be incorporated into existing\nruntime systems. We describe the design of the memory manager and show\nhow it can be added to most existing garbage collectors with little to\nno effort. Using an ex- perimental evaluation of both homogeneous and\nheterogeneous Java workloads on a dual processor machine, we show that\nPoor Richard\xc3\xa2\xc2\x80\xc2\x99s Memory Manager improves average performance by a factor\nof 3 or more when paging, while adding almost no overhead when there\nis no memory pressure. We further show that this system is not\nspecific to any single algorithm, but improves every garbage collector\non which it is tested. We finally demonstrate the versatility of our\nmemory manager by using it to improve the performance of a range of\n.Net workloads.'",2
"b'We describe the goals, architecture, and functioning of the TRAINS-93\nsystem, with emphasis on the representational issues involved in\nputting together a complex language processing and reasoning agent. \nThe system is intended as an experimental prototype of an intelligent,\nconversationally proficient planning advisor in a dynamic domain of\ncargo trains and factories. For this team effort, our strategy at the\noutset was to let the designers of the various language processing,\ndiscourse processing, plan reasoning, execution and monitoring modules\nchoose whatever representations seemed best suited for their tasks, but with\nthe constraint that all should strive for principled, general approaches.\n\nDisparities between modules were bridged by careful design of the\ninterfaces, based on regular in-depth discussion of issues encountered by\nthe participants. Because of the goal of generality and principled\nrepresentation, the multiple representations ended up with a good deal\nin common (for instance, the use of explicit event variables and the\nability to refer to complex abstract objects such as plans); and future\nunifications seem quite possible. We explain some of the goals and\nparticulars of the KRs used, evaluate the extent to which they served their\npurposes, and point out some of the tensions between representations that\nneeded to be resolved. On the whole, we found that using very expressive\nrepresentations minimized the tensions, since it is easier to extract what\none needs from an elaborate representation retaining all semantic nuances,\nthan to make up for lost information.'",0
"b""Existing algorithms for pronoun resolution typically cast the problem\ninto a coreference task, which means they simply identify an antecedent\nnoun phrase for each pronoun. Selection of the antecedent is usually based\non a calculation of salience or focus. This simplified approach is unable to\naccount for pronouns without noun-phrase antecedents. Examples are abstract\nreferents such as events, propositions, and speech acts that might appear in\nthe linguistic surface form as sentential complements, verbal constructions\nor entire sentences, as well as consequences or outcomes that don't appear\nin the surface form at all. This paper contains a survey of current methods\nof pronoun resolution for natural language understanding.  It then proposes\na strategy for resolving pronominal reference to abstract entities that\nincorporates semantic information in addition to salience calculations.\nPreliminary experiments are described that show the strategy to perform\nwell above baseline on a collection of spoken task-oriented dialogs.""",0
"b'We describe two domain-independent temporal reasoning systems called\nTimeGraph I and II, which can be used in AI-applications as tools for\nefficiently managing large sets of relations in the Point Algebra, in\nthe Interval Algebra, and metric information such as absolute times\nand durations. Our representation of time is based on timegraphs,\ngraphs partitioned into a set of chains on which the search is\nsupported by a metagraph data structure.  TimeGraph I was originally\ndeveloped by Taugher, Schubert, and Miller in the context of story\ncomprehension. TimeGraph II provides useful extensions, including\nefficient algorithms for handing inequations, and relations expressing\npoint-interval exclusion and interval disjointness. These extensions\nmake the system much more expressive in the representation of\nqualitative information and suitable for a large class of applications.'",0
"b""This dissertation addresses the problem of unsupervised learning for\npattern classification or category learning.  A model that is based on\ngross cortical anatomy and implements biologically plausible\ncomputations is developed and shown to have classification power\napproaching that of a supervised discriminant algorithm.\n\nThe advantage of supervised learning is that the final error metric is\navailable during training.  Unfortunately, when modeling human\ncategory learning, or in constructing classifiers for autonomous\nrobots, one must deal with not having an omniscient entity labeling\nall incoming sensory patterns.  We show that we can substitute for the\nlabels by making use of structure between the pattern distributions to\ndifferent sensory modalities.  For example the co-occurrence of a\nvisual image of a cow with a ``moo'' sound can be used to\nsimultaneously develop appropriate visual features for distinguishing\nthe cow image and appropriate auditory features for recognizing the moo.\n\nWe model human category learning as a process of minimizing the\ndisagreement between outputs of sensory modalities processing\ntemporally coincident patterns.  We relate this mathematically to the\noptimal goal of minimizing the number of misclassifications in each\nmodality and apply the idea to derive an algorithm for piecewise\nlinear classifiers in which each network uses the output of the other\nnetworks as a supervisory signal.\n\nUsing the Peterson-Barney vowel dataset we show that the algorithm\nfinds appropriate placement for the classification boundaries.\nThe algorithm is then demonstrated on the task of learning to recognize\nacoustic and visual speech from images of lips and their emanating sounds\nPerformance on these tasks is within 1-7\\% of the related\nsupervised algorithm (LVQ2.1).\n\nFinally we compare the algorithm to Becker's IMAX algorithm and give\nsuggestions as to how the algorithm may be implemented in the brain\nusing physiological results concerning the relationship between two\ntypes of neural plasticity, LTP and LTD, observed in visual cortical\ncells.  We also show how the algorithm can be used as an efficient method\nfor dealing with learning from data with missing values.""",0
"b'We argue that due to engineering choices in the design of\ncomputational machinery, the fundamental difficulty of\nachieving translation invariance in vision systems is widely\nmisunderstood in the image-processing community. Far from being\na relatively trivial problem, translation invariance represents a\ncomplex abstraction that is of equivalent difficulty to\n(and can be considered complete for) an important class of\nstructural distortion problems. We also argue that this class\nof abstractions is, in an important sense, efficiently learnable.\nThese facts have significant implications for the abilities of\nany plastic system (e.g. the brain) that is able to acquire\nor ""learn"" some member of the class.'",1
b'We describe a method for reconstructing indoor scenes from image\nmosaics using prior knowledge of the cuboid structure of the environment. \nThe method is inspired by traditional approaches to the camera pose\nestimation problems known as the PnL and PnA problems.  We show that\na cuboid can be reconstructed from the images of three of its corners.\nThe necessary camera intrinsic parameters are obtained by self-calibration\nin the image mosaicking process. The major advantages of this method\nover methods such as single view metrology are (1) it can do metric\nreconstruction; (2) it is a closed form solution so it is numerically\nstable; and (3) it requires only minimal user interaction.',1
"b'Theories of vision have traditionally confined themselves to the\npassive analysis of static images, focusing on the extraction of\ntask-independent, 3D reconstructions of the visual world. However, the\nimages projected on the retina are seldom unrelated static signals. Rather,\nthey represent measurements of a coherent and continuous stream of events\noccurring in the visual environment, constrained both by physical laws\nof nature and the observer\'s actions on the immediate environment. In short,\nvision is inherently a dynamic process.\n\nIn this thesis, we propose two related theories of dynamic visual perception.\nThe first theory exploits the ability to make eye movements for dynamically\nexploring the visual world. The resulting architecture uses appearance-based\nmodels of objects in lieu of hand-coded 3D models, and employs two visual\nroutines, one for object identification and another for object location,\nfor solving visual cognitive tasks. The second theory, which can be seen as\nan elaboration of the first, is based directly on the premise that vision\nis a stochastic, dynamic process. The task of visual perception is then\nreduced to the dual problems of optimally estimating visual events occurring\nin the external environment, and on a longer time scale, learning efficient\ninternal models of the environment. Both estimation and learning are\nappearance-based, relying only on input images rather than hand-coded\nobject/environment models. Using this framework, we derive estimation and\nlearning algorithms for visual recognition, visual ""attention,""\nocclusion-handling, segmentation, prediction, hierarchical recognition,\ntransformation-invariant recognition, and pose estimation. Experimental\nresults are provided to corroborate the viability of these derived algorithms.\n\nIn addition to their potential applications in machine vision and robotics,\nthe derived algorithms can also be used to understand human and mammalian\nvision. We use the visual routines theory to model saccade learning\nbehaviors in infants, visual search/cognitive behaviors in adult subjects,\nand hemispatial neglect in patients with parietal cortex lesions. The optimal\nestimation and learning framework is used to interpret the hierarchical and\nlaminar circuitry of the mammalian visual cortex, and to explain neuronal\nproperties such as endstopping, response suppression during free viewing\nof natural images, and spatiotemporal receptive field development in\nprimary visual cortex.'",1
"b'In this paper, we discuss how to process visual information in convoying\napplications, using only low-cost, off-the-shelf hardware. We introduce a\nnumerical algorithm for real-time perspective pose estimation that uses\nstrong task-specific constraints to achieve efficiency and stability.\nThrough extensive experiments performed with synthetic data, we show that\nthis approach yields more accurate recovery than a general-purpose\nstructure-and-motion recovery framework known as the Variable State Dimension\nFilter, even when some of its fundamental task-specific assumptions are\nonly partially valid. In addition, we discuss efficient ways to perform\nlow-level vision with off-the-shelf hardware, and we present a two-level\ncontrol strategy that uses high-frequency odometry data to stabilize visual\ncontrol. Real-world convoying experiments show that our tracking-and-control\nsystem performs quite well in the sense that it manages to keep targets\nin view, tolerates changes in lighting conditions, and enables vehicles\nto keep up with complex maneuvers performed by other members of the convoy,\nsuch as 180-degree turns.'",1
"b'Voting and elections are at the core of democratic societies.\nPeople vote to elect leaders, decide policies, and organize their\nlives, but elections also have natural applications in computer\nscience. For example, agents in multiagent systems often need to work\ntogether to complete some task, but each agent may have its own set\nof beliefs, preferences, and goals. Voting provides agents with a\nnatural way to reach decisions that take all their preferences into\naccount. With elections playing such an important role both in\nreal-life political settings and in computer science, it is natural\nto ask about their resistance to misuse.\n\nTwo particular types of election misuse are manipulation and bribery.\nIn manipulation, a group of voters chooses to misrepresent its\npreferences in order to obtain a\nmore desirable outcome, and in bribery an outside agent, the briber,\nasks (possibly at a cost) a group of voters to change its votes, to\nobtain some outcome desirable for the\nbriber. Classical results from political science show that, for any\nreasonable election system, there are scenarios where at least some\nvoters have an incentive to attempt manipulation.\n\nIn this thesis we seek to protect elections from manipulators and\nbribers by making their computational task of finding good\nmanipulations/bribes prohibitively expensive. When this is not\npossible, we seek to better understand (and even improve) the\nalgorithmic attacks that manipulators and bribers can employ. In doing\nso, we develop new models of manipulation and bribery, and provide new\napproaches to studying the computational complexity of bribery and\nmanipulation in elections.'",3
"b'We address the problems of determining consistency and of finding a\nsolution for sets of 3-point relations expressing exclusion of a point\nfrom an interval, and for sets of 4-point relations expressing\ninterval disjointness. Availability of these relations is an important\nrequirement for dealing with the sorts of temporal constraints\nencountered in many AI applications such as plan reasoning. We prove that\nconsistency testing is NP-complete and finding a solution is NP-hard.'",0
"b""Control of elections refers to attempts by an agent to, via such\nactions as addition/deletion/partition of candidates or voters, ensure\nthat a given candidate wins [BTT92].  An election system in which such\nan agent's computational task is NP-hard is said to be resistant to\nthe given type of control.  The only election systems known to be\nresistant to all the standard control types are highly artificial\nelection systems created by hybridization [HHR07].  In this paper, we\nprove that an election system developed by the 13th century mystic\nRamon Llull and the well-studied Copeland election system are both\nresistant to all the standard types of (constructive) electoral\ncontrol other than one variant of addition of candidates.  This is the\nmost comprehensive resistance to control yet achieved by any natural\nelection system.  In addition, we show that Llull and Copeland voting\nare very broadly resistant to bribery attacks, and we integrate the\npotential irrationality of voter preferences into many of our results.""",3
"b'This document describes the design and implementation of TRAINS-96,\na prototype mixed-initiative planning assistant system.\nThe TRAINS-96 system helps a human manager solve routing problems\nin a simple transportation domain. It interacts with the human\nusing spoken, typed, and graphical input and generates spoken output\nand graphical map displays. The key to TRAINS-96 is that it treats\nthe interaction with the user as a dialogue in which each participant \ncan do what they do best. The TRAINS-96 system is intended as both a\ndemonstration of the feasibility of realistic mixed-initiative planning\nand as a platform for future research. This document describes \nboth the design of the system and such features of its use as\nmight be useful for further experimentation. Further references\nand a comprehensive set of manual pages are also provided.'",0
"b'One serious problem of standard Genetic Programming (GP)\nis that evolved expressions appear to drift towards large and slow forms\non average. This report presents a novel analysis of the role played\nby variable complexity in the selection and survival of GP expressions.\nIt defines a particular property of GP representations, called\nrooted tree-schema, that sheds light on the role of variable complexity\nof evolved representations. A tree-schema is a relation on the space of\ntree-shaped structures which provides a quantifiable partitioning\nof the search space. The present analysis answers questions such as:\nWhat role does variable complexity play in the selection and survival of\nevolved expressions? What is the influence of a parsimony penalty?\nHow heavy should parsimony penalty be weighted or how should it be\nadapted in order to preserve the underlying optimization process?\nAre there alternative approaches to simulating a parsimony penalty\nthat do not result in a change of the fitness landscape?\nThe present report provides theoretical answers to these questions,\ninterpretation of these results, and an experimental perspective.'",0
"b""Self-awareness is an aspect of consciousness that is highly developed\nin humans in comparison with other animals. A human being unaware of\nhis or her personal characteristics, of what he or she knows and\ndoesn't know, can do and cannot do, wants and doesn't want, has\nexperienced and is experiencing, etc., would surely be difficult to\ncommunicate with naturally. Therefore we believe that consciousness\nplays a crucial role in building artificial dialog agents with\nhuman-level abilities.\n\nWe will provide an overview of consciousness as viewed in philosophy,\nbiology and artificial intelligence, and we will present relevant work\non agents that show abilities related to consciousness. Moreover we\nwill present our initial attempt to extend the architecture of a simple\nEPILOG-based agent originally built by A.N. Kaplan in the\ndirection of our goal of a human-like conscious dialog agent.""",0
"b'This manual describes a method for annotating rhetorical relations,\nadjacency pairs, and other argumentation acts found in task-oriented\nspoken dialog [Traum, 1993; Traum and Hinkelman, 1992].  It is largely\naimed at the novice annotator rather than the computational linguist, and\ntherefore in choosing terminology we have valued intuitiveness over precision.\nThis work came out of an exploration of how to mark structure above the\nspeech act in the Monroe corpus [Stent, 2000 (TN 99-2)]. For more\ninformation about the development of this manual, see [Stent, 2000 (INLG)]. \nThis tool is designed for use with ArgumentationTool, a tool for\nmarking argumentation acts in dialog that is available from\nhttp://www.cs.rochester.edu/research/cisd/resources/aad/.'",0
"b'In classic pattern recognition problems, classes are mutually\nexclusive by definition. Classification errors occur when the classes\noverlap in the feature space.  We examine a different situation,\noccurring when the classes are, by definition, not mutually exclusive.\nSuch problems arise in scene and document classification and in medical\ndiagnosis.  We present a framework to handle such problems and apply it\nto the problem of semantic scene classification, where a natural scene\nmay contain multiple objects such that the scene can be described by\nmultiple class labels (e.g., a field scene with a mountain in the\nbackground). Such a problem poses challenges to the classic pattern\nrecognition paradigm and demands a different treatment. \nWe discuss approaches for training and testing in this scenario and\nintroduce new metrics for evaluating individual examples, class recall\nand precision, and overall accuracy.  Experiments show that our methods\nare suitable for scene classification; furthermore, our work appears\nto generalize to other classification problems of the same nature.'",1
"b'A high-concurrency Transactional memory (TM) implementation needs\nto track concurrent accesses, buffer speculative updates, and manage\nconflicts. We propose that the requisite hardware mechanisms be\ndecoupled from one another. Decoupling (a) simplifies hardware\ndevelopment, by allowing mechanisms to be developed independently;\n(b) enables software to manage these mechanisms and control policy\n(e.g., conflict management strategy and laziness of conflict\ndetection); and (c) makes it easier to use the hardware for purposes\nother than TM.\n\nWe present a system, FlexTM (FLEXible Transactional Memory), that\nemploys three decoupled hardware mechanisms: read and write\n signatures, which summarize per-thread access sets; per-thread\n conflict summary tables, which identify the threads with which\n conflicts have occurred; and a lazy versioning mechanism, which\n maintains the speculative updates in the local cache and employs a\n thread-private buffer (in virtual memory) only in the rare event of\n an overflow. The conflict summary tables allow lazy conflict\n management to occur locally, with no global arbitration (they also\n support eager management). All three mechanisms are kept\n software-accessible, to enable virtualization and to support\n transactions of arbitrary length. In experiments with a prototype on\n the Simics/GEMS testbed, FlexTM provides a 5 times speedup over\n high-quality software TM, with no loss in policy flexibility. Our\n analysis highlights the importance of lazy conflict detection, which\n maximizes concurrency and helps to ensure forward progress. Eager\n detection provides better overall system utilization in a\n mixed-programming environment. We also present a preliminary case\n study in which FlexTM components aid in the development of a tool to\n detect memory-related bugs.'",2
"b""Image-based object recognition systems developed recently don't require\nthe construction of a 3D geometric model, allowing recognition of objects\nfor which current geometric recognition technologies do not apply.\nSuch systems are typically trained with labeled, clean views that cover\nthe whole viewing sphere and can sometimes handle generic, visually similar\nclasses with moderate variation.  It has been little explored whether\nsuch systems can be trained from imagery that is unlabeled, and whether\nthey can be trained from imagery that is not trivially segmentable.\n\nIn this report we investigate how an object recognition system developed\npreviously can be trained from clean images of objects with minimal\nsupervision. After training this system on a single or a small number of\nviews of each object, a simple learning algorithm is able to attract\nadditional views to the object representation, building clusters of views\nbelonging to the same object. We explore how the learning performance\nimproves by extending the set of views, introducing a small amount of\nsupervision, or using more complicated learning algorithms.""",0
"b'We analyze the problem of computing the minimal labels\nfor a network of temporal relations in the Point Algebra.\nvan Beek proposes an algorithm for accomplishing this task\nwhich takes $O(max(n^3,n^2\\cdot m))$ time\n(for $n$ points and $m$ $\\neq$-relations).\nWe show that the proof of the correctness of this algorithm\ngiven by van Beek and Cohen is faulty, and we provide a new proof\nshowing that the algorithm is indeed correct.'",0
"b'Language is about symbols and those symbols must be grounded\nin the physical environment during human development. Most recently,\nthere has been an increased awareness of the essential role of\ninferences of speakersU referential intentions in grounding those symbols.\nExperiments have shown that these inferences as revealed in eye,\nhead and hand movements serve as an important driving force in\nlanguage learning at a relatively early age. The challenge ahead\nis to develop formal models of language acquisition that can shed\nlight on the leverage provided by embodiment.  We present an implemented\ncomputational model of embodied language acquisition that learns words\nfrom natural interactions with users. The system can be trained in\nunsupervised mode in which users perform everyday tasks while providing\nnatural language descriptions of their behaviors.  We collect acoustic\nsignals in concert with user-centric multisensory information from\nnonspeech modalities, such as userUs perspective video, gaze positions,\nhead directions and hand movements.  A multimodal learning algorithm\nis developed that firstly spots words from continuous speech and then\nassociates action verbs and object names with their grounded meanings.\nThe central idea is to make use of non-speech contextual information\nto facilitate word spotting, and utilize userUs attention as deictic\nreference to discover temporal correlations of data from different\nmodalities to build lexical items. We report the results of a series\nof experiments that demonstrate the effectiveness of our approach.'",0
"b""Reduction is the operation of transforming a production in a\nLinear Context-Free Rewriting System (LCFRS) into two simpler\nproductions by factoring out a subset of the nonterminals on the\nproduction's righthand side.  Reduction lowers the rank of a\nproduction but may increase its fan-out.  We show how to apply\nreduction in order to minimize the parsing complexity of the\nresulting grammar, and study the relationship between rank,\nfan-out, and parsing complexity.  We show that it is always\npossible to obtain optimum parsing complexity with rank two.\nHowever, among transformed grammars of rank two, minimum parsing\ncomplexity is not always possible with minimum fan-out.""",0
"b'We investigate the relative complexity of the graph isomorphism\nproblem (GI) and problems related to the reconstruction of a graph\nfrom its vertex-deleted or edge-deleted subgraphs (in particular, deck\nchecking (DC) and legitimate deck (LD) problems).  We show that these\nproblems are closely related for all amounts $c \\geq 1$ of deletion:\n\n1) $GI \\equiv^{l}_{iso} VDC_{c}$, $GI \\equiv^{l}_{iso} EDC_{c}$,\n$GI \\leq^{l}_{m} LVD_c$, and $GI \\equiv^{p}_{iso} LED_c$.\n\n2) For all $k \\geq 2$, $GI \\equiv^{p}_{iso} k-VDC_c$ and\n$GI \\equiv^{p}_{iso} k-EDC_c$.\n\n3) For all $k \\geq 2$, $GI \\leq^{l}_{m} k-LVD_c$.\n\n4) $GI \\equiv^{p}_{iso} 2-LVC_c$.\n\n5) For all $k \\geq 2$, $GI \\equiv^{p}_{iso} k-LED_c$.\n\nFor many of these results, even the $c = 1$ case was not previously known.\n\nSimilar to the definition of reconstruction numbers $vrn_{\\exists}(G)$\n[HP85] and $ern_{\\exists}(G)$ (see page 120 of [LS03]), we introduce\ntwo new graph parameters, $vrn_{\\forall}(G)$ and $ern_{\\forall}(G)$,\nand give an example of a family $\\{G_n\\}_{n \\geq 4}$ of graphs on $n$\nvertices for which $vrn_{\\exists}(G_n) &lt; vrn_{\\forall}(G_n)$.  For every\n$k \\geq 2$ and $n \\geq 1$, we show that there exists a collection of\n$k$ graphs on $(2^{k-1}+1)n+k$ vertices with $2^{n}$ 1-vertex-preimages,\ni.e., one has families of graph collections whose number of\n1-vertex-preimages is huge relative to the size of the graphs involved.'",3
"b'We describe a self bootstrapping and adaptive system designed to make\nobservations of an outdoor \nenvironment and determine some simple environmental condi tions,\nspecifically whether it is day or night, \nand whether the conditions are clear, cloudy, or some mixtur e. Doing\nthis so that the system will self- \nadapt and operate reliably in a variety of locations and envi\nronments, robust against changes in seasons, \nweather, and typical human and non-human disturbances (e.g.\nstreetlights, thunderstorms) is a more \ncomplex problem than might first be thought. We describe some of the\npractical issues, and techniques \nfor dealing with them.'",1
"b""The ability to plan is a essential for any agent, artificial or\n%not,\nwishing to claim intelligence in both thought and behavior.  Not\nonly should a planning agent persist in pursuing a goal as long as\nthe situation justifies the agent's perseverance, but an\nintelligent planning agent must additionally be proficient\nwith responding to failures, opportunities, and threats in the\nenvironment.  This distinction leads naturally to a discussion of\nexternally motivated and internally motivated planning systems.\n\nWe first survey externally motivated planners, which exist and work\nonly to accomplish user-given goals.  These planners can be further\nclassified as either non-hierarchical or hierarchical, depending on\nwhether a high level plan is first developed and then successively\nelaborated.  We then review internally motivated planners, which are\nendowed with self-awareness and such mental attitudes as beliefs,\ndesires, and intentions.  Finally, we present a preliminary proposal\nof a self-aware, opportunistic planning agent that maximizes its own\ncumulative utility while achieving user-specified goals.""",0
"b'The focus of this thesis is to improve the ability of a\ncomputational system to understand spoken utterances in a dialogue\nwith a human. Available computational methods for word recognition\ndo not perform as well on spontaneous speech in task-oriented\ndialogue as we would hope. Even a state of the art recognizer\nachieves slightly worse than 70\\% word accuracy on spontaneous speech\nin a conversation focused on solving a specific problem.\n\nTo address this problem, I explore novel methods for post-processing\nthe output of a speech recognizer in order to correct errors.\nI adopt statistical techniques for modeling the noisy channel\nfrom the speaker to the listener in order to correct some of the\nerrors introduced there. The statistical model accounts for frequent\nerrors such as simple word/word confusions and short phrasal problems\n(one-to-many word substitutions and many-to-one word concatenations).\nTo use the model, a search algorithm is employed to find the most\nlikely correction of a given word sequence from the speech recognizer.\nThe post-processor output contains fewer erors, thus making\ninterpretation by downstream components, such as parsing,\nmore reliable.\n\nThe post-processor was employed in the TRAINS-95 and TRAINS-96\nconversational planning assistants to great avail. Using these\ntechniques, we were able to reduce the number of word recognition\nerrors in some scenarios by approximately 17\\% (absolute) in the\nTRAINS-95 and TRAINS-96 systems (from just under 40\\% to nearly 20\\%).\nConsequently, both systems were significantly more robust to\nrecognition errors when using the post-processor than when not.\nIn the scenario where the speech recognizer is tunable with the\navailability of new data, the impact of these techniques is not as\nlarge, but they do make an improvement nontheless.'",0
"b'It has been widely suggested that memory transactions should behave\nas if they acquired and released a single global lock. Unfortunately, this\nbehavior can be expensive to achieve, particularly when---as in the natural\npublication/privatization idiom---the same data are accessed both\ntransactionally and nontransactionally. To avoid overhead, we propose\nselective strict serializability (SSS) semantics, in which transactions have a\nglobal total order, but nontransactional accesses are globally ordered only\nwith respect to explicitly marked transactions. Our definition of SSS formally\ncharacterizes the permissible behaviors of an STM system without recourse to\nlocks. If all transactions are marked, then SSS, single- lock semantics, and\ndatabase-style strict serializability are equivalent.\n\nWe evaluate several SSS implementations in the context of a TL2-like\nSTM system. We also evaluate a weaker model, selective flow\nserializability (SFS), which is similar in motivation to the asymmetric lock\natomicity of Menon et al. We argue that ordering-based semantics are\nconceptually preferable to lock-based semantics, and just as efficient.'",2
"b'Appearance-based object recognition systems are currently the most\nsuccessful approach for dealing with 3D recognition of arbitrary objects\nin the presence of clutter and occlusion. However, no current system seems\ndirectly scalable to human performance levels in this domain.\nIn this report we describe a series of experiments on a previously\ndescribed object recognition system that try to see which, if any, design\naxes of such systems hold the greatest potential for improving performance.\nWe look at the potential effect of different design modifications\nand we conclude that the greatest leverage lies at the level of intermediate\nfeature construction.'",1
"b'Lexicon coverage is often the limiting factor in natural language \nprocessing systems. Recent work has attempted to remedy this situation\nby extracting information from machine readable dictionaries.\nUnfortunately, no NLP lexicon system or dictionary could possibly list\nall the potential words of English. However, humans are often able\nto interpret novel word forms (that is, words they have not seen before)\nwithout difficulty. One way we do this, if the word is complex\n(e.g., ""undecidability""), is by using cues from the internal structure \nof the word. Relations in phonological form often correspond to\nrelations in meaning. For example, if someone knows what the verb\n""open"" means, a number of educated guesses can be made about the\nmeaning of ""reopen"". Exceptions abound in lexical data and any system\nthat attempts to use lexical generalizations must be able to handle\nexceptions in a principled fashion. In this report, I will describe\nthe preliminary design of a system that uses relations in form\nto derive relations in meaning. For a new word, the system will produce\nmeaning postulates that represent an educated guess about the meaning\nof the new word. These meaning postulates will be written in Episodic\nLogic, and the entire system will be a module of the TRAINS system.'",0
"b'We attain two main objectives in this thesis. First, we employ test\nlanguages to prove limitations of proof techniques to resolve certain\nquestions in complexity theory. In this part of the thesis, we study the\nrelationship between quantum classes and counting classes via closure\nproperties, collapses, and relativized separations. We show that the best\nknown classical bounds for quantum classes such as EQP and BQP cannot be\nsignificantly improved using relativizable proof techniques. In some\ncases, we strengthen known relativized separations between quantum and\ncounting classes to their relativized immunity separations. Furthermore,\nusing the closure properties of certain gap-definable counting classes, we\nprove strong consequences, in terms of the complexity of the polynomial\nhierarchy, of the following hypotheses: NQP is contained in BQP, and EQP\nequals NQP. Aside from using test languages to study the relationship\nbetween quantum and counting classes, we use test languages to construct,\nvia degree bounds of polynomials, relativized worlds that exhibit\nseparations of classes and nonexistence of complete sets.\n\nSecond, we study certain concrete problems and characterize their\ncomplexity either by showing completeness results for complexity classes\nor by relating their complexity to some well-studied computational problem\n(e.g., the graph isomorphism problem). In this part of the thesis, we\nstudy concrete problems related to the reconstruction of a graph from a\ncollection of vertex-deleted or edge-deleted subgraphs, and concrete\nproblems related to a notion of linear connectivity in directed\nhypergraphs. We show that the problems we study related to the\nreconstruction of graphs either are isomorphic (in complexity-theoretic\nsense) to the graph isomorphism problem or are many-one hard for the graph\nisomorphism problem. In our study related to directed hypergraphs, we\nintroduce a notion of linear hyperconnectivity, denoted by L-hyperpath, in\ndirected hypergraphs and show how this notion can be used to model\nproblems in diverse domains. We study problems related to the cyclomatic\nnumber of directed hypergraphs with respect to L-hypercycles (the minimum\nnumber of hyperedges that need to be deleted so that the directed\nhypergraph becomes free of L-hypercycles) and obtain completeness\nresults for different levels of the polynomial hierarchy.'",3
"b""In this thesis we study the problem of recovering non-rigid motion,\nshape and reflectance properties of dynamic 3D scenes from image sequences.\nOur goals are both to advance towards a firmer mathematical understanding\nof the constraints that exist in this problem and to develop practical\nmethods that extract the desired properties directly from visual data,\nusing as little prior knowledge about the scenes being observed as possible.\n\nTo recover motion, shape and reflectance simultaneously when they are\nall unknown and the scenes potentially have discontinuities, we observe\nthat scenes composed of curves and surfaces with piecewise-smooth shape\nand motion trace manifolds embedded in 4D space-time as they move. Moreover,\nwe show that these manifolds have a well-defined differential-geometric\nstructure and, consequently, can be used as the basis to create\nspatiotemporally-distributed geometric and radiometric representations.\n\nThis insight is supported by a mathematical analysis of how multi-view\nimage sequences constrain spatiotemporally-localized scene properties\nsuch as the instantaneous 3D velocity, position and orientation of\nindividual scene points. Based on this analysis, we develop a general\nframework for visual reconstruction of dynamic scenes, and propose\nspecific representational primitives that are both powerful enough to\ncapture a broad class of scenes with arbitrarily-high accuracy and\nsimple enough to be unambiguously recovered from visual data alone.\nThe use of these primitives leads us to develop algorithms that break\nthe complex problem of reconstructing entire dynamic scenes into\ncollections of spatiotemporally-localized, well-posed optimization problems.\n\nExperiments with complex real scenes (paper, clothing, skin, shiny objects)\nand scenes for which ground-truth geometry is known illustrate our\nmethods' ability to (1) explain pixels and pixel variations in terms of\ntheir underlying physical causes---3D shape, surface reflectance,\n3D motion, illumination, and visibility, (2) recover dense and\nnon-rigid instantaneous velocity fields even in the presence of moving\nspecularities, and (3) incorporate spatio-temporal coherence into\ncomputations for improved stability, and accuracy gains with respect to\nstatic multi-view analysis techniques.""",1
"b'Predictive coding and temporal invariance are two major unsupervised\nlearning principles which have been used to explain the behavior of\nparts of the brain (most notably the striate cortex).\nAlthough both have been around for a number of years,\nno formal relationship between them has been established.\nWe prove that temporal invariance is a form of predictive coding.\nTo do this, we begin with the goal of predictive coding, make a set\nof assumptions about the class of problem we are dealing with,\nand derive temporal invariance from the predictive coding goal\nand our added assumptions.'",1
"b'This report documents our experience with different optical flow\nestimation methods and our attempt to use optical flow both qualitatively\nand quantitatively.  Special attention is devoted to improving the\nLucas-Kanade method to obtain dense flow. We use a simple clustering\ntechnique to find looming objects.  This method has the potential of\nsupporting obstacle avoidance using optical flow.  Experiments using\nreal images demonstrate that this simple clustering is effective for\ncertain scenes.  We also point out when this technique will fail. \nWe try to use optical flow quantitatively to recover the structure of\na piecewise planar environment.  First, we use the widely-known\n8-parameter planar flow equations to locate individual planes in the\nscene.   Second, in lieu of full flow, we try to use normal flow to\ncompute both the ego-motion and the structure.  Both trials fail\nungracefully, mostly due to noisy flow data.  We describe the mathematics\nofboth methods and our experimental results.'",1
"b'Appearance-based object recognition systems are currently the most\nsuccessful approach for dealing with 3D recognition of arbitrary objects\nin the presence of clutter and occlusion. However, no current system seems\ndirectly scalable to human performance levels in this domain.\nIn this report we describe a series of experiments on a previously\ndescribed object recognition system that try to see which, if any, design\naxes of such systems hold the greatest potential for improving performance.\nWe look at the potential effect of different design modifications\nand we conclude that the greatest leverage lies at the level of intermediate\nfeature construction.'",0
"b""Unambiguity in alternating Turing machines has received\nconsiderable attention in the context of analyzing globally-unique\ngames by Aida et al. [ACRW04] and in the design of efficient protocols\ninvolving globally-unique games by Crasmaru et al. [CGRS04]. This paper\nexplores the power of unambiguity in alternating Turing machines\nin the following settings:\n\n(1) We show that unambiguity based hierarchies---AUPH, UPH, and\n\\slant{UPH}---are infinite in some relativized world. For each $k$ &gt;= 2,\nwe construct another relativized world where the unambiguity based\nhierarchies collapse so that they have exactly $k$ distinct levels\nand their $k$'th levels coincide with PSPACE. These results shed light\non the relativized power of the unambiguity based hierarchies, and\nparallel the results known for the case of the polynomial hierarchy.\n\n(2) We define the bounded-level unambiguous alternating solution class\nUAS(k), for every $k &gt;= 1, as the class of sets for which strings in\nthe set are accepted unambiguously by some polynomial-time alternating\nTuring machine N with at most $k$ alternations, while strings not\nin the set either are rejected by $N$ or are accepted with ambiguity\nby N. We construct a relativized world where, for all $k &gt;= 1$,\n$UP_{\\leq k}$  is a subset of  $UP_{\\leq k+1}$ and \n$UAS(k)$  is a subset of $UAS(k+1)$.\n\n(3) Finally, we show that robustly $k$-level unambiguous alternating\npolynomial-time Turing machines accept languages that are computable\nin $P^{\\Sigma^{p}_{k} \\oplus A}$, for every oracle $A$. This generalizes\na result of Hartmanis and Hemachandra [HH90].""",3
"b'We prove that P-sel, the class of all P-selective sets, is\nEXP-immune, but is not EXP/1-immune.  That is, we prove that some\ninfinite P-selective set has no infinite EXP-time subset, but we\nalso prove that every infinite P-selective set has some infinite\nsubset in EXP/1.  Informally put, the immunity of P-sel is so\nfragile that it is pierced by a single bit of information.\n\nThe above claims follow from broader results that we obtain about\nthe immunity of the P-selective sets.  In particular, we prove that\nfor every recursive function f, P-sel is DTIME(f)-immune.  Yet\nwe also prove that P-sel is not \\Pi_2^p/1-immune.'",3
"b""An agent with selective perception focuses its sensors on\nthose parts of the environment that are relevant to the task at\nhand.  Selective perception is an efficient method of gathering\ninformation from the world, but it presents problems for a learning\nagent when different actions are required in situations for which\nthe selective perception system cannot produce distinguishing\noutputs.  If this happens the agent is said to have incomplete perception,\nand the agent may be able to use internal state determined by past\nperceptions and actions in order to choose the correct action.\n\nI propose research on learning algorithms that use short-term memory to\ndisambiguate the incomplete perception that arises with selective perception.\nI present the Utile Distinction Memory (UDM) algorithm that\nsolves the incomplete perception problem using a partially observable\nMarkov decision process to represent the agent's internal state space. \nA significant feature of the algorithm is that it will build an\ninternal state space proportionate to the task at hand, not as large as\nwould be required to represent all of the perceivable world. \nA second algorithm, part of work in progress, will keep the advantages\nof UDM while improving learning speed and the ability to recognize\nthe significance of memories that span multiple time steps.\n\nLearning to use memory is difficult and will require a strong bias to\nlearn efficiently.  I will investigate ``learning by watching'' as a\nmethod of providing bias. Two applications I propose to study are:\ndriving a simulated car using vision from the driver's point of view;\nand setting a table with human cooperation or interference. Using the\nresults of psychophysical experiments, I will compare my algorithm's\nperceptual actions with the perceptual actions made by human subjects.""",1
b'We obtain the first nontrivial worst-case upper bound on the number\nof iterations required by the well-known Hoffman-Karp algorithm for\nthe simple stochastic game problem. We also describe a randomized variant\nof the Hoffman-Karp algorithm and analyze the expected number of\niterations required by it in the worst case.',3
"b'We describe some simple domain-independent improvements to\nplan-refinement strategies for well-founded partial order planning\nthat promise to bring this style of planning closer to practicality.\nOne suggestion concerns the strategy for selecting plans for refinement\namong the current (incomplete) candidate plans. We propose an A* heuristic\nthat counts only steps and open conditions, while ignoring ""unsafe\nconditions"" (threats). A second suggestion concerns the strategy for\nselecting open conditions (goals) to be established next in a selected\nincomplete plan. Here we propose a variant of a strategy suggested by\nPeot and Smith and studied by Joslin and Pollack; the variant gives\ntop priority to unmatchable open conditions (enabling the elimination\nof the plan), second-highest priority to goals that can only be achieved\nuniquely, and otherwise uses LIFO prioritization. The preference for\nuniquely achievable goals is a ""zero-commitment"" strategy in the sense that\nthe corresponding plan refinements are a matter of deductive certainty,\ninvolving no guesswork. In experiments based on modifications of UCPOP,\nwe have obtained improvements by factors ranging from 5 to several hundred\nfor a variety of problems that are nontrivial for the unmodified version.\nCrucially, the hardest problems give the greatest improvements.'",0
"b'There is a fundamental division between two approaches to cognition and\ninference in the real world. These approaches may be found in relatively\npure form among ""probabilists"" and ""logicists"" in artificial intelligence.\nGiven evidence and background knowledge, the justifiable inference,\non the first view, is that the probability of the conclusion is p (or \nthat its degree of certainty is c, etc.). Given evidence and background\nknowledge, the inference to the conclusion, on the second view, is\njustified just in case it conforms to an acceptable (often non-monotonic)\nprinciple of inference.\n\nThis is such a fundamental difference that it may well be that abstract \narguments are not really going to prove much. It is surely the case\nthat both approaches should be explored and tested. This article will\nexplore the dimensions of a research program based on a particular version\nof the second approach: that in which the conclusion of an inference\nfrom data and background knowledge is justified if that data and\nbackground knowledge renders the conclusion probable enough.\nThe corresponding conclusion on the first view would be: the conclusion\nis highly probable. But our conclusion is categorical; it is not\nqualified or hedged; it is accepted. Nevertheless, it is accepted\ndefeasibly: more data could lead us to withdraw it.\n\nQuestions of various sorts arise: What are the relations between this sort\nof defeasible reasoning and ordinary deductive reasoning? What is the\nsource of the ""data and background knowledge"" on the basis of which\nwe derive conclusions? Where do the probabilities come from?\nHow do we use this structure for making decisions? How do we choose\na level of practical certainty? How does this structure relate to\nother non-monotonic formalisms? How is it related to probabilistic\nstructures? Both traditional probabilists and non-monotonic reasoners\ntake evidence as ""given,"" and modify beliefs in its light. But we\nmust also consider the reliability of evidence: we evaluate our evidence\nin the light of what we believe. Is there a vicious circularity here?\n\nWhat I seek to explore is the question of empirical argument and\ninference as it concerns us in the world. I don\'t expect to provide\ndefinitive answers to these questions (and I would not presume to think\nthat they are the only questions that can be raised!), but I hope to be\nable to provide provocative indications of the form that answers might take.'",0
"b'The Medication Advisor is the latest project of the Conversational\nInteraction and Spoken Dialogue research group at the University of\nRochester. The goal of the project is an intelligent assistant that\ninteracts with its users via conversational natural language, and\nprovides them with information and advice regarding their prescription\nmedications. Managing prescription drug regimens is a major problem,\nparticularly for older people living at home who tend to have both\ncomplex medication schedules and, often, somewhat reduced faculties\nfor keeping track of them. Patient compliance with prescribed regimens\nis notoriously low, leading to incorrect and sometimes harmful usage of\nboth prescribed and over-the-counter medications. The Medication Advisor\nbuilds on our prior experience constructing conversational assistants\nin other domains. In addition to providing new challenges, the project\nallows us to validate previous efforts in areas such as portability. This\nbrief report details our initial efforts and outlines our future direction.'",0
"b'In this paper, we present a method for propagating segmentation\ninformation across a saccade for a foveating camera. In particular,\nwe take a region of interest from a wide-angle, low-fidelity image and\npropagate its segmentation information to a zoomed, high-fidelity\nimage containing that region. Our method uses normalized greyscale\ntemplates to estimate the change in translation and magnification\nrequired to transform the segmented region. This process is useful for\nsystems which detect regions of interest at low-fidelity and then\nperform a saccade to provide a high-fidelity view of that region of\ninterest. We show how using this method increases the performance\nof an active object recognition system.'",1
"b""Using a binocular, maneuverable visual system, a robot that holds\nits gaze on a visual target can enjoy improved visual perception and\nperformance in interacting with the world. This dissertation examines\nthe problem of holding gaze on a moving object from a moving platform,\nwithout requiring the ability to recognize the target.\nA novel aspect of the approach taken is the use of controlled\ncamera movements to simplify the visual processing necessary\nto keep the cameras locked on the target.\nA gaze holding system on the Rochester robot's binocular head\ndemonstrates this approach. Even while the robot is moving, the cameras\nare able to track an object that rotates and moves in three dimensions.\n \nThe key observation is that visual fixation can help separate\nan object of interest from distracting surroundings.\nCamera vergence produces a horopter (surface of zero stereo disparity)\nin the scene.  Binocular features with no disparity can be extracted\nwith a simple filter, showing the object's location in the image.\nSimilarly, an object that is being tracked will be imaged near\nthe center of the field of view, so spatially-localized processing\nhelps concentrate on the target. Rochester's binocular robot\nexploits these observations. The vergence and smooth tracking systems\ncooperate to hold the cameras on an object moving in three dimensions.\nThe vergence system changes the vergence angle of the cameras to\ndrive the disparity of the target to zero, relying on the tracking system\nto keep the target in the central field of view.\nThe tracking system centers the cameras on the zero-disparity signals,\nrelying on the vergence system to hold vergence on the target. \nInstead of requiring a way to recognize the target, the system relies\non active control of camera movements and binocular fixation segmentation.""",1
"b""We study the complexity of influencing elections through bribery: How\ncomputationally complex is it for an external actor to determine\nwhether by a certain amount of bribing voters a specified candidate\ncan be made the election's winner?  We study this problem for election\nsystems as varied as scoring protocols and Dodgson voting, and in a\nvariety of settings regarding homogeneous-vs.-nonhomogeneous\nelectorate bribability, bounded-size-vs.-arbitrary-sized candidate\nsets, weighted-vs.-unweighted voters, and succinct-vs.-nonsuccinct\ninput specification.  We obtain both polynomial-time bribery\nalgorithms and proofs of the intractability of bribery, and indeed our\nresults show that the complexity of bribery is extremely sensitive to\nthe setting.  For example, we find settings in which bribery is\nNP-complete but manipulation (by voters) is in P, and we find settings\nin which bribing weighted voters is NP-complete but bribing voters\nwith individual bribe thresholds is in P.  For the broad class of\nelections (including plurality, Borda, k-approval, and veto) known as\nscoring protocols, we prove a dichotomy result for bribery of weighted\nvoters: We find a simple-to-evaluate condition that classifies every\ncase as either NP-complete or in P.""",3
"b""A linguistic form's compositional, timeless meaning can be surrounded\nor even contradicted by various social, aesthetic,\nor analogistic companion meanings.\nThis paper addresses a series of problems in the structure of\nspoken language discourse, including turn-taking and grounding.\nIt views these processes as composed of fine-grained actions,\nwhich resemble speech acts both in resulting from a computational\nmechanism of planning and in having a rich relationship to the\nspecific linguistic features which serve to indicate their presence.\n\nThe resulting notion of Conversation Acts is more general than\nspeech act theory, encompassing not only the traditional speech acts\nbut turn-taking, grounding, and higher-level argumentation acts as well.\nFurthermore, the traditional speech acts in this scheme become fully joint\nactions, whose successful performance requires full listener participation.\n\nThis paper presents a detailed analysis of spoken language dialogue.\nIt shows the role of each class of conversation acts\nin discourse structure, and discusses how members of each class\ncan be recognized in conversation. Conversation acts, it will be seen,\nbetter account for the success of conversation than speech act theory alone.""",0
"b""In this report, we describe an obstacle identification method using\naffine structures from motion.  We first identify a reference plane by\ntracking feature points across image sequences.  We then compute the\nhomographies between images induced by the reference plane from these\nfeature points.  Once the feature points are categorized as on the\nplane and off the plane, we reconstruct the affine structure from all\nthe off-plane points.  The obstacles are identified from the affine\nstructure.  Our method doesn't require a calibrated camera.  Results\nof simulated and real experiments show that our method work very well.""",1
"b'We study the complexity of manipulation for a family of election\nsystems derived from Copeland voting via introducing a parameter\nalpha that describes how ties in head-to-head contests are valued. We\nshow that the problem of manipulation for unweighted\nCopeland^alpha elections is NP-complete even if the size of the\nmanipulating coalition is limited to two.  Our result holds for all\nrational values of alpha such that 0 &lt; alpha &lt; 1 except for\nalpha = 1/2. We contrast our result with the fact that microbribery\nfor Copeland^alpha is currently known to be in P exactly for alpha in\n{0,1/2,1} (complexity results for other values of alpha are unknown).\nMicrobribery is a problem very closely related to manipulation.  Since\nit is well known that manipulation via a single voter is easy for\nCopeland, ourresult is the first one where an election system originally known to\nbe vulnerable to manipulation via a single voter is shown to be\nresistant to manipulation via a coalition of a constant number\nof voters.  We also study the complexity of manipulation for\nCopeland^alpha for the case of a constant number of candidates. We\nshow that here the exact complexity of manipulation often depends\nclosely on the winner model as well as on the parameter alpha:\nDepending whether we try to make our favorite candidate a winner or\na unique winner and whether alpha is 0, 1 or between these values, the\nproblem of weighted manipulation for Copeland^alpha with three\ncandidates is either in P or is NP-complete. Our results show that\nways in which ties are treated in an election system, here Copeland\nvoting, can be crucial to establishing complexity results for this\nsystem.'",3
"b'In this paper, we present the results for semantic labeling, extending\nthe work of [Gildea and Jurafsky, 2002], [Fleischman et al., 2003],\n[Pradhan et al., 2004], and others. The main labeling approach is based\non Maximum Entroopy.  We show the performance of the baseline system\nas well as those by applying coreference resolution, stemming and feature\ncombinations to the feature files.'",0
"b""Most natural language processing tasks require lexical semantic\ninformation such as verbal argument structure and selectional\nrestrictions, corresponding nominal semantic class, verbal aspectual\nclass, synonym and antonym relationships between words, and various\nverbal semantic features such as causation and manner.  This\ndissertation addresses two primary questions related to such\ninformation: how should one represent it and how can one acquire it.\n\nIt is argued that, in order to support inferencing, a representation\nwith well-understood semantics should be used.  Standard first order\nlogic has well-understood semantics and a multitude of inferencing\nsystems have been implemented for it.  However, standard first order\nlogic, although a good starting point, needs to be extended before\nit can efficiently and concisely support all the lexically-based\ninferences needed.  Using data primarily from the TRAINS\ndialogues, the following extensions are argued for: modal operators,\npredicate modification, restricted quantification, and non-standard\nquantifiers.  These representational tools are present in many\nsystems for sentence-level semantics but have not been discussed in\nthe context of lexical semantics.\n\nA number of approaches to automatic acquisition are considered and\nit is argued that a ``surface cueing'' approach is currently the\nmost promising.  Morphological cueing, a type of surface cueing, is\nintroduced.  It makes use of fixed correspondences between\nderivational affixes and lexical semantic information.  The\nsemantics of a number of affixes are discussed and data resulting\nfrom the application of the method to the Brown corpus is presented.\n\nFinally, even if lexical semantics could be acquired on a large\nscale, natural language processing systems would continue to\nencounter unknown words.  Derivational morphology can also be used\nat run-time to help natural language understanding systems deal with\nunknown words.  A system is presented that provides lexical semantic\ninformation for such derived unknown words.""",0
"b'We present a method for autonomous learning of dextrous manipulation\nskills with multifingered robot hands. We use heuristics derived from\nobservations made on human hands to reduce the degrees of freedom of the task\nand make learning tractable. Our approach consists of learning and storing\na few basic manipulation primitives for a few prototypical objects and then\nusing an associative memory to obtain the required parameters for new objects\nand/or manipulations. The parameter space of the robot is searched using\na modified version of the evolution strategy, which is robust to the noise\nnormally present in real-world complex robotic tasks. Given the difficulty\nof modeling and simulating accurately the interactions of multiple fingers\nand an object, and to ensure that the learned skills are applicable in the\nreal world, our system does not rely on simulation; all the experimentation\nis performed by a physical robot, in this case the 16-degree-of-freedom\nUtah/MIT hand. Experimental results show that accurate dextrous manipulation\nskills can be learned by the robot in a short period of time.'",1
"b""Predictive coding is an unsupervised learning principle which has\nbeen proposed to explain the brain's perceptual abilities.\nWhile it has enjoyed success in modeling the receptive field\nproperties of cells in the visual and auditory cortex,\nits application has so far been limited only to perceptual areas\nof the cortex. Given the uniformity of the cortex, it seems likely that\none principle can account for the operation of the entire cortex.\n\nWe believe that predictive coding is such a principle, and that\nits utility extends well beyond perception.\nAll that is necessary for a predictive coding network\nto do motor control is that it have some feedback. \nIf its outputs affect its inputs, then it will use its outputs\nto affect the world in a way that it can predict.\nTherefore, motor control falls naturally out of the\npredictive coding framework.\n\nOne must be very careful in the development of a predictive\ncoding network in order to avoid making assumptions that prevent\nthe network from using its outputs in this fashion.\nIn particular, the network must not assume that its input is\nindependent of its output.  It also must not assume\nthat its outputs should be independent of each other.\nFinally, and most importantly, it must maximize Shannon information\nabout its input, instead of Fisher information. \nWe are not aware of any predictive coding network which\nsatisfies these criteria, so we present a derivation of one here.""",1
"b'A central difficulty with automatic speech recognition is the temporally\ninaccurate nature of the speech signal. Despite this, speech has been\ntraditionally modeled as a purely sequential (albeit probabilistic) process.\nThe usefulness of accurate sequence information is re-evaluated in this paper,\nboth at the acoustic and lexical levels for the task of speech recognition. At\nthe acoustic level, speech segments are quantized into discrete vectors, and\nconverted into set representations as opposed to accurate sequences.\nRecognition of the quantized vector sets dramatically improved\nperformance as contrasted with the corresponding vector sequence\nrepresentations. At the lexical level, our study suggests that accurate\nsequence information is, again, not crucial. In fact locally discarding\nphoneme sequence information may be useful for coping with errors (such as\ninsertion, substitution).  Based on the idea of phone set indexing, a\nlexical access algorithm is developed. Thus, this work questions the\ntraditional approach of modeling speech as a purely sequential process, and\nsuggests that discarding local sequential information may be a good idea.\nAs an alternative to a purely sequential representation,\na set representation seems to be a viable option.'",0
"b'Due to recent advances in the art, object recognition may soon replace\nlow-level feature extraction processes in automatic image database annotation.\nHowever, improvement in performance is still an important consideration.\nIn addition, model acquisition for appearance-based object recognition is\ntedious, since such systems usually require training on a large set of\nsegmentable example views that cover variation among class exemplars.\nThese views have to be labeled with object identity and pose.\n\nIn this thesis we first develop and analyze a feature-based object\nrecognition system that demonstrates good recognition of a variety of\n3D shapes, with full orthographic invariance.  We report the results of\nlarge-scale tests that evaluate recognition performance in conditions of\nbackground clutter and partial occlusion, as well as generic capabilities\nof the system.  We develop a statistical framework for predicting the\nperformance in a variety of situations from a few basic measurements.\nWe investigate the performance of object recognition systems to see which,\nif any, design axes of such systems hold the greatest potential for\nimproving performance. One conclusion is that the greatest leverage\nseems to lie at the level of intermediate feature construction.\nWe also analyze the effect of other improvements,\nsuch as parallelization and the use of multiple views.\n\nWe then formalize a system for constructing 3D recognition models using\nlarge, cluttered visual corpora, in a minimally supervised manner.\nAfter giving it a few seed pictures of an object class (say a couple of\npictures of cars), the system is given access to an unlabeled image\ndatabase containing, among other images, other pictures of the object.\nThe system then explores the image database, augmenting its representation\nof the object (in this case the car) class to include new information\nwhenever it finds a near enough match to the existing representation.\nAfter exposure to sufficient imagery, the system will usually have a\ngeneral model of the car that can label cars in the entire database\nand other databases.  We obtain a significant improvement in recognition\nperformance when training the system from unlabeled cluttered background\nimages, as opposed to training only on the labeled, black background\nseed image. The approach could use any appearance-based 3D object\nrecognition system.'",1
"b""On 7 December 1994, four student-built autonomous robots demonstrated\nvarious strategic, tactical, and mechanical approaches to a delivery task.\nThat event was preceded by approximately two years of history and\ntwo days of frenzied preparation.  Our robotics efforts were based on\nmaterials from MIT's well-known 6.270 course. This report summarizes\nour experiences, from pedagogical goals and organizational matters\nthrough mechanical and electronic techniques. Our intended audience\nis future robot-builders, and organizers of robot-building courses.\nWe assume familiarity with material in Jones and Flynn's Mobile Robotics\ntext, and with the various materials available from MIT over the internet.""",1
"b'Designing real-world applications can involve coordinating many pieces of\nhardware and integrating multiple software components.  Increased\nprocessing power has allowed complex real-world applications to be\ndesigned, and there has been increasing interest in the issues involved in\ndesigning both the applications and their support.  In this paper we\ndescribe the issues involved in designing the application.  The shepherding\napplication we have chosen is representative of many real-world\napplications.  This report focuses on technical details.  We describe the\nunderlying hardware, including the camera, vision processing boards,\nprocessors, and puma robot arm.  We then discuss the software components we\ndesigned to integrate the hardware components in real-time.  At each stage\nwe describe the trade-offs between the different possibilities and why the\nones chosen were best suited for our environment.  We also present results\nsupporting our selection.  At appropriate points we indicate underlying\nsupport that would have eased and improved our implementation.'",1
"b""A filesystem's sole purpose is to store data so it can \nbe easily accessed at a later time. Part of that entails \nrecovering properly from a system crash. But a difficulty \nthat modern filesystems face is the advent of write caching \nin a disk. The disk will report that a write operation has \ncompleted before the data is actually secure on the \nmagnetic platter. How is a programmer to respond to this \noutright lie from the hardware?\n\nThe problem goes even further. Journaled filesystems depend \non the order of the write operations they send to the disk. \nIf the real data is written before the journal, then there \nis not only no point in having the journal, but it actually \ngives a false sense of security. After a crash, the disk \nchecker will only replay the journal, never bothering to \nexamine the real data on the disk for consistency.\n\nThere is a solution to this problem. It is called Tagged \nCommand Queuing (TCQ) in the SCSI-2 specification. And it \nis optional. Filesystems, Ext3 in particular in this paper, \nuse TCQ exclusively and have no fallback. We present a \nfallback solution that depends on a required feature of the \nSCSI-2 specification, Force Unit Access (FUA). Our results \nshowed that write-intensive workloads display a significant\nslowdown from the FUA-based solution. However, the \nperformance impact is still less than that incurred by \nusing other methods, such as synchronizing the cache after \neach journal write.""",2
"b'Interactive spoken dialog provides many new challenges for natural\nlanguage understanding systems. One of the most critical challenges is\nsimply determining the speaker\'s intended utterances: both segmenting a\nspeaker\'s turn into utterances and determining the intended words in each\nutterance. Even assuming perfect word recognition, the latter problem is\ncomplicated by the occurrence of speech repairs, which occur when the\nspeaker goes back and changes (or repeats) something she just said.\nThe words that are replaced or repeated are no longer part of the intended\nutterance, and so need to be identified. The two problems of segmenting\nthe turn into utterances and resolving speech repairs are strongly\nintertwined with a third problem: identifying discourse markers.\nLexical items that can function as discourse markers, such as ""well"" and\n""okay,"" are ambiguous as to whether they are introducing an utterance unit,\nsignaling a speech repair, or are simply part of the context of an utterance,\nas in ""that\'s okay."" Spoken dialog systems need to address these three\nissues together and early on in the processing stream. In fact, just as\nthese three issues are closely intertwined with each other, they are also\nintertwined with identifying the syntactic role or part-of-speech (POS)\nof each word and the speech recognition problem of predicting the next word\ngiven the previous words.\n\nIn this thesis, we present a statistical language model for resolving\nthese issues. Rather than finding the best word interpretation for an\nacoustic signal, we redefine the speech recognition problem so that it\nalso identifies the POS tags, discourse markers, speech repairs and\nintonational phrase endings (a major cue in determining utterance units).\nAdding these extra elements to the speech recognition problem actually\nallows it to better predict the words involved, since we are able to make\nuse of the predictions of boundary tones, discourse markers and speech\nrepairs to better account for what word will occur next. Furthermore, we\ncan take advantage of acoustic information, such as silence information,\nwhich tends to co-occur with speech repairs and intonational phrase endings,\nthat current language models can only regard as noise in the acoustic signal.\nThe output of this language model is a much fuller account of the speaker\'s\nturn, with part-of-speech assigned to each word, intonation phrase endings\nand discourse markers identified, and speech repairs detected and corrected.\nIn fact, the identification of the intonational phrase endings,\ndiscourse markers, and resolution of the speech repairs allows the speech\nrecognizer to model the speaker\'s utterances, rather than simply the words\ninvolved, and thus it can return a more meaningful analysis of the speaker\'s\nturn for later processing.'",0
"b'In this paper we present a system for vision-based planning and\nexecution of fingertip grasps using a four-fingered dextrous hand. Our\nsystem does not rely on prior models of the objects to be grasped; it\nobtains all the information it needs from vision and from tactile\nsensors located at the fingertips of the hand. The grasp planner is\nbased on a genetic algorithm modified to allow the use of real numbers\nas the basic representation unit. The grasp executer is based on\ndifferential visual feedback, which allows the system to specify goals and\nmonitor progress in image space without needing absolute calibration\nbetween the camera and the hand. We present experimental results\nshowing the application of the system to grasping unknown objects with\nthe Utah/MIT hand.'",1
"b'This paper is about orienting, that is, establishing and maintaining\na spatial relation between a motorized pair of cameras\n(the eye-head system) and a static or a moving object tracked over time.\nMotivated by physiological evidence, the paper proposes a simple set of\nvision-based strategies aimed to perform head, eyes and body movements\nin a complex environment. Fixation is shown to be an essential feature\nin visual servoing, and it is used to decouple control on\nhead rotational degrees of freedom, making possible a metric-less approach\nto the orientation problem. A running implementation of these strategies,\nusing a binocular camera system mounted on a PUMA 700,\ndemonstrates the effectiveness of the approach.'",1
"b'This note is a commentary on, and critique of, Andre Luiz\n Barbosa\'s paper entitled ""P != NP Proof.""  Despite its\n provocative title, what the paper is seeking to do is not to prove\n P \\neq NP in the standard sense in which that notation is used in the\n literature. Rather, Barbosa is (and is aware that he is) arguing that a\n different meaning should be associated with the notation P \\neq NP,\n and he claims to prove the truth of the statement P \\neq NP\n in his quite different sense of that statement.  However,\n we note that (1) the paper fails even on its own terms, as due to a\n uniformity problem, the paper\'s proof does not establish, even in its\n unusual sense of the notation, that P \\neq NP; and (2) what the\n paper means by the claim P \\neq NP in fact implies that\n P \\neq NP holds even under the standard meaning that that notation has\n in the literature (and so it is exceedingly unlikely that\n Barbosa\'s proof can be fixed any time soon).'",3
"b'This paper addresses interoperability of software transactions and\nad hoc nonblocking algorithms. Specifically, we explain how to modify\n%arbitrary nonblocking methods so that (1) they can be used both\ninside and outside transactions, (2) external uses serialize with\ntransactions, and (3) internal uses succeed if, only if, and when the\n surrounding transaction commits. Interoperability has two important\nbenefits. First, it allows nonblocking methods to play the role of\nfast, closed nested transactions, with potentially significant\nperformance benefits. Second, it allows programmers to safely mix transactions\nand nonblocking methods, e.g., to update legacy code, call nonblocking\nlibraries, or atomically compose nonblocking methods.\n\nWe demonstrate our ideas in the context of the Java-based ASTM system\non several lock-free datastructures. Our findings are encouraging:\nAlthough performance of transaction-safe nonblocking objects\ndoes not match that of the original nonblocking objects, the\ndegradation is not unacceptably high (particularly after application\nof an optimization we call lazy logging). It is, moreover, significantly better\nthan that of analogous transactional objects. We conclude that\ntransaction safe nonblocking objects can be a significant enhancement to software transactional memory.'",2
"b'The study of semifeasible algorithms was initiated by Selman\'s work a\nquarter of century ago [Sel79,Sel81,Sel82].  Informally put, this\nresearch stream studies the power of those sets L for which there is a\ndeterministic (or in some cases, the function may belong to one of\nvarious nondeterministic function classes) polynomial-time function f\nsuch that when at least one of x and y belongs to L, then f(x,y) \\in L\n\\cap \\{x,y\\}.  The intuition here is that it is saying: ""Regarding\nmembership in L, if you put a gun to my head and forced me to bet on\none of x or y as belonging to L, my money would be on f(x,y).""\n\nIn this article, we present a number of open problems from the theory\nof semifeasible algorithms. For each we present its background and\nreview what partial results, if any, are known.'",3
"b'This paper describes a method for computing the domain of\nquantification of an adverbially quantified sentence.  This method\nrelies on the accommodation of presuppositions in the scope of a\nquantificational adverb and on the resolution of the domain in\ncontext.  Situations form the link between adverbial quantifiers\nand presuppositions, as adverbial quantifiers are taken to quantify\nover situations and presuppositions are taken to be constraints on\nresource situations.  This paper also briefly describes a\ncomputational system for processing such sentences based on this method.'",0
"b'Software transactional memory systems enable a programmer\nto easily write concurrent data structures such as lists, trees,\nhashtables, and graphs, where non-conflicting operations proceed\nin parallel. Many of these structures take the abstract form of\na dictionary, in which each transaction is associated with a search key.\nBy regrouping transactions based on their keys, one may improve\nlocality and reduce conflicts among parallel transactions.\n\nIn this paper, we present an executor that partitions transactions\namong available processors. Our key-based adaptive partitioning\nmonitors incoming transactions, estimates the probability distribution\nof their keys, and adaptively determines the (usually nonuniform)\npartitions. By comparing the adaptive partitioning with uniform\npartitioning and round-robin keyless partitioning on a 16-processor\nSunFire 6800 machine, we demonstrate that key-based adaptive\npartitioning significantly improves the throughput of fine-grained\nparallel operations on concurrent data structures.'",2
"b""We describe the design and implementation of a video-based augmented\nreality system capable of overlaying three-dimensional graphical objects\non live video of dynamic environments. The key feature of the system is\nthat it is completely uncalibrated: it does not use any metric information\nabout the calibration parameters of the camera or the 3D locations and\ndimensions of the environment's objects. The only requirement is the\nability to track across frames at least four feature points that are\nspecified by the user at system initialization time and whose world\ncoordinates are unknown.  Our approach is based on the following\nobservation: Given a set of four or more non-coplanar 3D points, the\nprojection of all points in the set can be computed as a linear combination\nof the projections of just four of the points. We exploit this observation\nby (1) tracking lines and fiducial points at frame rate, and\n(2) representing virtual objects in a non-Euclidean, affine frame of\nreference that allows their projection to be computed as a linear\ncombination of the projection of the fiducial points.""",1
"b'In this report, we describe methods of acquiring an environment map\nby image mosaicking.  We focus on technique details of the different\nalgorithms involved. These algorithms include image matching, homography\nestimation, linear image warping and linear self calibration. Many of these\ndetails are distributed in various publications and we here bring them\ntogether.  Furthermore, these algorithms are widely used in other\ncircumstances and we provide all the C++ code for each of the algorithms.'",1
"b'Automatic single-frame image orientation detection is a difficult\nproblem.  In this report, we describe a system designed to classify\nthe orientation of an image.  An algorithm designed by researchers at\nMichigan State University  is used as a baseline. First- and second-order\nspatial color moments are used as features. Learning Vector Quantization\n(LVQ) is used to estimate the underlying probability density function\nneeded by a Bayesian classifier.  We compare these results with those\nfor 1NN and SVM classifiers, and with LDA used as a feature extractor.\nExtensive experiments were conducted to gain insight into how and why\nthe MSU algorithm works.\n\nWe present results both for a stock photo library (Corel) and for\na set of consumer images (JBJL). Analyzing these results shows that\ncertain prototypical images (e.g., those with sky at the top) can be\nclassified correctly over 90% of the time, but that the general problem is\nmuch more difficult for low-level feature-based approaches.  We obtained\nbest results of 74% accuracy on the Corel set and 68% accuracy on JBJL,\nassuming equal prior among all four possible image orientations.'",1
"b""We describe some simple domain-independent improvements to\nplan-refinement strategies for well-founded partial order planning that\npromise to bring this style of planning closer to practicality.\nOne suggestion concerns the strategy for selecting plans for refinement\namong the current (incomplete) candidate plans. We propose an A* heuristic\nthat counts only steps and open conditions, while ignoring ``unsafe\nconditions'' (threats). A second suggestion concerns the strategy for\nselecting open conditions (goals) to be established next in a selected\nincomplete plan. Here we propose a variant of a strategy suggested by\nPeot \\&amp; Smith and studied by Joslin \\&amp; Pollack; the variant gives top\npriority to unmatchable open conditions (enabling the elimination of the\nplan), second-highest priority to goals that can only be achieved uniquely,\nand otherwise uses LIFO prioritization. The preference for uniquely\nachievable goals is a ``zero-commitment'' strategy in the sense that the\ncorresponding plan refinements are a matter of deductive certainty,\ninvolving no guesswork. In experiments based on modifications of UCPOP,\nwe have obtained improvements by factors ranging from 5 to more than 1000\nfor a variety of problems that are nontrivial for the unmodified version.\nCrucially, the hardest problems give the greatest improvements.""",0
"b'In their framework for ontological analysis, Guarino and Welty\nprovide a number of insights that are useful for guiding the design\nof taxonomic hierarchies.  However, the formal statements of these\ninsights as logical schemata are flawed in a number of ways,\nincluding inconsistent notation that makes the intended semantics of\nthe logic unclear, false claims of logical consequence, and\ndefinitions that provably result in the triviality of some of their\nproperty features.  This paper makes a negative contribution, by\ndemonstrating these flaws in a rigorous way, but also makes a\npositive contribution wherever possible, by identifying the underlying\nintuitions that the faulty definitions were intended to capture, and\nattempting to formalize those intuitions in a more  accurate way.'",0
"b'In this paper we consider the problem of computing the 3D shape of an\nunknown, arbitrarily-shaped scene from multiple color photographs taken at\nknown but arbitrarily-distributed viewpoints. By studying the equivalence\nclass of all 3D shapes that reproduce the input photographs, we prove the\nexistence of a special member of this class, the maximal photo-consistent\nshape, that (1) can be computed from an arbitrary volume that contains the\nscene, and (2) subsumes all other members of this class. We then give a\nprovably-correct algorithm for computing this shape and present experimental\nresults from applying it to the reconstruction of a real 3D scene from\nseveral photographs. The approach is specifically designed to (1) build 3D\nshapes that allow faithful reproduction of all input photographs,\n(2) resolve the complex interactions between occlusion, parallax, shading,\nand their effects on arbitrary collections of photographs of a scene, and\n(3) follow a ""least commitment"" approach to 3D shape recovery.'",1
"b'Explanation closure (EC) axioms were previously introduced as a means of\nsolving the frame problem. This paper provides a thorough demonstration\nof the power of EC combined with action closure (AC) for reasoning about\ndynamic worlds, by way of Sandewall\'s test suite of 12-or-so\nproblems [Sandewall 1991; 1992]. Sandewall\'s problems range from the\n""Yale turkey shoot"" (and variants) to the ""stuffy room"" problem, and\nwere intended as a test and challenge for nonmonotonic logics of action.\nThe EC/AC-based solutions for the most part do not resort to\nnonmonotonic reasoning at all, yet yield the\nintuitively warranted inferences in a direct, transparent fashion.\nWhile there are good reasons for ultimately employing\nnonmonotonic or probabilistic logics---e.g., pervasive uncertainty and\nthe qualification problem---this does show that the scope of\nmonotonic methods has been underestimated. Subsidiary purposes\nof the paper are to clarify the intuitive status of EC axioms in relation\nto action effect axioms; and to show how EC, previously formulated within\nthe situation calculus, can be applied within the framework of a\ntemporal logic similar to Sandewall\'s ""discrete fluent logic,"" with\nsome gains in clarity.'",0
"b""Preference aggregation in a multiagent setting is a central issue\nin both human and computer contexts. In this paper, we study in terms\nof complexity the vulnerability of preference aggregation to destructive\ncontrol. That is, we study the ability of an election's chair to,\nthrough such mechanisms as voter/candidate addition/suppression/partition,\nensure that a particular candidate (equivalently, alternative) does not\nwin. And we study the extent to which election systems can make it\nimpossible, or computationally costly (NP-complete), for the chair\nto execute such control. Among the systems we study---plurality,\nCondorcet, and approval voting---we find cases where systems immune\nor computationally resistant to a chair choosing the winner nonetheless\nare vulnerable to the chair blocking a victory. Beyond that, we see\nthat among our studied systems no one system offers the best protection\nagainst destructive control. Rather, the choice of a preference\naggregation system will depend closely on which types of control\none wishes to be protected against. We also find concrete cases where\nthe complexity of or susceptibility to control varies dramatically\nbased on the choice among natural tie-handling rules.""",3
"b'Most computing users today have access to clusters of multi-core\ncomputers.  To fully utilize a cluster, one must combine two levels\nof parallelism: shared-memory parallelism within a machine and\ndistributed memory parallelism across machines.  Such programming is\ndifficult.  Either a user has to mix two programming languages in a\nsingle program and use fixed computation and data partitioning\nbetween the two, or the user has to rewrite a program from scratch.\nEven after careful programming, a program may still have hidden\nconcurrency bugs.  Users who are accustomed to sequential\nprogramming do not find the same level of debugging and performance\nanalysis support especially for a distributed environment.\nThe paper presents a language of suggestions for distributive\nparallelization.  The suggestion language is designed for a user or\na profiling-based tool to annotate possible parallelism in C/C++\nprograms by inserting hints.  The hints are safe against any type of\nmisuse and expressive enough to specify independent, pipelined, and\nspeculative parallel execution on a cluster of multi-core computers.'",2
"b""Spoken dialogue poses many new problems to researchers in the field of\ncomputational linguistics.  In particular, conversants must detect and\ncorrect speech repairs, segment a turn into individual utterances, and\nidentify discourse markers.  These problems are interrelated.  For\ninstance, there are some lexical items whose role in an utterance can\nbe ambiguous: they can act as discourse markers, signal a speech\nrepair, or even be part of the content of an utterance unit.  So,\nthese issues must be addressed together. The resolution of these\nproblems will allow a basic understanding of how a speaker's turn can\nbe broken down into individual contributions to the dialogue.  We\npropose that this resolution must be and can be done\nusing local context.  They do not require a full understanding of the\ndialogue so far, nor, in most cases, a deep understanding of the\ncurrent turn.  Resolving these issues locally also means they can be\nresolved for the most part before later processing, and so will make a\nnatural language understanding system more robust and able to deal\nwith the unconstrained nature of spoken dialogue.""",0
b'Several decades of research have made many advances\ntowards the goal of interpreting the neural spike train but a\ncomprehensive understanding remains elusive. This paper pursues this\ngoal in the context of a new class of models termed predictive models.\nPredictive models characterize the cortex as a memory whose\nparameters can be used to predict its input. This allows the input to\nbe economically coded as a residual difference between itself and the\nprediction. Such models have recently had considerable success in\nmodeling features of visual cortex. This paper shows that the\npredictive coding model can be extended to a lower level of detail\nthat includes individual spikes as primitives. This is a significant\nimprovement in perspicuity compared to the firing rate variables used\nby most current models. The specific model we describe exploits the\nuse of coincidence of spike arrival times and the fact that neural\nrepresentations can be distributed over large numbers of cells.',1
"b'For years, researchers have used knowledge-intensive techniques for\ndisambiguating during parsing. These techniques required a lot of hand-coded\ninformation, thus they would not scale to large domains. In addition,\nthey often required the invention of pseudo-probabilities, which also\ndo not scale, and provide ill-founded quantitative measures. The data-driven\ntechniques, which have become popular over the past few years,\nseem appealing in light of this: once you have an annotated corpus,\nthere is no need to code up knowledge bases or invent ""magic numbers.""\nHowever, these methods also have extensive failings, which we will detail.\nWe present a framework for corpus-based syntactic disambiguation which\npulls together the well-foundedness of the traditional approaches and\nthe scalability of the corpus-based approaches. We also present a model of\nlanguage production that places greater emphasis on lexical statistics.'",0
"b'This paper studies the task of using a mobile camera platform to\nsearch a region of space for a target object.\nOur goal is to maximize the efficiency of such searches.\nThe problem is analyzed using a simple mathematical description of the factors\nthat affect search efficiency. This analysis suggests that one way to\nimprove efficiency is to take advantage of the spatial relationships\nin which the target object commonly participates. Searches that do so, \nwhich we call indirect searches, are modeled as two-stage processes\nthat first find an intermediate object that commonly participates in\na spatial relationship for the target object, and then look for the target\nin the restricted region specified by this relationship.\nA mathematical model of search efficiency is then used to analyze\nthe efficiency of indirect search over a wide range of situations that vary\nthe spatial structure of the domain as well as\nrecognition performance. The model predicts that, for searches\nthat involve rotating a camera about a fixed location, indirect searches\nimprove efficiency by factors of 2 to 8. An implemented robot search system\nsubstantiates these predictions. Finally, we highlight some areas \nin need of further research if these efficiencies are to be achieved.'",1
"b""We further siimplify Paterson's version of the Ajtai-Komlos-Szemeredi\nsorting network, and its analysis, mainly by tuning the invariant\nto be maintained.""",3
"b'This dissertation studies the problem of searching for a target object\nwith a visual sensor. In particular, it studies the task of selecting a\nsequence of viewpoints, viewing directions, and fields of view that\nefficiently examines the area being searched. \nThis is made difficult by two problems, namely the need for high image\nresolution and the presence of obstacles that occlude portions of\nthe search area from certain viewpoints.\n\nSearches for objects that require high image resolution to be\nrecognizable can potentially require the examination of a large number\nof images; high resolution requires a narrow field of view,\nand hence more images are necessary to span a given visual angle.\nThis dissertation considers a method for increasing search efficiency\nby searching only those subregions that are especially likely\nto contain the object. Searches that use this method, called\nindirect searches, repeatedly find a cheaply-locatable ""intermediate""\nobject that commonly participates in a spatial relationship with\nthe target object, and then look for the target in the restricted region\nspecified by this relationship. A decision-theoretic model\nof search efficiency is developed. The model identifies desiderata\nfor useful intermediate objects and predicts that, in typical indoor\nsituations, indirect search provides up to an eight-fold increase in\nefficiency. The model is also suitable for use in an on-line system\nfor selecting intermediate objects.\n\nThe second problem facing a searcher is that portions of the area being\nsearched are often hidden from view. Multiple viewpoints are therefore\noften necessary. This dissertation examines the selection of such\nviewpoints. Traditional viewpoint selection methods involve detailed\nmaps of the scene portions viewed so far. Simpler model-free methods\nare presented that, though less selective about their viewpoints, find\nobjects without significantly more effort than map-based methods.\nThey suggest that the main requirement for selecting efficient viewpoint\nsequences is that the searcher possesses a mechanism for ensuring\nthat it systematically traverses the viewpoint space. Such mechanisms\ncan be much simpler than maps. One drawback of model-free methods\nis that when the object is not present, they can waste more effort\nbefore aborting. Suggestions for remedying this are presented.'",1
"b'To study data placement on memory hierarchy, we present a model\ncalled {\\em reference affinity}.  Given a program trace, the model\ndivides program data into hierarchical partitions (called affinity\ngroups) based on a parameter $k$, which specifies the number of\ndistinct data elements between accesses to members of each affinity\ngroup. Trivial solutions exist for the two ends of the hierarchy.\nAt the top, when $k$ is no less than the data size, all program data\nbelong to one affinity group.  At the bottom, when $k$ is 0, each\nelement is an affinity group.\n\nWe present two theoretical results.  The first is the complexity.\nWe show that finding and checking affinity groups are in P when\n$k=1$ and $k=2$.  When $k=3$, the checking problem is NP-complete,\nand the finding problem is NP-hard.  The second is the uses.  We\nshow that reference affinity captures the hierarchical data locality\nfrom the trace of a hierarchical computation.  As additional\nevidence, we cite empirical results for general-purpose programs.'",3
"b'The goal of this thesis is to demonstrate the utility of\nlow-level motion  features for the purpose of recognition.\nAlthough motion plays an important role in biological recognition tasks,\nmotion recognition, in general, has received little attention\nin the literature compared to the volume of work on static object recognition.\nIt has been shown that in some cases, motion information alone is\nsufficient for the human visual system to achieve reliable recognition.\nPrevious attempts at duplicating such capability in machine vision\nhave been based on abstract higher-level models of objects, or\nhave required building intermediate representations such as the\ntrajectories of certain feature points of the object.\nIn this work we demonstrate that motion recognition can be accomplished\nusing lower-level motion features, without the use of abstract object models\nor trajectory representations.\n\nFirst, we show that certain statistical spatial and temporal features\nderived from the optic flow field have invariant properties, and can be\nused to classify regional motion patterns\nsuch as ripples on water, fluttering of leaves, and chaotic fluid flow.\nWe then present a novel low-level computational approach for detecting\nand recognizing temporally repetitive movements, such as those\ncharacteristic of walking people or flying birds, on the basis of\nthe periodic nature of their motion signatures.\nWe demonstrate the techniques on a number of real-world image sequences\ncontaining complex non-rigid motion patterns.\nWe also show that the proposed techniques are reliable and efficient by\nimplementing a real-time activity recognition system.'",1
"b""We present the theory behind TOD (the Temporal Object Discoverer), a\nnovel unsupervised system that uses only temporal information to\ndiscover objects across image sequences acquired by any number of\nuncalibrated cameras.  The process is divided into three phases: (1)\nExtraction of each pixel's temporal signature, a partition of the\npixel's observations into sets that stem from different objects; (2)\nConstruction of a global schedule that explains the signatures in\nterms of the lifetimes of a set of quasi-static objects; (3) Mapping\nof each pixel's observations to objects in the schedule according to\nthe pixel's temporal signature.  Our Global Scheduling (GSched)\nalgorithm provably constructs a valid and complete global schedule\nwhen certain observability criteria are met.  Our Quasi-Static\nLabeling (QSL) algorithm uses the schedule created by GSched to\nproduce the maximally-informative mapping of each pixel's\nobservations onto the objects they stem from.  Using GSched and QSL,\nTOD ignores distracting motion, correctly deals with complicated\nocclusions, and naturally groups observations across cameras.  The\nsets of 2D masks recovered are suitable for unsupervised training\nand initialization of object recognition and tracking systems.""",1
"b'Recent advances in computer hardware and signal processing have made\nit feasible to use human EEG signals or ""brain waves"" to communicate\nwith a computer. Locked-in patients now have a means to communicate with\nthe outside world. Even with modern advances, such systems still suffer\nfrom communication rates on the order of 2-3 items/minute.  In addition,\nexisting systems are not likely to be designed with flexibility in mind,\nleading to slow systems that are difficult to improve.\nThis dissertation presents a flexible brain-computer interface\nthat is designed to facilitate changes in signal processing methods\nand user applications.  In order to show the flexibility of the system,\nseveral applications, ranging from a brain-body actuated video game\nplayed with eye movements to a brain-computer interface for\nenvironmental control in a virtual apartment, are shown.\n\nThe P3 evoked potential is a positive wave in the EEG signal peaking\nat around 300 milliseconds after task-relevant stimuli and it can be\nused as a binary control signal.  A virtual driving experiment shows\nthat the P3 can be reliably detected within a virtual environment.\nSeveral on-line algorithms for processing single trial P3 evoked\npotentials are presented and compared.  It is important that actual\nEEG signals rather than signal artifacts are being recognized and thus\nfalse recognition of artifacts is shown to be small.\n\nResults from an environmental control application within a virtual\napartment are presented. Subjects do not perform significantly\ndifferent between controlling the application from a computer monitor\nand when fully immersed in the virtual apartment and subjects like\nthe immersive VR environment better. This highlights the fact that the\nP3 component of the evoked potential is robust over different environments\nand that usability does not depend solely on performance, but on other\nfactors as well. Future work is discussed within this context.'",1
"b'This report proposes a generalization of Dynamic Predicate Logic\nthat allows a straightforward treatment of functional anaphora\nin texts such as ""Most men had a gun, but only a few used it,""\nor ""If all of the graduates received a job offer, then all of them\naccepted their offer.""  The approach dynamically assigns (partial)\nfunctions as values of variables that are existentially quantified\nwithin the scopes of quantifiers like ""all"" and ""most.""\nThe proposed method is also applicable to bridging anaphora and\nfunctionally dependent entities in frames, scripts, and generic sentences.'",0
"b""Visual cognition depends critically on the\nmoment-to-moment orientation of gaze. Gaze is changed by \nsaccades, rapid eye movements that orient the fovea over targets\nof interest in a visual scene.  Saccades are ballistic; a\nprespecified target location is computed prior to the movement and\nvisual feedback is precluded.  Once a target is fixated, gaze is\ntypically held for about 300 milliseconds, although it can be held\nfor both longer and shorter intervals. Despite these distinctive\nproperties, there has been no specific computational model of the\ngaze targeting strategy employed by the human visual system during\nvisual cognitive tasks.  This paper proposes such a model that uses\niconic scene representations derived from oriented spatiochromatic\nfilters at multiple scales. Visual search for a target object\nproceeds in a coarse-to-fine fashion with the target's largest scale\nfilter responses being compared first. Task-relevant target\nlocations are represented as saliency maps which are used to program\neye movements. Once fixated, targets are remembered by using spatial\nmemory in the form of object-centered maps.  The model was\nempirically tested by comparing its performance with actual eye\nmovement data from human subjects in natural visual search tasks.\nExperimental results indicate excellent agreement between eye\nmovements predicted by the model and those recorded from human subjects.""",0
"b'The paper presents delta send-recv, an MPI extension for\noverlapping coarse-grained computation and communication. It provides\nan interface for marking the data computation and its communication.\nIt automatically blocks computation and divides communication into\nincrements. Delta sends and recvs are dynamically chained to effect\nsender-receiver pipelining, which is superior to pipelining only at\nthe sender or the receiver side.\nThe evaluation uses kernel tests to find the best increment size for\ndifferent MPI implementations and types of machines and networks. It\nshows 2 to 3 times performance improvement for large-volume data\nreduce involving 16 or 32 processors. In addition, the new interface\nenables computation and communication pipelining in an interpreted\nprogramming language, Rmpi.'",2
"b'In this report we discuss the creation and initial annotation of the\nMonroe corpus, a collection of video and audio data of 20 human-human,\nmixed-initiative, task-oriented dialogs about disaster-handling tasks.\nWe describe how the dialogs were collected, what tasks were used, and\nhow the data was transcribed and aligned.'",0
"b""The human brain has to integrate the inputs it receives from different\nsensory modalities into a coherent description of its environment.\nThis integration is often adaptive, showing recalibration or suppression\nof discordant sensory modalities. This paper proposes a qualitative theory\nof sensory integration which relates these adaptation phenomena to the\nanatomy of the neocortex and a rapid reversible synaptic mechanism\nas proposed in von der Malsburg's correlation theory of brain function.""",1
"b'Recently Gla{\\ss}er et al. have shown that for many classes $C$\nincluding PSPACE and NP it holds that all of\nits nontrivial many-one complete languages are autoreducible.\nThis immediately raises the question of whether all many-one complete \nlanguages are Turing self-reducible for such classes $C$.\n\nThis paper considers a simpler version of this question---whether all\nPSPACE-complete (NP-complete) languages are \nlength-decreasing self-reducible.  We show that if all  \nPSPACE-complete languages are length-decreasing \nself-reducible then PSPACE = P and that if all \nNP-complete languages are length-decreasing self-reducible then \nNP = P.\n\nThe same type of result holds for many other natural complexity classes.\nIn particular, we show that\n(1) not all NL-complete sets are logspace length-decreasing\nself-reducible,\n(2) unconditionally not all PSPACE-complete languages are\nlogspace length-decreasing self-reducible, and\n(3) unconditionally not all EXP-complete languages are\npolynomial-time length-decreasing self-reducible.'",3
"b'Training a learning machine from examples is accomplished by minimizing\na quantitative error measure, the training error defined over a training set.\nA low error on the training set does not, however, guarantee a low expected\nerror on any future example presented to the learning machine---that is,\na low generalization error.\n\nThe main goal of the dissertation is to merge theory and practice: \nto develop theoretically based but experimentally adapted tools that\nallow an accurate prediction of the generalization error of an arbitrarily\narbitrarily complex classifier. This goal is reached through experimental \nand theoretical studies of the relationship between the training and\ngeneralization error for a variety of learning machines. The result is\nthe introduction of a practical and principled method for predicting the\ngeneralization error. The power and accuracy of the predictive procedure \nis illustrated from application to real-life problems.\nTheoretical inspiration for the model arises from calculations of\nof the expected difference between the training and generalization error \nfor some simple learning machines. Novel computations of this character\nare included in the dissertation. Experimental studies yield experience\nwith the performance ability of real-life classifiers, and result in \nnew capacity measures for a set of classifiers.\n\nThe dissertation also presents a new classification algorithm, the \nSoft Margin Classifier algorithm, for learning with errors on the\ntraining set. The algorithm is an extension of the\nOptimal Margin Classifier algorithm, and is consistently found to\noutperform its predecessor because it absorbs out-lying and erroneous\npatterns in flexible margins.'",0
"b'The implementation of genetic algorithms raises many important issues.\nThese issues can be divided into two main classes: genetic search quality\nand execution performance. In the context of parallel genetic algorithms\non distributed-memory computers, performance considerations have\nalways driven the design of implementations. Thus, centralized\nimplementations have not previously been seriously considered for\ndistributed-memory architectures.\n\nThe work we present here defines a set of genetic algorithm implementation\nalternatives for distributed-memory computers, in which strategies with some\ncentralization are included. Each of our implementation alternatives uses a\ndifferent level of distribution of the population, from the single logically\ncentralized population to a totally distributed set of subpopulations.\n\nThe design alternatives we define can be applied to the implementation\nof any parallel genetic algorithm. As an example of such an implementation,\nwe study the quality of the search and the execution performance of\nour strategies on the 0-1 Integer Linear Programming problem, on a\nTransputer network. Our results show that implementations incurring\nhigher overheads can produce as good or better solutions faster than\nthan very ""efficient"" implementations, depending on the characteristics of\nthe problem at hand. More specifically, in some cases, utilizing more\ncentralized parallel genetic search strategies results in the fastest\nconvergence towards the optimal solution, therefore reducing the number\nof generations needed by the algorithm.'",0
"b'The RHET system is a knowledge representation tool that is intended\nto support the development of advanced prototype natural language under-\nstanding and planning systems. It is what is currently called a ""hybrid""\nrepresentation, which consists of a set of separately defined specialized\nreasoning systems that are presented to the user within a single uniform\nframework.  It can be used as a horn-clause based theorem proving system,\nor it can be used as a rich frame-based representation, or used in any way\nfalling between these styles of use. The primary specialized reasoning\ncomponents include a type hierarchy system, an equality reasoning system,\na temporal reasoning system, and a hierarchical context mechanism\nthat support reasoning about different agent\'s beliefs as well as\nhypothetical reasoning. This report provides a sequence of tutorials each\ndemonstrating a major feature of the system.'",0
"b'The task of generic object recognition involves learning to identify\nmembers of a class of objects based on a few exemplars from that class.\nGeneric object classes are inherently ill-defined. Objects can be grouped\ninto classes based on varying criteria such as form, function, color,\nsize, etc.  In this work, we develop two extensions to a well-studied,\n3D view-based, rigid-object recognizer that improve its performance on\ngeneric object classes grouped on shape and a related class of objects\nwe call loosely structured objects.\n\nThe first extension uses clustering on the underlying local context\nfeatures to discover features that recur within object classes.\nThe modification improves performance for rigid, generic, and loosely\nstructure classes, but it does not reliably discover recurrent features.\nFurther analysis shows most of the performance improvement comes\nfrom a side-effect of the clustering algorithm. Namely, features\nthat tend to create noise in the system become marginalized.\n\nThe second extension takes a principled approach to estimating\nthe quality of each object model feature based on its robustness\nand commonness. Noisy features get a low quality score and thus\ncontribute less noise to the recognition process.\nThis approach further improves recognition for rigid, generic, and\nloosely structured object classes over the clustering method.\n\nWe also develop an active recognition system that achieves better\nrecognition by utilizing additional information available in the active\nvision setting. The system uses change detection to perform\nforeground/background segmentation on the scene. This segmentation\ninformation is used to command a pan, tilt, zoom camera to acquire a\nhigh-resolution image of target regions in the scene. Furthermore,\nthe segmentation information is used to reduce background clutter\nin these high-resolution target images.\n\nFinally, we describe the Memory Assistant application built on top of\nthe active recognition system. This application is designed to assist\npeople with mild to moderate memory loss keep track of important\nobjects in a home environment. A prototype of this system is currently\ndeployed at the Center for Future Health at the University of Rochester\nMedical Center.'",1
"b""In uncertain reasoning one often needs to combine conflicting pieces of\nevidence. We show how the need for evidence combination arises in Kyburg's\nEvidential Probability system and investigate various methods of dealing\nwith it.""",0
"b""Statistical techniques have revolutionized all areas of natural language\nprocessing, and syntactic parsing is no exception. The availability of\nlarge syntactically annotated corpora (principally through the Penn Treebank\nproject) has precipitated parsing's shift from the task of constructing\ninterpretations to the task of constructing a labeled bracketing.\n\nThese corpus-based techniques are robust and scalable, two desiderata\nlacking in early, knowledge-based approaches to parsing. The early\napproaches are typified by parsers that could operate only in a narrow\ndomain, but that produced semantically interpretable parses. In contrast, the\ncorpus-based approaches produce underspecified labeled bracketings that are\nnot sufficiently detailed for applications in natural language understanding.\n\nIn this dissertation we describe a parser that uses hand-written\nlinguistically informed knowledge sources (grammar, lexicon, ontology)\nto enrich the labeled bracketing in the Penn Treebank. The enriched corpus\nis then used as the data source for statistical parsing in our well-founded\nframework. Furthermore, parsing in this framework supports a\nfully-lexicalized parsing model, and allows for the natural integration\nof word sense disambiguation with syntactic disambiguation.  We show\nthat jointly modeling word sense ambiguity and syntactic ambiguity\nresults in improved syntactic disambiguation.  We also describe our\ntreatment of coordinated structures (a topic generally ignored in\nstatistical parsing), and our novel method for using an ontology to\nsettle on backed-off estimators via hypothesis testing.""",0
"b""Discourse markers, also known as clue words, are used extensively\nin human-human task-oriented dialogs to signal the structure of the discourse.\nPrevious work showed their importance in monologs and social conversations\nfor marking discourse structure, but little attention has been paid to\ntheir importance in spoken dialog systems. This paper investigates what\ndiscourse markers signal about the upcoming speech, and when they tend to be\nused in task-oriented dialog. We demonstrate that there is a high correlation\nbetween specific discourse markers and specific conversational moves,\nbetween discourse marker use and adjacency pairs, and between discourse\nmarkers and the speaker's orientation to information presented in the prior\nturn. We limit our analysis to turn-initial discourse markers and discover\nnew patterns in their interaction with phenomena specific to dialog.""",0
"b'This report describes a corpus of task-oriented dialogues set in the\nTRAINS domain. A user collaborates with a planning assistant to\naccomplish some task involving manufacturing and shipping goods in a\nrailroad freight system. We include a description of the task,\ncollection situation, and transcriptions conventions. The audio\nfiles, along with time-aligned word and phoneme transcriptions are\navailable on CD-ROM from the Linguistic Data Consortium. Altogether,\nthere are 98 dialogs included, collected using 20 different tasks and\n34 different speakers. This amounts to six and a half hours of\nspeech, about 5900 speaker turns, and 55000 transcribed words.'",0
"b""Augmented reality is the merging of synthetic sensory information into\na user's perception of a real environment. Until recently, it has\npresented a passive interface to its human users, who were merely\nviewers of the scene augmented only with visual information.  In\ncontrast, practically since its inception, computer graphics--and its\noutgrowth into virtual reality--has presented an interactive\nenvironment.  It is our thesis that the agumented reality interfce can\nbe made interactive.  We present: techniques that can free the user\nfrom restricttive requirements such as working in calibrated\nenvironments, resutls with haptic interface technology incorporated\ninto augmented reality domains, and systems considerations that\nunderlie the practical realization of these interactive augmented\nreality techinques.""",1
"b""The Datacube MaxVideo 200 is a high-speed image processing system that can\nprovide video rate processing of images.  A user writes programs using the\nDatacube ImageFlow libraries to control the hardware.  Learning the details\nof ImageFlow programming is a daunting task for the new user.  This\nlearning task is made more difficult because the manuals for the MaxVideo\n200 hardware and ImageFlow software are rather obscure to the typical\nnovice user.  This user's guide describes several simple ImageFlow\nprograms.  Emphasis is placed on providing some of the folklore that is\nneeded to get started in MV200/ImageFlow programming.  Also, the\norganization of the information in the Datacube manuals is described so\nthat the new user can continue exploring on their own system features that\nare not in the sample programs.""",1
"b""This paper addresses the inference of 3D shape from a set\nof n noisy photos.  We derive a probabilistic\nframework to specify what one can infer about 3D shape for\narbitrarily-shaped, Lambertian scenes and arbitrary\nviewpoint configurations. Based on formal definitions of\nvisibility, occupancy, emptiness, and photo-consistency, the\ntheoretical development yields a formulation of the\nPhoto Hull Distribution, the tightest probabilistic bound\non the scene's true shape that can be inferred from the\nphotos.  We show how to (1) express this distribution in\nterms of image measurements, (2) represent it compactly by\nassigning an occupancy probability to each point in space,\nand (3) design a stochastic reconstruction algorithm that\ndraws fair samples (i.e., 3D photo hulls) from it.  We also\nshow experimental results on two complex scenes.""",1
"b'Speech of multiple speakers is transformed to speech produced by\na single speaker (speech normalization) using cross-coding networks.\nInternal representations for classification are acquired by feeding back\nthe internal speech (i-speech) produced. Training proceeds by\nunfolding the network through time, and combining the classification error\nwith the intermediate speaker-normalization errors.\nExperimental results on multi-speaker syllable recognition tasks\nwith trained and new speakers are discussed.'",0
"b'Finding lineal features in an image is an important step in many object\nrecognition and scene analysis procedures.  Previous feature extraction\nalgorithms exhibit poor parallel performance because features often extend\nacross large areas of the data set. This paper describes a parallel method\nfor extracting lineal features based on an earlier sequential algorithm,\nstick growing.  The new method produces results qualitatively similar to\nthe sequential method.\n\nExperimental results show a significant parallel processing speed-up\nattributable to three key features of the method: a large numbers of lock\npreemptible search jobs, a random priority assignment to source search\nregions, and an aggressive deadlock detection and resolution algorithm.\nThis paper also describes a portable generalized thread model. The model\nsupports a light-weight job abstraction that greatly simplifies parallel\nvision programming.'",0
"b""In this paper we introduce a formalism for optimal sensor\nparameter selection for iterative state estimation in static systems.\nIn contrast to common approaches, where a certain metric---for example,\nthe mean squared error between true and estimated state---is optimized\nduring state estimation, in this work the optimality is defined in terms of\nreduction in uncertainty in the state estimation process. The main\nassumption is that state estimation becomes more reliable if the\nuncertainty and ambiguity in the state estimation process can be reduced.\n\nWe consider a framework based on Shannon's information theory and\nselect the camera parameters that maximize the mutual information,\ni.e., optimize the information that the captured image conveys about\nthe true state of the system. The technique implicitly takes into\naccount the a priori probabilities governing the computation of the mutual\ninformation. Thus a sequential decision process can be formed by treating\nthe a priori probability at a certain time step in the decision process\nas the a posteriori probability of the previous time step.\n\nWe demonstrate the benefits of our approach using an object recognition\nscenario and an active pan/tilt/zoom camera. During the sequential\ndecision process the camera looks to parts of the object that allow\nthe most reliable distinction of similar looking objects. We performed\nexperiments with discrete density representation as well as with continuous\ndensities and Monte Carlo evaluation of the mutual information. The\nresults show that the sequential decision process outperforms a random\ngaze control, both in the sense of recognition rate and number of views\nnecessary to return a decision.""",1
"b'We propose a compaction of WordNet senses for natural language\nunderstanding (NLU) applications, where only those distinctions that are\nnot predictable from other knowledge sources are retained.  Further, we\npropose that word sense disambiguation programs that use WordNet as\ntheir dictionary may be evaluated with respect to this compaction, for\na better indicator of performance.  WordNet is attractive for studies\nof word sense disambiguation because of its quite comprehensive lexical\ncoverage.  However, for NLU applications, its very fine-grained\ndistinctions among word senses may be superfluous, in that these\ndistinctions often reflect a regular polysemy which is productive across\nmany words. The knowledge that this regular polysemy exploits is\nknowledge that a natural language understanding system must already have\nin order to handle other phases of the understanding process, such as\nreference resolution.  Thus a program which is able to disambiguate\nWordNet senses modulo, e.g. metonymy, will have essentially ""done its job""\nas a word sense disambiguator.  We conclude with an evaluation of\ndifferent disambiguators with respect to the compaction.'",0
b'In this report we describe a method for extracting curves from an image\nusing directional pixel variances instead of gradient measures as low-level\nboundary evidence. The advantage of the variance over the image gradient\nis that we can accurately compute the direction of a local edge even if\na sudden contrast change occurs in the background. This allows curves\nbelonging to object contours to be followed more easily. We compared our\nmethod to a similar method based on the image gradient and we found that\nit obtains better results when run on synthetic and natural images.\nOur method also improved the performance of a contour-based 3D object\nrecognition system in cluttered images.',0
"b'This paper addresses the issue of how verbal communication arises\nfrom the complex and uncertain representations that seem necessary to\nrobustly carry out perception in real-world domains. We propose that the\ngeneration of natural language in such domains should be addressed as\nthe optimization problem of finding, under various constraints, the\nverbalization that has the greatest probability of achieving a specific\nchange that the speaker wants to induce in the mental state or behavior\nof the listener. This most likely effective or MLE strategy has the\nadvantage of making the problem concrete, and allowing (possibly\nempathic) models of the perceptual and behavioral processes to be used\nin a principled way. We illustrate these issues in the context of\nthe specific problem of describing real objects in native domains\nusing basic color language (e.g., ""mostly brown,"" ""partly red"").\nThe term ""native domains"" refers to real-world environments that \nhave not been tailored to suit the application.'",1
"b'We eliminate some special cases from the proofs of two theorems\nin which a machine instantiating a many-query reduction to a p-selective\nset is made to use only one query. The first theorem, originally proved\nby Buhrman, Torenvliet, and van Emde Boas [BTvEB93], states\nthat any set that positively reduces to a p-selective set has a\nmany-one reduction to that same set. The second, originally proved\nby Buhrman and Torenvliet [BT96], states that self-reducible\np-selective sets are in P.'",3
"b'Redundancy is a basic property of many computational settings. This\nthesis concerns techniques for eliminating redundancy in some cases,\nand exploiting it in others.\n\nWe study one-way functions, i.e., functions that are easy to compute\nbut hard to invert. Such functions were previously studied as\ncryptographic primitives. Since it remains an open question whether\none-way functions exist, we study the question of their existence in\nrelation to a variety of complexity-theoretic hypotheses.\n\nStarting with one-way functions in which redundancy in the preimage is\nabsolutely minimal, i.e. one-to-one, we provide the first\ncharacterization of the existence of one-way permutations by a\ncomplexity class separation hypothesis, namely $\\P \\neq \\up \\inter\n\\coup$.\n\nNext, we study a type of one-way function that provably can never be\none-to-one. Strong, total, associative, one-way functions are\ntwo-argument, one-way functions that are hard to invert, even if one\nof their arguments is known. Such special, one-way functions were\noriginally used to construct secret-key agreement and digital\nsignature protocols. We study techniques for creating such functions\nwhose amount of preimage redundancy (as a function of the length of\nthe corresponding image element) is minimized.\nWe show that, if $\\p \\neq \\up$, then such special one-way functions\nexist and that we can go from total, associative polyomial-time\ncomputable functions to strong, total, associative, one-way functions\nat no cost in increased preimage redundancy.\n\nContinuing our study of eliminating redundancy in functions, we\nexamine the complexity of counting the sizes of intervals over orders\nhaving certain, natural, computational and redundancy properties. We\nshow that having redundancy in the adjacency relations of the order\nadds almost nothing to the computational complexity of computing such\nintervals.\n\nFinally, we look at a problem in routing on ad-hoc networks whose\nsolution exploits redundancy. We provide a theoretical framework for\nanalyzing the behavior of a variety of tableless routing schemes. We\nshow that such schemes work well when there is redundancy between the\nnetwork distance and the objective functions used to make routing decisions.'",3
"b'In POPL 2002, Petrank and Rawitz showed a universal result---finding\noptimal data placement is not only NP-hard but also impossible to\napproximate within a constant factor if P &lt;&gt; NP.  Here we study a\nrecently published concept called reference affinity, which\ncharacterizes a group of data that are always accessed together in\ncomputation.  On the theoretical side, we give the complexity for\nfinding reference affinity in program traces, using a novel reduction\nthat converts the notion of distance into satisfiability.  We also\nprove that reference affinity automatically captures the hierarchical\nlocality in divide-and-conquer computations including matrix solvers\nand N-body simulation.  The proof establishes formal links between\ncomputation patterns in time and locality relations in space.\n\nOn the practical side, we show that efficient heuristics exist.  In\nparticular, we present a sampling method and show that it is more\neffective than the previously published technique, especially for data\nthat are often but not always accessed together.  We show the effect\non generated and real traces.  These theoretical and empirical\nresults demonstrate that effective data placement is still attainable\nin general-purpose programs because common (albeit not all) locality\npatterns can be precisely modeled and efficiently analyzed.'",3
"b'We consider word alignment within the ""bag-of-words"" framework of\nIBM Model 1, and explore alternative optimization criteria and\nsolutions and show that neither the EM nor the probabilistic\nconstraint is necessary for learning good parameters.'",0
"b'We provide an overview of some recent progress on the complexity of\nelection systems.  The issues studied include the complexity of the\nwinner, manipulation, bribery, and control problems.'",3
"b'This paper describes how well prosodic information correlates with the\ntopic structure of a cooperative dialogue. To investigate this correlation\nsystematically, first we introduce the notion of utterance unit (UU)\nas a basic unit in conversations. We define the utterance unit by\nemploying four principles. The grammatical principle is a syntactic\ncriterion in which the UU boundary is set wherever the period can be placed.\nThe pragmatic principle says that each UU corresponds to a basic speech act.\nIn other words, if two neighboring phrases correspond to different\nspeech acts (for instance, acknowledgment and request),\nthey should be taken as two different UUs. The conversational principle\naddresses the turn-taking aspect of conversations. A UU boundary should\nbe placed wherever the speaker changes. Finally, the prosodic principle\nsays that whenever a medium length or longer pause (750 msec) is inserted\nbetween two phrases, they are to be taken as two different UUs.\nWe apply these principles to a speech database containing\nabout one and a half hours of collected dialogue\nto split the dialogues into a sequence of UUs.\nWe then classify the inter-UU boundaries based on the relationship\nbetween two neighboring UUs into four semantic categories:\ntopic shift, topic continuation, elaboration (or clarification), and\nspeech-act continuation.\nThe prosodic parameters measured at each boundary are the onset fundamental\nfrequency (F0), the final F0, and the F0 maximal peak declination ratio\n(the ratio of the current UUUs maximal peak to that of the preceding UU).\nOur study shows how these prosodic parameters vary depending on\nthe topic structure. Our results can be summarized as follows.\n(1) The onset F0 value tends to be higher when the topic is changed at\nthe UU boundary. (2) The final F0 value indicates finality and is much higher\n(on average) at speech-act continuation boundaries than at other boundaries.\n(3) The maximal peak declination ratio reflects the degree of subordination\nto the preceding UU. That is, this ratio is lowest at elaboration\nboundaries and highest at topic shift boundaries.\nFinally, we discuss discourse structure identification\nvia the prosodic parameters.'",0
"b""The focus of this thesis proposal is to improve the ability of a\ncomputational system to understand spoken utterances in a dialogue\nwith a human.  Available computational methods for word recognition do\nnot perform as well on spontaneous speech as we would hope.  Even a\nstate of the art recognizer achieves slightly worse than 70\\% word\naccuracy on (nearly) spontaneous speech in a conversation about a\nspecific problem.\n\nTo address this problem, I will explore novel methods for\npost-processing the output of a speech recognizer in order to\ncorrect errors.  I adopt statistical techniques for modeling the\nnoisy channel from the speaker to the listener in order to correct\nsome of the errors introduced there.  The statistical model accounts\nfor frequent errors such as simple word/word confusions and short\nphrasal problems (one-to-many word substitutions and many-to-one\nword concatenations).  To use the model, a search algorithm is\nrequired to find the most likely correction of a given word sequence\nfrom the speech recognizer.  The post-processor output should\ncontain fewer errors, thus making interpretation by higher levels,\nsuch as parsing, more reliable.\n\nSpontaneous speech is also challenging to process because it is more\nincremental than written language.  Utterances frequently form brief\nphrases and fragments rather than full sentences; they tend to come\nin installments and refinements.  Known methods for parsing do not\nperform as well as we would like in the face of these linguistic\nambiguities and idiosyncrasies.  Even state of the art algorithms\nfor parsing spontaneous language sustain high error rates.\n\nTo address the incrementality of spontaneously spoken utterances, I\nwill develop methods for segmenting a given utterance into ``chunks''\nrepresenting individual thoughts.  Given an utterance of spontaneous\nspeech, a tool for automatic prosodic feature extraction will\nanalyze the output of the error-correcting post-processor and the\nacoustic waveform to generate prosodic cues.  These cues will\naid a robust parser using a prosody-wise grammar to identify the\nincremental phrases in the utterance and to provide a syntactic analysis.\n\nThese components will augment the {\\sc Trains-95} conversational\nplanning assistant.""",0
"b'The location of objects in images is difficult owing to the view\nvariance of geometric features but can be determined by developing\nview-insensitive descriptions of the intensities local to image\npoints. View-insensitive descriptions are achieved in this work by\ndescribing points in terms of the responses of steerable filters at\nmultiple scales. Owing to the use of multiple scales, the vector for\neach point is, for all practical purposes, unique, and thus can be\neasily matched to other instances of the point in other images. We\nshow that this method can be extended to handle the case where the\narea near a point of interest is partially occluded. The method uses\na description of the occluder in the form of a template that can be\nobtained easily via active vision systems using a method such as\ndisparity filtering.'",1
"b'Supervised, neural network, learning algorithms have proven very\nsuccessful at solving a variety of learning problems. However,\nthey suffer from a common problem of requiring explicit output labels.\nThis requirement makes such algorithms implausible as biological models.\nIn this paper, it is shown that pattern classification can be achieved\nin a multi-layered, feed-forward neural network, without requiring\nexplicit output labels, by a process of supervised self-organization.\nThe class projection is achieved by optimizing appropriate\nwithin-class uniformity and between-class discernibility criteria.\nThe mapping function and the class labels are developed together iteratively\nusing the derived self-organizing back-propagation algorithm.\nThe ability of the self-organizing network to generalize on unseen data\nis also experimentally evaluated on real data sets, and compares\nfavorably with the traditional labeled supervision with neural networks.\nHowever, interesting features emerge out of the proposed\nself-organizing supervision that are absent in conventional approaches.\nThe further implications of self-organizing supervision with\nneural networks are also discussed.'",0
"b""Tracking is frequently considered a frame-to-frame operation. As such,\nobject recognition techniques are generally too slow to be used for\ntracking.  There are domains, however, where the objects of interest\ndo not move most of the time.  In these domains, it is possible to watch\nfor activity in the scene and then apply object recognition techniques\nto find the object's new location. This makes tracking a discrete process\nof watching for object disappearances and reappearances.  We have developed\na memory assistance tool that uses this approach to help people with\nslight to moderate memory loss keep track of important objects around\nthe house.  The system is currently deployed in a prototype smart home.""",1
"b'This document describes a toolkit and guidelines for the transcription\nof dialogues. The premise of these tools is that a dialogue between\ntwo people can be broken down into a series of utterance files, \neach spoken by one participant. This allows the transcription tools and\nstandards already designed for single speaker speech to be used.'",0
"b'Recognition of motion sequences is a crucial ability for\nbiological and robot vision systems. We present an architecture\nfor the higher-level processes involved in recognition of\ncomplex structured motion. The work is focused on modeling human recognition\nof Moving Light Displays. MLDs are image sequences that contain\nonly motion information at a small number of locations.\nDespite the extreme paucity of information in these displays,\nhumans can recognize MLDs generated from a variety of common\nhuman movements. This dissertation explores the high-level representations\nand computational processes required for the recognition task.\nThe structures and algorithms are articulated in the language of\nstructured connectionist models. The implemented network can\ndiscriminate three human gaits from data generated by several actors.\n\nRecognition of any motion involves indexing into stored models of movement.\nWe present a representation for such models, called scenarios,\nbased on coordinated sequences of discrete motion events. \nA method for indexing into this representation is described.\nWe develop a parallel model of spatial and conceptual attention that is\nessential for disambiguating the spatially and temporally diffuse MLD data.\nThe major computational problems addressed are: (1) representation\nof time-varying visual models; (2) integration of visual stimuli over time;\n(3) gestalt formation in and between spatially-localized feature maps\nand central movement representations; (4) contextual feedback\nto lower levels; and (5) the use of attention to focus processing\non particular spatial locations and particular high-level representations.\nSeveral novel connectionist mechanisms are developed\nand used in the implementation.\n\nIn particular, we present advances in connectionist representation of\ntemporal sequences and in using high-level knowledge to control\nan attentional mechanism. We show that recognition of gait can be\nachieved directly from motion features, without complex shape information,\nand that the motion information need not be finely quantized. \nWe show how the ""what"" and ""where"" processes in vision can be tightly\ncoupled in a synergistic fashion. These results indicate the value\nof the structured connectionist paradigm in modeling perceptual processes:\nno previous computational model has accounted for MLD recognition\nand we do not know how it would be approached in any other paradigm.'",0
"b'Rhetorical (Rhet) is a programming / knowledge representation system\nthat offers a set of tools for building an automated reasoning system.\nIts emphasis is on flexibility of representation. This document extends\nTR 326 with more information about the internals of the Rhet system.\nIn addition it provides the information needed for users to write their\nown builtin functions, or better lispfns (that use internally provided\nlibrary functions).'",0
"b""We propose a semantics for belief in which the derivation of\nnew beliefs from old ones is modeled as a computational process.\nUsing this model, we characterize conditions under which it is\nappropriate to reason about other agents by simulating their inference\nprocesses with one's own.""",0
"b""In the year 1876 the mathematician Charles Dodgson, who wrote\nfiction under the now more famous name of Lewis Carroll, devised a beautiful\nvoting system that has long fascinated political scientists.  However,\ndetermining the winner of a Dodgson election is known to be complete\nfor the \\Theta_2^p level of the polynomial hierarchy.  This implies\nthat unless P=NP no polynomial-time solution to this problem exists,\nand unless the polynomial hierarchy collapses to NP the problem is not\neven in NP.  Nonetheless, we prove that when the number of voters is\nmuch greater than the number of candidates---although the number of\nvoters may still be polynomial in the number of candidates---a simple\ngreedy algorithm very frequently finds the Dodgson winners in such a\nway that it ``knows'' that it has found them, and furthermore the\nalgorithm never incorrectly declares a nonwinner to be a winner.""",3
"b""Manipulators with large numbers of degrees of freedom, from the human\nhand to the trunk of an elephant, are common in the biological world.\nThese freedoms allow highly flexible and robust performance of complex\ntasks.  However, progress in developing and controlling artificial\nhigh-degree-of freedom manipulators has been slow.  The main problem\nis that traditional robotics has focussed on the solution of systems\nof kinematic equations where there is a unique solution.  Such\napproaches tend not to generalize well to situations with a\nhigh-dimensional solution space, and controlling redundant systems has\nacquired a reputation as a hard problem.  However, this need not be\nthe case.  In this paper, we describe a behavioral method for using\nextra degrees of freedom to simplify rather than complicate\nmanipulation problems, while at the same time obtaining more\nflexibility than would be available with a simpler system.  The method\nis developed in the context of a high DOF robot hand, but it has the\npotential to generalize to other sorts of manipulators.\n\nThe basic idea is based on the observation that, for a particular\ntask, using a custom-designed fitting can greatly simplify the control\nproblem. Using a wrench sized for a particular nut is an extreme\nexample.  We use the extra degrees of freedom to dynamically configure\nor ``tailor'' the manipulator to match the particular object and task\nat hand.  This creates a virtual tool.  The tailoring is\naccomplished by imposing low-level, task-specific constraints on the\ndegrees of freedom.  These constraints are selected dynamically from a\nlarge set of potential constraints in response to the demands of the\ncurrent task.  The process of smoothly transitioning from one virtual tool\nto another in the course of task execution is referred to as morphing.\nWe apply the technique to the control of a 16-DOF Utah/MIT hand, and\nperform fine manipulations on a range of objects using virtual tools that\nare dynamically instantiated on the basis of sensory information.""",1
"b'This report presents a method by which a reinforcement learning agent\ncan solve the incomplete perception problem using memory.\nThe agent uses a Hidden Markov Model (HMM) to represent its internal\nstate space and creates memory capacity by splitting states of the HMM.\nThe key idea is a test to determine when and how a state should be split:\nthe agent only splits a state when the split will help the agent predict\nutility. Thus the agent can build an internal state space\nproportionate to the task at hand, not as large as would be required\nto represent all of its perceivable world. I call the technique UDM,\nfor Utile Distinction Memory.'",0
"b'Fast track is a software speculation system that enables unsafe\noptimization of sequential code. It speculatively runs optimized code\nto improve performance and then checks the correctness of the\nspeculative code by running the original program on multiple\nprocessors.\n\nWe present the interface design and system implementation for\nFast Track. It lets a programmer or a pro\xc3\xaf\xc2\xac\xc2\x81ling tool mark fast-track\ncode regions and uses a run-time system to manage the parallel\nexecution of the speculative process and its checking processes and\nensures the correct display of program outputs. The core of the\nrun-time system is a novel concurrent algorithm that balances\nexploitable parallelism and available processors when the fast track\nis too slow or too fast. The programming interface closely affects\nthe run-time support. Our system permits both explicit and implicit\nend markers for speculatively optimized code regions as well as\nextensions that allow the use of multiple tracks and user de\xc3\xaf\xc2\xac\xc2\x81ned\ncorrectness checking. We discuss the possible uses of speculative\noptimization and demonstrate the effectiveness of our prototype\nsystem by examples of unsafe semantic optimization and a general\nsystem for fast memory-safety checking, which is able to reduce the\nchecking time by factors between 2 and 7 for large sequential code on\na 8-CPU system.'",2
"b""In the search for high performance, most transactional memory (TM)\nsystems execute atomic blocks concurrently and must thus be prepared\nfor data conflicts. These conflicts must be detected and the system\nmust choose a policy in terms of when and how to manage the resulting\ncontention.  Conflict detection essentially determines when the\nconflict manager is invoked, which can be dealt with eagerly (when\nthe transaction reads/writes the location), lazily at commit time, or\nsomewhere in between.\n\nIn this paper, we analyze the interaction between conflict detection\nand contention manager heuristics. We show that this has a significant\nimpact on exploitation of available parallelism and overall\nthroughput. First, our analysis across a wide range of applications\nreveals that simply stalling before arbitrating helps side-step\nconflicts and avoid making the wrong decision. HTM systems that don't\nsupport stalling after detecting a conflict seem to be prone to\ncascaded aborts and livelock. Second, we show that the time at which\nthe contention manager is invoked is an important policy decision:\nlazy systems are inherently more robust while eager systems seem prone\nto pathologies, sometimes introduced by the contention manager itself.\nFinally, we evaluate a \\textit{mixed} conflict detection mode that\ncombines the best of eager and lazy. It resolves write-write conflicts\nearly, saving wasted work, and read-write conflicts lazily, allowing\nthe reader to commit/serialize prior to the writer while executing \nconcurrently.""",2
"b""Electoral control refers to attempts by an election's organizer\n(``the chair'') to influence the outcome by adding/deleting/partitioning\nvoters or candidates.  The groundbreaking work of Bartholdi, Tovey,\nand Trick on (constructive) control proposes computational complexity\nas a means of resisting control attempts: Look for election systems\nwhere the chair's task in seeking control is itself computationally\ninfeasible.\n\nWe introduce and study a method of combining two or more\ncandidate-anonymous election schemes in such a way that the combined\nscheme possesses all the resistances to control (i.e., all the\nNP-hardnesses of control) possessed by any of its constituents: It\ncombines their strengths.  From this and new resistance constructions,\nwe prove for the first time that there exists an election scheme that\nis resistant to all twenty standard types of electoral control.""",3
"b""Neurons in the visual cortex are known to possess localized,\noriented receptive fields. It has previously been suggested that\nthese distinctive properties may reflect an efficient image encoding\nstrategy based on maximizing the sparseness of the distribution of\noutput neuronal activities or alternately, extracting the\nindependent components of natural image ensembles. Here, we show\nthat a relatively simple neural solution to the problem of\ntransformation-invariant visual recognition also causes localized,\noriented receptive fields to be learned from natural images. These\nreceptive fields, which code for various transformations in the\nimage plane, allow a pair of cooperating neural networks, one\nestimating object identity (``what'') and the other estimating\nobject transformations (``where''), to simultaneously recognize an\nobject and estimate its pose by jointly maximizing the \na posteriori probability of generating the observed visual data. We\nprovide experimental results demonstrating the ability of these\nnetworks to factor retinal stimuli into object-centered features and\nobject-invariant transformations. The resulting neuronal architecture\nsuggests concrete computational roles for the neuroanatomical\nconnections known to exist between the dorsal and ventral visual pathways.""",0
"b'Training a statistical machine translation system starts with\ntokenizing a parallel corpus. Some languages such as Chinese do not\nincorporate spacing in their writing system, which creates a challenge\nfor tokenization. Morphologically rich languages such as\nKorean and Hungarian present an even bigger challenge, since optimal\ntoken boundaries for machine translation in these languages are often\nunclear. Both rule-based solutions and statistical solutions are\ncurrently used. In this paper, we present unsupervised methods to\nsolve tokenization problem. Our methods incorporate information\navailable from parallel corpus to determine a good tokenization for\nmachine translation.'",0
"b""The problem of ambiguity is central to any theory of\nlanguage interpretation, whether our interest is in language\nprocessing in humans or in developing a usable natural language\nprocessing system. Psycholinguistic evidence suggests that human subjects\nare able to choose an interpretation when necessary, and\nthat competing factors are involved in this choice; however, no theory of\nlanguage interpretation deals satisfactorily with the combinatorial\nexplosion paradox---the fact that no matter how ambiguous natural language\nsentences are, they are usually interpreted without significant effort.\n\nThe main idea presented in this dissertation is that the scope preferences\nobserved in the literature are not obtained by an independent `scope\ndisambiguation' module, but are the result of independent interpretation\nprocesses such as definite description interpretation or the interpretation\nof modals. None of these interpretive procedures is especially concerned\nwith `scope disambiguation,' but the result of these inferences is that\nrelations of contextual dependency such as anaphoric reference or\npresuppositionality become part of the common ground; the scope preferences\nobserved in the literature reflect these relations of dependency. The\ndissertation includes a formal proposal concerning the representation of\ncontextual dependency and its impact on the semantics of sentence constituents.\n\nThe theory of ambiguity here presented is based on a distinction between\nsemantic ambiguity, that can be captured implicitly, by means of\nunderspecified representations, and perceived ambiguity, that results\nfrom the process of discourse interpretation. A new model of the common ground\nis introduced, that can be used to characterize both situations characterized\nby the presence of semantic ambiguity, and situations characterized by the\nexistence of perceived ambiguity.\n\nThe reasoning that leads to the establishment of scoping preferences\nmakes use, I argue, of information that is pragmatic in nature;\nthis calls for a model of discourse interpretation in which the\ncommon ground contains such information. In the case of spoken language\nconversations, the common ground must be a model of the\ndiscourse situation of the conversational participants.""",0
"b'Reuse distance is a basic metric for program locality.  The\ndistribution of reuse distances, called the reuse signature, shows the\naverage locality or the amount of actively used data.  Random access\nis often assumed in analytical models about program behavior.  An\ninteresting question is whether the reuse behavior of random data\naccess has a closed-form answer.  In this paper we prove that the\nlength of reuse distances of random access is uniformly distributed\nfrom 0 to n-1 when n is the size of data.  We also test random\ntraces of different lengths to show the effect on the distribution.'",2
"b'The TRAINS world is a transportation domain in which commodoties are\nmoved from site to site by various forms of transportation.\nIt includes factories, warehouses, trains, planes, ships and trucks\nand the agents that operate these facilities. The TRAINS world simulator\nis a general purpose graphical simulator that includes modules for\nsimulating the TRAINS world. The simulator allows extensions to the\nTRAINS world by providing a language for describing causal models.'",0
"b'We describe an appearance-based object recognition system using a keyed,\nmulti-level context representation reminiscent of certain aspects of cubist\nart. Specifically, we utilize distinctive intermediate-level features,\nin this case automatically extracted 2D boundary fragments, as keys,\nwhich are then verified within a local context, and assembled within a\nloose global context to evoke an overall percept. This system demonstrates\nextraordinarly good recognition of a variety of 3D shapes, ranging from\nsports cars and fighter planes to snakes and lizards with full orthographic\ninvariance. We report the results of large-scale tests, involving over 2000\nseparate test images, that evaluate performance with increasing number of\nitems in the database, in the presence of clutter, background change, and\nocclusion, and also the results of some generic classification experiments\nwhere the system is tested on objects never previously seen or modelled.\nTo our knowledge, the results we report are the best in the literature for\nfull-sphere tests of general shapes with occlusion and clutter resistance.'",1
"b""Using results from the field of robust statistics, we derive a class of\nKalman filters that are robust to structured and unstructured noise in the\ninput data stream. Each filter from this class maintains robust optimal\nestimates of the input process's hidden state by allowing the measurement\ncovariance matrix to be a non-linear function of the prediction errors.\nThis endows the filter with the ability to reject outliers in the input\nstream. Simultaneously, the filter also learns an internal model of input\ndynamics by adapting its measurement and state transition matrices using\ntwo additional Kalman filter-based adaptation rules. We present experimental\nresults demonstrating the efficacy of such filters in mediating\nappearance-based segmentation and recognition of objects and image sequences\nin the presence of varying degrees of occlusion, clutter, and noise.""",0
"b""This paper describes a formalism, Statistical Event Logic (SEL),\nthat adds statistical reasoning to Allen's planning language\n[Allen et al., 1991 (Reasoning about Plans)]. Interval temporal logic\nsupports reasoning about time and events; probability inferred from the\nplanner's experience supports reasoning about incomplete information.\nStatistical Event Logic can represent knowledge that allows a planner to\nreason both about choices based on incomplete knowledge and about\nthe future likely to result from these choices.""",0
"b""This thesis presents a bottom-up approach to understanding and\nextending robotic motor control by integrating human guidance. The focus\nis on dexterous manipulation using a Utah/MIT robot hand but the ideas\napply to other robotic platforms as well.\n\n{\\em Teleassistance} is a novel method of human/robot interaction in which\nthe human operator uses a gestural sign language to guide an otherwise\nautonomous robot through a given task. The operator wears a glove that\nmeasures finger joint angles to relay the sign language. Each sign serves\nto orient the robot within the task action sequence by indicating the next\nperceptual sub-goal and a relative spatial basis. Teleassistance merges\nrobotic servo loops with human cognition to alleviate the limitations of\neither full robot autonomy or full human control alone.\n\nThe operator's gestures are {\\em deictic}, from the Greek {\\em deiktikos}\nmeaning pointing or showing, because they circumscribe the possible\ninterpretations of perceptual feedback to the current context and thereby\nallow the autonomous routines to perform with computational economy and\nwithout dependence on a detailed task model. Conversely, the use of\nsymbolic gestures permits the operator to guide the robot strategically\nwithout many of the problems inherent to literal master/slave teleoperation,\nincluding non-anthropomorphic mappings, poor feedback, and reliance\non a tight communication loop.\n\nThe development of teleassistance stems from an analysis of autonomous\ncontrol, in light of recent advances in manipulator technology. This work\nalso presents a {\\em qualitative}, context-sensitive control strategy\nthat exploits the many degrees of freedom and compliance of dexterous\nmanipulators. The qualitative strategy governs the underlying autonomous\nroutines in teleassistance.""",1
"b'One of the less appreciated obstacles to scaling multi-agent systems\nis understanding the impact of the role(s) that people will play in those\nsystems. As we try to adapt existing software tools and agent-based\napplications to play supportive roles in larger multi-agent systems,\nwe must develop strategies for coordinating not only the problem-solving\nbehavior of these agent communities, but also their information sharing and\ninteractive behavior. Our research interest is in mixed-initiative control\nof intelligent systems [Burstein and McDermott, 1996; Burstein et al., 1998;\nFerguson et al., 1996a] and, in particular, of interactive planning systems\ncomprised of a heterogeneous collection of software agents. In this paper,\nwe describe our experience constructing a prototype tool combining elements\nof TRIPS [Ferguson and Allen, 1998], an interactive, mixed-initiative\nagent-based planning architecture using spoken natural language dialogue,\nwith the CAMPS Mission Planner, an interactive airlift scheduling tool\ndeveloped for the Air Force [Emerson and Burstein, 1999], together with\nsome related resource management agents representing other parts of the\nairlift planning organization. The latter scheduling tools were not\noriginally designed to participate as part of a mixed-initiative,\ninteractive agent community, but rather were designed for direct user\ninteraction through their own GUIs. We describe some requirements revealed\nby this effort for effective mixed-initiative interaction in such an\nenvironment, including the role of explanation, the need for contextual\ninformation sharing among the agents, and our approach to intelligent\ninvocation and integration of available agent capabilities.'",0
"b'This study of the Fall 2002 Computer Programming (CSC 171) course\nprovides a detailed analysis of the relationship between variables\nsuch as workshop attendance, gender, ethnicity and prior student ability\nand student performance. The results, detailed in the subsequent\nsections below, suggest the following:\n\n* Workshop attendance has a significantly positive impact on student\nperformance even after controlling for variations in gender and prior\nstudent ability.\n\n* Due to the small sample size of the female and minority groups,\nthe magnitude of the role gender and ethnicity plays in affecting\nstudent performance cannot be conclusively determined based on \nstatistical analyses.\n\n* Withdrawing female students performed significantly below their male\ncounterparts even though they attended more workshops on average,\nwhile female students who completed the course did not perform\nsignificantly differently from their male counterparts.\n\n* Prior student ability (as measured by SAT scores) is significant\nin affecting student performance.\n\n* Controlling for prior student ability alters the effect of workshop\nattendance on performance only slightly.  OLS regression results suggest\nan overestimation, logistic regression results suggest an underestimation\nof the effect prior to adding SAT scores.'",0
"b'Integrated, flexible, surviving, autonomous AI systems\nare on the horizon, raising new issues in systems support.\nThese systems typically embody hard real-time constraints (for servoing)\nand soft real-time constraints (solving problems to some level of\neffectiveness within some time constraints).\nWe assume an adequate hard real-time control substrate,\nand are concerned here with resource allocation for high-level\ndecision-making in Soft PArallel Real-Time ApplicationS (SPARTAS).\nSuch applications only need to respond to their environment\nquicker than their environment can dramatically change on them.\nSPARTAS often generate behavior by running high-level algorithms\nbased on a model of the world and on information from the environment.\nDesigning an executive for SPARTAS is challenging,\nsince in its full generality it calls for dynamic decision-making\nabout resource allocation, scheduling, choice of methods,\nand handling reflexive or reactive behavior smoothly\nwithin a context of planned or intended actions, and\na host of other issues not typically encountered either in\noff-line or hard real-time applications.\nAn important aspect of the environment for a SPARTA is its own state;\nwhat resources are being used for what purposes, and which are available.\nModern SPARTAS are written on parallel computers,\nfurther complicating matters.\nWe are designing Ephor, a run-time envirobnment for parallel machines\nto alleviate some of the difficulties faced by a SPARTA programmer.\nIn this paper we briefly describe Ephor,\nshow how it allows simpler application code, and\ndemonstrate that Ephor improves problem-solving performance\nin the presence of varying internal system state\nby dynamically choosing between different planners.'",0
"b'In a teleconference, reprojecting  a face can make it appear\nto be looking in a particular direction.  Thus reprojection can\nsubstitute for an individual camera for each member of the conference,\nsaving on hardware and transmission bandwidth.  Our reprojection\nalgorithm has an off-line part, which calculates fundamental matrices\nexpressing the relationships of different points of view.  \nDuring operation, the on-line part converts a single image into\npossibly several others that give conference participants the\nconsistent impression that the speaker is addressing a particular person.\nOur offline algorithm presents only an easy version of the generally\ndifficult correspondence problem.'",1
"b""Reinforcement learning is a promising technique for learning agents\nto adapt their own strategies in multi-agent systems. Most existing\nreinforcement learning algorithms are designed from a single-agent's\nperspective and for simplicity assume the environment is stationary,\ni.e., the distribution of the utility of each state-action pair does not\nchange. However, in a more realistic model of multi-agent systems, the\nagents are continually adapting their own strategies owing to different\nutilities at different times. Because of the non-stationarity, multi-agent\nsystems are more sensitive to the trade-off between exploitation,\nwhich uses the best strategy so far, and exploration, which tries to\nfind better strategies. Exploration is especially important to these\nchanging circumstances. In this paper, we assume that the utility of each\nstate-action pair is a stochastic process. This allows us to describe\nthe trade-off dilemma as a Brownian bandit problem to formalize Sutton's\nrecency-based exploration bonus in non-stationary environments.\nTo demonstrate the performance of the exploration bonus, we build agents\nusing Q-learning algorithm with a smoothed best response dynamics.\nThe simulations show that the agents can efficiently adapt to changes\nin their peers' behaviors whereas the same algorithm, using Boltzmann\nexploration, cannot adapt.""",0
"b'Active vision systems have the capability of continuously interacting\nwith the environment. The rapidly changing environment of such systems\nmeans that it is attractive to replace static representations with visual\nroutines that compute information on demand. Such routines place a premium\non image data structures that are easily computed and used.\n\nThe purpose of this paper is to propose a general active vision architecture\nbased on efficiently computable iconic representations. This architecture\nemploys two primary visual routines, one for identifying the visual image\nnear the fovea (object identification), and another for locating a stored\nprototype on the retina (object localization). This design allows complex\nvisual behaviors to be obtained by composing these two routines with\ndifferent parameters.\n\nThe iconic representations are comprised of high-dimensional feature vectors\nobtained from the responses of an ensemble of Gaussian derivative\nspatial filters at a number of orientations and scales. \nThese representations are stored in two separate memories.\nOne memory is indexed by image coordinates while the other is indexed by\nobject coordinates. Object localization matches a localized set of model\nfeatures with image features at all possible retinal locations.\nObject identification matches a foveal set of image features with\nall possible model features. We present experimental results for a near\nreal-time implementation of these routines on a pipeline image processor and\nsuggest relatively simple strategies for tackling the problems of occlusions\nand scale variations. We also discuss two additional visual routines\none for top-down foveal targeting using log-polar sensors and another\nfor looming detection, which are facilitated by the proposed architecture.'",1
"b'The goal of cache management is to maximize data reuse.\nCollaborative caching provides an interface for software to\ncommunicate access information to hardware. In theory, it can obtain\noptimal cache performance.\n\nIn this paper, we study a collaborative caching system that allows a\nprogram to choose different caching methods for its data. As an\ninterface, it may be used in arbitrary ways, sometimes optimal but\nprobably suboptimal most times and even counter productive. We develop\na theoretical foundation for collaborative cache to show the inclusion\nprinciple and the existence of a distance metric we call LRU-MRU stack\ndistance. The new stack distance is important for program analysis and\ntransformation to target a hierarchical collaborative cache system\nrather than a single cache configuration. We use 10 benchmark programs\nto show that optimal caching may reduce the average miss ratio by 24%,\nand a simple feedback-driven compilation technique can utilize\ncollaborative cache to realize 38% of the optimal improvement.'",2
"b'The TRAINS project is an effort to build a conversationally\nproficient planning assistant. A key part of the project is the\nconstruction of the TRAINS system, which provides the research\nplatform for a wide range of issues in natural language\nunderstanding, mixed-initiative planning systems, and representing\nand reasoning about time, actions and events.  Four years have now\npassed since the beginning of the project. Each year we have\nproduced a demonstration system that focused on a dialog that\nillustrates particular aspects of our research.  The commitment to\nbuilding complete integrated systems is a significant overhead on\nthe research, but we feel it is essential to guarantee that the\nresults constitute real progress in the field. This paper describes\nthe goals of the project, and our experience with the effort so far.\n\nThis paper is to appear in the Journal of Experimental and\nTheoretical AI, 1995.'",0
"b""A general-purpose object indexing technique is described that\ncombines the virtues of principal component analysis with the\nfavorable matching properties of high-dimensional spaces to achieve\nhigh precision recognition.  An object is represented by a set of\nhigh-dimensional iconic feature vectors comprised of the responses\nof derivative of Gaussian filters at a range of orientations and\nscales. Since these filters can be shown to form the eigenvectors of\narbitrary images containing both natural and man-made structures,\nthey are well-suited for indexing in disparate domains.  The\nindexing algorithm uses an active vision system in conjunction with\na modified form of Kanerva's sparse distributed memory which\nfacilitates interpolation between views and provides a convenient\nplatform for learning the association between an object's appearance\nand its identity. The robustness of the indexing method was\nexperimentally confirmed by subjecting the method to a range of\nviewing conditions and the accuracy was verified using a well-known\nmodel database containing a number of complex 3D objects under varying pose.""",1
"b'Many of the previous efforts in generalizing over knowledge\nextracted from text have relied on the use of manually created word\nsense hierarchies, such as WordNet. We present initial results on\ngeneralizing over textually derived knowledge, through the use of the\nLDA topic model framework, as the \xc3\xaf\xc2\xac\xc2\x81rst step towards automatically\nbuilding corpus speci\xc3\xaf\xc2\xac\xc2\x81c ontologies.'",0
"b""This paper presents a new class of interactive image editing\noperations designed to maintain physical consistency between multiple\nimages of a physical 3D object.  The distinguishing feature of these\noperations is that edits to any one image propagate automatically to\nall other images as if the (unknown) 3D object had itself been\nmodified. The approach is useful first as a power-assist that enables\na user to quickly modify many images by editing just a few, and second\nas a means for constructing and editing image-based scene representations\nby manipulating a set of photographs. The approach works by extending\noperations like image painting, scissoring, and morphing so that they\nalter an object's plenoptic function in a physically-consistent way,\nthereby affecting object appearance from all viewpoints simultaneously.\nA key element in realizing these operations is a new volumetric\ndecomposition technique for reconstructing an object's plenoptic\nfunction from an incomplete set of camera viewpoints.""",1
"b'We present a computational, constructive theory of\ntunable, open loop trajectory skills.  A skill is a controller\nwhose outputs achieve any task in a space characterized by n\nparameters, n &gt; 1. Throwing a ball at a target is a 3-dimensional task\nif the target may be anywhere within a 3-dimensional volume.  Repetitous\npick and place tasks are zero-dimensional, and thus not skills.\nSkills are performed open loop for speed reasons: we assume\nthe entire command sequence is generated before any feedback can\nbecome available.  We do not assume prior knowledge of plant or task\nmodels, so skills must be at least partly learned.\nA skill output is a vector of values---in our work so far\nit is generated as the sum of a base vector and a weighted change\nvector whose weight accomplishes the tuning.\nLearning consists of a search for the best set of base and change vectors.\nAn interpretation process maps skill outputs \ninto sequences of commands for the plant by using basis functions\n(given a priori in this paper). The basis functions may be\narbitrarily complex. We claim that appropriate basis functions\ncan speed up the learning process and overcome the limitations of the\nlinear trajectory tuning algorithm. This report describes a skill\nlearning algorithm and experiments done with various basis\nfunctions and control methods for a one-dimensional throwing task.\nIt concludes with a discussion of future work in learning basis\nfunctions, higher dimensional tasks, and comparisons against\ncommon learning and control algorithms.'",1
"b'Traditional analytic robotics defines grasping \nby knowing the task geometry \nand the forces acting on the manipulator precisely. \nThis method is particularly important for non-compliant manipulators \nwith few degrees of freedom, such as a parallel jaw gripper, \nthat overconstrain the solution space. In contrast, the advent of \nanthropomorphic, high degree-of-freedom grippers allows us to use \nclosed-loop strategies that depend heavily on the task context \nbut do not require precise positioning knowledge. \nTo demonstrate, a robotic hand flips a plastic egg, \nusing the finger joint tendon tensions as the sole control signal.\nThe manipulator is a compliant, sixteen degree-of-freedom, Utah/MIT hand \nmounted on a Puma 760 arm. \nThe completion of each subtask, such as picking up the spatula, \nfinding the pan, and sliding the spatula under the egg, \nis detected by sensing when the tensions of the hand tendons \npass a threshold.  Beyond this use of tendon tensions \nand the approximate starting position\nof the spatula and pan, no model of the task is constructed. \nThe routine is found to be robust to different spatulas and to changes in\nthe location and orientation of the spatula, egg, and table, \nwith some exceptions.\n\nThe egg-flipping example relies on interpreting fluctuating \ntension values within a known temporal sequence of actions.\nFor instance, knowing when the manipulator is trying to touch the pan\nwith the spatula provides the context \nto interpret changes in tendon tensions.\nGiven the success of this task, we go on to propose a method \nfor analyzing the temporal sensory output for tasks \nthat have not been previously segmented.\nThis method suggests a means for automatically generating robust\nforce-control programs to perform previously teleoperated manipulation tasks.'",1
"b'We describe a method of 3-D object recognition based on two stage use\nof a general purpose associative memory and a principal views representation.\nThe basic idea is to make use of semi-invariant objects called\nkeys. A key is any robustly extractable feature that has\nsufficient information content to specify a 2-D configuration of an\nassociated object (location, scale, orientation) plus sufficient additional\nparameters to provide efficient indexing and meaningful verification.\nThe recognition system utilizes an associative memory organized\nso that access via a key feature evokes associated hypotheses for the\nidentity and configuration of all objects that could have produced it.\nThese hypothesis are fed into a second stage associative memory,\nwhich maintains a probabilistic estimate of the likelihood of each\nhypothesis based on statistics about the occurrence of the keys\nin the primary database.\nBecause it is based on a merged percept of local features rather than\nglobal properties, the method is robust to occlusion and background\nclutter, and does not require prior segmentation.\nEntry of objects into the memory is an active, automatic procedure.\nWe have implemented a version of the system that allows arbitrary\ndefinitions for key features. Experiments using keys based on\nperceptual groups of line segments are reported.\nGood results were obtained on a database derived from of approximately 150\nimages representing different views of 7 polyhedral objects.'",1
"b""Control and bribery are settings in which an external agent seeks to\ninfluence the outcome of an election.  Faliszewski et al. [FHHR07]\nproved that Llull voting (which is here denoted by Copeland^1) and a\nvariant (here denoted by Copeland^0) of Copeland voting are\ncomputationally resistant to many, yet not all, types of constructive\ncontrol and that they also provide broad resistance to bribery.  We\nstudy a parameterized version of Copeland voting, denoted by\nCopeland^alpha where the parameter alpha is a rational number\nbetween 0 and 1 that specifies how ties are valued in the pairwise\ncomparisons of candidates in Copeland elections.  We establish resistance or\nvulnerability results, in every previously studied control scenario,\nfor Copeland^alpha, for each rational alpha, 0 &lt;alpha &lt; 1.  In particular, we\nprove that Copeland^0.5, the system commonly referred to as ``Copeland\nvoting,'' provides full resistance to constructive control. Among the\nsystems with a polynomial-time winner problem, this is the first\nnatural election system proven to have full resistance to constructive\ncontrol. Results on bribery and fixed-parameter tractability of\nbounded-case control proven for Copeland^0 and Copeland^1 in [FHHR07]\nare extended to Copeland^alpha for each rational alpha, 0 &lt; alpha &lt; 1;\nwe also give results in more flexible models such as microbribery\nand extended control.""",3
"b'DISCOPLAN is an implemented set of efficient preplanning\nalgorithms intended to enable faster domain-independent planning.\nIt includes algorithms that use a hypothesize-and-test paradigm to\ndiscover and inductively verify state constraints (invariants)\nimplicit in the structure of a given set of planning operators\nand initial state. Such state constraints have been shown to be very\nuseful, for example, for speeding up SAT-based planning, regression\nplanning, and heuristic decomposition of planning problems.\nDISCOPLAN handles operators with conditional effects, and efficiently\ndiscovers constraints of the following types: (1) type constraints;\n(2) predicate domain constraints; (3) simple implicative constraints\ninvolving up to two fluent literals and any number of static literals,\nwhere one of the fluent literals contains all of the variables\noccurring in the other literals; (4) single-valuedness (sv-) and\nn-valuedness constraints; (5) implicative and sv-constraints,\nrelaxing the restrictions on variable subsumption and requiring\nsimultaneous induction; (6) antisymmetry constraints;\n(7) XOR-constraints; and (8) some additional constraints obtainable\nby an iterative version of the hypothesize-and-test paradigm.\nThe methods for (6) and (8) involve ""expanding"" operators so as to\ninclude preconditions and effects implied by constraints discovered\nearlier. We also provide provably correct (and provisionally\nimplemented) methods for discovering additional types of constraints,\nincluding constraints involving arbitrarily many fluent literals.'",0
"b""In ordinary first-order logic, a valid inference in a\nlanguage {\\bf L} is one in which the conclusion is true in every\nmodel of the language in which the premises are true.  \nTo accommodate inductive/uncertain/probabilistic/non-monotonic inference,\nwe weaken that demand to the demand that the conclusion be true in\na large proportion of the models in which the relevant premises are true.\nMore generally, we say that an inference is [p,q] valid if its conclusion\nis true in a proportion lying between p and q of those models\nin which the relevant premises are true.  If we include a statistical\nvariable binding operator ``%'' in our language, there are many\nquite general (and useful) things we can say about uncertain validity. \nA surprising result is that some of these things may conflict with\nBayesian conditionalization.""",0
"b""One of the guiding principles of sparse coding is that neurons\nshould convey as much information as possible with every spike.\nHowever, sparse coding models have not lived up to this idea.  Many\nmodels use neurons which output continuous values over time.  This\nis justified by assuming they communicate by firing rates, but this\ndisregards all temporal information from the spike.  Newer models\nuse exact spike times, but they also use synchronous firing chains.\nFor neurons to convey as much information as possible per spike,\ntheir spikes must be as independent as possible.  Synfire chains\nare, in contrast, very highly correlated spike trains.\n \nThis model is to our knowledge the first sparse coding model on\nspiking neurons which does not use synfire chains.  Instead, each\nneuron tries to make its spike train as independent as possible from\nthose of its neighbors.  The neurons are strictly local, with\ntemporal receptive fields and recurrent inhibitory connections.  The\ninput can be reconstructed by summing the convolutions of each\nneuron's spike trains with their receptive fields.  Finally, we\nargue that the algorithm is related to K-means clustering in a\nconvolutional feature space.""",1
"b'Computer scientists, programmers, and engineers need to determine the\ncomplexity of computational problems on a daily basis, and they\ntypically ask the following questions: Is the problem easy or hard?\nIf it is easy, is there a really efficient algorithm for the problem?\nIf the problem is hard, how hard is it?  Are there large subclasses of\nproblems that are easy?  Are there efficient approximation algorithms\nfor the problem?  Finding the answers to these questions pertaining to\nproblem classification can be arduous and daunting for someone who is\nnot an expert in the domain.  Different problems, even from the same\ndomain, may require vastly different proof techniques for problem\nclassification.  Thus, it is highly desirable to have easily\napplicable tools (theorems, classification tests, algorithms, and\ndichotomy results) that classify a wide range of problems.  In this\nthesis we provide such general tools for determining the complexity of\nproblems arising in the following settings: boolean circuits, language\nproperties of central complexity classes (such as NP, PP, and\nParityP), cycles in graphs, oracle (database) access, theoretical\nbmodels of computer simulation, and structural restrictions on the\nwitness functions of nondeterministic polynomial-time Turing machines.'",3
"b'Machine learning aims towards the acquisition of knowledge based on\neither experience from the interaction with the external environment\nor by analyzing the internal problem-solving traces. Both approaches\ncan be implemented in the Genetic Programming (GP) paradigm.\nHillis [1990] proves in an ingenious way how the first approach\ncan work. There have not been any significant tests to prove that GP\ncan take advantage of its own search traces. This paper presents an\napproach to automatic discovery of functions in GP based on the\nideas of discovery of useful building blocks by analyzing the\nevolution trace, generalizing of blocks to define new functions and\nfinally adapting of the problem representation on-the-fly.\nAdaptation of the representation determines a hierarchical\norganization of the extended function set which enables a\nrestructuring of the search space so that solutions can be found more\neasily. Complexity measures of solution trees are defined for an\nadaptive representation framework and empirical results are presented.'",1
"b'We present a new algorithm, GM-Sarsa(0), for finding approximate\nsolutions to multiple-goal reinforcement learning problems that are\nmodeled as composite Markov decision processes. According to our\nformulation different sub-goals are modeled as MDPs that are coupled\nby the requirement that they share actions. Existing reinforcement\nlearning algorithms address similar problem formulations by first\nfinding optimal policies for the component MDPs, and then merging these\ninto a policy for the composite task. The problem with such methods is\nthat policies that are optimized separately may or may not perform well\nwhen they are merged into a composite solution. Instead of searching\nfor optimal policies for the component MDPs in isolation, our approach\nfinds good policies in the context of the composite task.'",1
"b'Hierarchical genetic programming (HGP) approaches rely on the\ndiscovery, modification, and use of new functions to accelerate\nevolution. This paper provides a qualitative explanation of the\nimproved behavior of HGP, based on an analysis of the evolution\nprocess from the dual perspective of diversity and causality. From a\nstatic point of view, the use of an HGP approach enables the\nmanipulation of a population of higher diversity programs. Higher\ndiversity increases the exploratory ability of the genetic search\nprocess, as demonstrated by theoretical and experimental fitness\ndistributions and expanded structural complexity of individuals.\nFrom a dynamic point of view, this report analyzes the causality of\nthe crossover operator. Causality relates changes in the structure of\nan object with the effect of such changes, i.e., changes in the\nproperties or behavior of the object. The analyses of crossover\ncausality suggests that HGP discovers and exploits useful structures\nin a bottom-up, hierarchical manner. Diversity and causality are\ncomplementary, affecting exploration and exploitation in genetic\nsearch. Unlike other machine learning techniques that need extra\nmachinery to control the tradeoff between them, HGP automatically\ntrades off exploration and exploitation.'",0
"b'Many sequential applications are difficult to parallelize because of\nproblems such as unpredictable data access, input-dependent parallelism,\nand custom memory management. These difficulties led\nus to build a system for behavior-oriented parallelization (BOP),\nwhich allows a program to be parallelized based on partial information\nabout program behavior, for example, a user reading just\npart of the source code, or a profiling tool examining merely one or\nfew inputs.\n\nThe basis of BOP is programmable software speculation, where\na user or an analysis tool marks possibly parallel regions in the\ncode, and the run-time system executes these regions speculatively.\nIt is imperative to protect the entire address space during speculation.\nThe main goal of the paper is to demonstrate that the general\nprotection can be made cost effective by three novel techniques:\nprogrammable speculatio'",2
"b'Currently, the TRAINS dialog system uses a more or less standard chart\nparser as the interface between the text of the dialog and the rest of the\ndialog processing system. However, traditional chart parsers are not well\nequipped to handle dialogs because dialog constituents can be discontinuous,\nwith interspersed acknowledgments, editing terms, repairs, etc. This paper\nproposes some modifications of the current TRAINS parser enabling it to handle\ndiscontinuous dialog structure. The representation of a dialog is still\nsuperficially hierarchical (rather than consisting of interleaved structures).\nThis is made possible by two devices: one is to accommodate repairs (e.g., to\nuh .. to Corning) through explicit grammar rules; the other is to accommodate\nmid-sentence acknowledgments (e.g., okay), editing terms (e.g., uh), etc. as\n``trailers"" attached to lexical items. We show how this works on a simple\nsample dialog. Because allowing for repairs and interruptions introduces\nmuch ambiguity, we also discuss some initial disambiguation techniques.'",0
"b""When a reinforcement learning agent's next course of action depends on\ninformation that is hidden from the sensors because of problems such\nas occlusion, restricted range, bounded field of view and limited\nattention, we say the agent suffers from the Hidden State Problem.\nState identification techniques use history information to uncover\nhidden state.  Previous approaches to encoding history include: finite\nstate machines [Chrisman 1992; McCallum 1992], recurrent neural\nnetworks [Lin and Mitchell 1992], and genetic programming with\nindexed memory [Teller 1994].  A chief disadvantage of all\nthese techniques is their long training time.\n\nThis report presents Instance-Based State Identification, a new\napproach to reinforcement learning with state identification that\nlearns with much fewer training steps.  Noting that learning with\nhistory and learning in continuous spaces both share the property that\nthey begin without knowing the granularity of the state space, the\napproach applies instance-based (or ``memory-based'') learning to\nhistory sequences---instead of recording instances in a continuous\ngeometrical space, we record instances in action-perception-reward\nsequence space. The first implementation of this approach,\ncalled Nearest Sequence Memory, learns with an order of magnitude\nfewer steps than several previous approaches.""",1
"b'In this paper we describe a recent experiment designed to evaluate the\nperformance of the TRAINS-95 system.  The evaluation uses a task-based\nevaluation methodology appropriate for dialogue systems such as TRAINS-95,\nwhere a human and a computer interact and collaborate to solve a given\nproblem. In task-based evaluations, techniques are measured in terms of\ntheir affect on task performance measures such as how long it takes to\ndevelop a solution using the system, and the quality of the final plan\nproduced. The evaluation explores the robustness of the TRAINS-95 system in\nthe presence of word recognition errors, the amount of training required\nto effectively use the system, and user preferences.'",0
"b""Table lookup with interpolation is used for many learning and adaptation\ntasks.  Redundant mappings capture the important\nconcept of ``motor skill,'' which is important in real, behaving systems.\nFew, if any, robot skill implementations have dealt with redundant\nmappings, in which the space to be searched to create the table has much\nhigher dimensionality than the table itself.  A practical method\nfor inverting redundant mappings is\nimportant in physical systems with limited time for trials.\nWe present the ``Guided Table Fill In'' algorithm, which\nuses data already stored in the table to guide  search through\nthe space of potential table entries.  The algorithm is illustrated and tested\non a robot skill learning task both in simulation and on a robot with a\nflexible link.  Our experiments show that the ability to search\nhigh dimensional action spaces efficiently allows skill learners\nto find new behaviors that are qualitatively different\nfrom what they were presented or what the system designer may have\nexpected.  Thus the use of this technique can allow researchers to seek\nhigher dimensional action spaces for their systems rather than\nconstraining their search space at the risk of excluding the best actions.""",1
"b'The web has the potential to serve as an excellent source of\nexample imagery for visual concepts.  Image search engines based on\ntext keywords can fetch thousands of images for a given query;\nhowever, their results tend to be visually noisy. We present a\ntechnique that allows a user to refine noisy search results and\ncharacterize a more precise visual object class. With a small amount\nof user intervention we are able to re-rank search engine results to\nobtain many more examples of the desired concept. Our approach is\nbased on semi-supervised machine learning in a novel probabilistic\ngraphical model composed of both generative and discriminative\nelements. Learning is achieved via a hybrid expectation maximization\n/ expected gradient procedure initialized with a small example set\ndefined by the user. We demonstrate our approach on images of musical\ninstruments collected from Google image search. The rankings given by\nour model show significant improvement with respect to the\nuser-refined query. The results are suitable for improving user\nexperience in image search applications and for collecting large\nlabeled datasets for computer vision research.'",1
"b'Planning invariants are formulae that are true in every reachable state of\na planning world.  We describe a novel approach to the problem of\ndiscovering such invariants in propositional form---by analyzing only a set\nof reachable states of the planning domain, and not its operators.  Our\nsystem works by exploiting perceived patterns of propositional covariance\nacross the set of states: It hypothesizes that strongly-defined patterns\nrepresent features of the planning world.\n\nWe demonstrate that, in practice, our system overwhelmingly produces\ncorrect invariants.  Moreover, we compare it with a well-known system from\nthe literature that uses complete operator descriptions, and show that it\ndiscovers a comparable number of invariants, and moreover, does so hundreds\nor thousands of times faster.\n\nWe also show how an existing operator-based invariant finder can be used to\nverify the correctness of the invariants we find, should operator\ninformation be available. We show that such hybrid systems can efficiently\nproduce verifiably true invariants.'",0
"b'In this report we consider the problem of 3D object recognition, and\nthe role that perceptual grouping processes must play. In particular,\nwe argue that a single level of perceptual grouping is inadequate, and\nthat reliance on a single level of grouping is responsible for the specific\nweaknesses of several well-known recognition techniques. Instead, we argue\nthat recognition must utilize a hierarchy of perceptual grouping processes,\nand describe an appearance-based system that uses four distinct levels of\nperceptual grouping, the upper two novel, to represent 3D objects in a form\nthat not only allows recognition, but reasoning about 3D manipulation\nof a sort that has been supported in the past only by 3D geometric models.'",1
"b'We describe a method of 3-D object recognition based on two stage use\nof a general purpose associative memory and a principal views representation.\nThe basic idea is to make use of semi-invariant objects called keys.\nA key is any robustly extractable feature that has sufficient information\ncontent to specify a 2-D configuration of an associated object (location,\nscale, orientation) plus sufficient additional parameters to provide\nefficient indexing and meaningful verification. The recognition system\nutilizes an associative memory organized so that access via a key feature\nevokes associated hypotheses for the identity and configuration of all\nobjects that could have produced it. These hypothesis are fed into a\nsecond stage associative memory, which maintains a probabilistic estimate\nof the likelihood of each hypothesis based on statistics about the\noccurrence of the keys in the primary database.\nBecause it is based on a merged percept of local features rather than\nglobal properties, the method is robust to occlusion and background\nclutter, and does not require prior segmentation.\nEntry of objects into the memory is an active, automatic procedure.\nWe have implemented a version of the system that allows arbitrary\ndefinitions for key features. Experiments using keys based on\nperceptual groups of line segments are reported.\nGood results were obtained on a database derived from of approximately 150\nimages representing different views of 7 polyhedral objects.'",0
"b'Bayesian approaches have been shown to reduce the amount of\noverfitting that occurs when running the EM algorithm, by placing\nprior probabilities on the model parameters. We apply one such\nBayesian technique, variational Bayes, to GIZA++, a widely-used piece\nof software that computes word alignments for statistical machine\ntranslation. We show that using variational Bayes improves the\nperformance of GIZA++, as well as improving the overall performance of\nthe Moses machine translation system in terms of BLEU score.'",0
"b'We describe a general framework for modeling transformations in the\nimage plane using a stochastic generative model. Algorithms that resemble\nthe well-known Kalman filter are derived from the MDL principle for\nestimating both the generative weights and the current transformation state.\nThe generative model is assumed to be implemented in cortical feedback\npathways while the feedforward pathways implement an approximate\ninverse model to facilitate the estimation of current state.\nUsing the above framework, we derive models for invariant\nrecognition, motion estimation, and stereopsis, and present preliminary\nsimulation results demonstrating recognition of objects in the presence of\ntranslations, rotations and scale changes.'",0
"b'Existing work in the extraction of commonsense knowledge from text\nhas been restricted to factoids that serve as statements about what may\npossibly obtain in the world. We present an approach to deriving\nstronger general claims from large sets of factoids. The idea is to\ncoalesce the observed nominals for a given predicate argument into a\nfew predominant types, obtained as WordNet synsets. The results can be\nconstrued as generically quanti\xc3\xaf\xc2\xac\xc2\x81ed sentences restricting the semantic\ntype of an argument position of a predicate.'",0
"b'For many election systems, bribery (and related) attacks have been\nshown NP-hard using constructions on combinatorially rich structures\nsuch as partitions and covers. It is important to learn how robust\nthese hardness protection results are, in order to find whether they\ncan be relied on in practice. This paper shows that for voters who\nfollow the most central political-science model of electorates---single-peaked preferences---those protections vanish. By using single-peaked preferences to simplify combinatorial covering challenges, we for the first time show that NP-hard bribery problems---including those for Kemeny and Llull elections---fall to\npolynomial time for single-peaked electorates.  By using single-peaked preferences to simplify combinatorial partition challenges, we for the first time show that NP-hard partition-of-voters problems fall to polynomial time for\nsingle-peaked electorates.  We show that for single-peaked\nelectorates, the winner problems for Dodgson and Kemeny elections,\nthough \\Theta_2^p-complete in the general case, fall to polynomial\ntime.  And we completely classify the complexity of weighted\ncoalition manipulation for scoring protocols in single-peaked\nelectorates.'",3
"b'We study the concept of bribery in the situation where voters are\nwilling to change their votes as we ask them, but where their prices\ndepend on the nature of the change we request. Our model is an\nextension of the one of Faliszewski et  al. [FHH06], where each voter\nhas a single price for any change we may ask for.  We show polynomial-time\nalgorithms for our version of bribery for a broad range of voting\nprotocols, including plurality, veto, approval, and utility based\nvoting. In addition to our polynomial-time algorithms we provide\nNP-completeness results for a couple of our nonuniform bribery\nproblems for weighted voters, and a couple of approximation\nalgorithms for NP-complete bribery problems defined\nin [FHH06] (in particular, an FPTAS for plurality-weighted-$bribery problem).'",3
"b'Early implementations of software transactional memory (STM) assumed\nthat sharable data would be accessed only within transactions. Memory\nmay appear inconsistent in programs that violate this assumption, even\nwhen program logic would seem to make extra-transactional accesses\nsafe.  Designing STM systems that avoid such inconsistency has been dubbed the\nprivatization problem. We argue that privatization comprises a pair of\nsymmetric subproblems: private operations may fail to see updates made\nby transactions that have committed but not yet completed; conversely,\ntransactions that are doomed but have not yet aborted may see updates made by\nprivate code, causing them to perform erroneous, externally visible\noperations. We explain how these problems arise in different styles of \nSTM, present strategies to address them, and discuss their\nimplementation tradeoffs. We also propose a taxonomy of contracts\nbetween the system and the user, analogous to programmer-centric memory con- \nsistency models, which allow us to classify programs based on their\nprivatization requirements. Finally, we present empirical comparisons\nof several privatization strategies. Our results suggest that the best \nstrategy may depend on application characteristics'",2
"b'An investigation of the referring behavior of personal and demonstrative\npronouns in two corpora: a collection of problem-solving dialogs from the\nTRAINS93 corpus and prepared news stories from the Boston University Radio\nCorpus. Unlike most studies of pronominal reference, which limit themselves\nto pronouns that co-specify the meaning of another noun phrase (called\ncoreference annotation), this study has a wider scope and includes all\npronouns in the discourse. As a result, a broader characterization is\npossible for the pronouns in question. This study shows that current\nmodels of pronoun resolution that assume each pronoun to have a nominal\nantecedent are of limited utility when applied to spontaneous language.'",0
"b'The clustering problem has been widely studied since it arises in many\napplication domains in engineering, business and social science.\nIt aims at identifying the distribution of patterns and intrinsic\ncorrelations in large data sets by partitioning the data points into\nsimilarity clusters. Traditional clustering algorithms use distance\nfunctions to measure similarity and are not suitable for high dimensional\nspaces.  In this paper, we propose a non-distance based clustering\nalgorithm for high dimensional spaces. Based on the maximum likelihood\nprinciple, the algorithm is to optimize parameters to maximize the\nlikelihood between data points and the model generated by the parameters.\nExperimental results on both synthetic data sets and a real data set\nshow the efficiency and effectiveness of the algorithm.'",0
"b'We describe a parser that draws from both extant corpora and\nlinguistic knowledge sources, and thus is suitable as a front end for\napplications requiring both broad coverage and rich syntactic analysis.\nWe detail many of the difficulties and assumptions involved in combining\nthese data and knowledge sources.  We also describe the novel language\nmodel that we use for disambiguation and show that it outperforms\na comparable model without the same knowledge sources.'",0
"b'In many domains, the task can be decomposed into a set of independent\nsub-goals.  Often, such tasks are too complex to be learned using\nstandard techniques such as Reinforcement Learning.  The complexity is\ncaused by the learning system having to keep track of the status of all\nsub-goals concurrently.  Thus, if the solution to one sub-goal is known\nwhen another sub-goal is in some given state, the known solution must be\nrelearned when the status of the other sub-goal changes.\n\nThis dissertation presents a modular approach to reinforcement\nlearning that takes advantage of task decomposition to avoid\nunnecessary relearning. In the modular approach, modules are created\nto learn each sub-goal. Each module receives only those inputs\nrelevant to its associated sub-goal, and can therefore learn without\nbeing affected by the state of other sub-goals.  Furthermore, each\nmodule searches a much smaller space than that defined by all inputs\nconsidered together, thereby greatly reducing learning time.  Since\neach module learns how to achieve a separate sub-goal, at any given\ntime it may recommend an action different from that recommended by\nother modules.  To select an action that best satisfies as many of the\nmodules as possible, a simple arbitration strategy is used.  One such\nstrategy, explored in this dissertation, is called {\\em greatest\nmass\\/} which simply combines action utilities from all modules and\nselects the one with the largest combined utility.\n\nSince the modular approach limits and separates information given to the\nmodules, the solution learned must necessarily differ from that learned\nby a standard, non-modular approach.  However, experiments in a simple\ndriving world indicate that while sub-optimal, the solution learned by\nthe modular system only makes minor errors when compared with that\nlearned by the standard approach.  A complex task can thus be learned\nvery quickly, using only small amounts of computational resources, with\nonly small sacrifices in solution quality, using the modular approach.'",0
"b'Much work has been devoted, during the past twenty years, to using\ncomplexity to protect elections from manipulation and control.  Many\nresults have been obtained showing NP-hardness shields, and recently\nthere has been much focus on whether such worst-case hardness\nprotections can be bypassed by frequently correct heuristics or by\napproximations.  This paper takes a very different approach: We argue\nthat when electorates follow the canonical political science model of\nsocietal preferences the complexity shield never existed in the first\nplace.  In particular, we show that for electorates having\nsingle-peaked preferences, many existing NP-hardness results on\nmanipulation and control evaporate.'",3
"b""One of the biggest challenges in systems neuroscience is\na satisfactory model of neural signaling. From rate coding to temporal\ncoding, models of neural signaling have been challenged by the fact\nthat neurons fire highly irregularly. A typical interpretation of the\nvariability is ``noise other than signal'', which not only has difficulty\naccounting for the speed, accuracy, efficiency and complexity of\nbiological systems, but is also contradicted by recent studies that\nshow both spike generation and transmission are highly reliable.\n\nChallenged with the discrepancy between theory and data, we take a\nfresh view of the subject with the proposal that the randomness\nassociated with neuronal outputs is certain to have a purpose. In\nparticular, we model neurons as probabilistic devices that not only\ncompute probabilities but also fire probabilistically to signal their\ncomputations. According to our model, signaling of probabilities is\ndone by having cells with similar receptive fields fire synchronously\nto achieve fast communication, this is consistent with observations of\nneurons coding as ensembles and topographic map organization. Our\nproposal of probabilistic, distributed synchronous volleys as a neural\nsignaling strategy not only accounts for variable neural responses,\nbut also provides the advantage of robust and fast computation.\nFurthermore, the involvements of probabilistic firing and distributed\ncoding explicate how synchronous firing can appear to be a rate code,\naccounting for the vast amount of data supporting a rate code assumption.\n\nAny neural signaling model must support cortical computation\nin a biologically realistic fashion. Going beyond simply addressing the\nrole of spikes in cortical cells' communication, we show that our\ndistributed synchrony model can be implemented in a predictive coding\nframework and can be used to learn structures in the natural environment.\nTrained with patches from natural images, our model V1 cells develop\nlocalized and oriented receptive fields, consistent with V1 simple\ncell properties. Unlike most cortical computation models, our predictive\ncoding model makes use of single spikes, instead of abstracting spikes\naway with analog quantities. This close resemblance to biology\nmakes our model well suited for guiding experimental research.""",1
"b'Factoring a Synchronous Context-Free Grammar into an equivalent\ngrammar with a smaller number of nonterminals in each rule\nenables more efficient strategies for synchronous parsing.\nWe present an algorithm for factoring an n-ary SCFG into a\nk-ary grammar in time O(kn). We also show how to efficiently\ncompute the exact number of k-ary parsable permutations\nof length n, and discuss asymptotic behavior as n grows.\nThe number of length n permutations that are k-ary parsable\napproaches a fixed ratio between successive terms as n grows\nfor fixed k. As k grows, the difference between successive ratios\napproaches 1/e.'",0
"b'Memory hardware reliability is an indispensable part of whole-system\ndependability.  Its importance is evidenced by a plethora of prior \nresearch work studying the impact of memory errors on software systems.\nHowever, the absence of solid understanding of the error characteristics\nprevents software system researchers from making well reasoned \nassumptions, and it also hinders the careful evaluations over\ndifferent choices of fault tolerance design.  In this paper, we present our \nrealistic memory hardware error traces collected from production \ncomputer systems with more than 800GB memory for around nine months.\nBased on the traces (including detailed information on the error\naddresses and patterns), we explore the implications of different \nhardware ECC protection schemes so as to identify the most common\nerror causes and approximate error rates exposed to the software level.\nLastly, we investigate the software system susceptibility to some\nmajor error causes, with the particular goal to validate, question, and \naugment results of prior system studies.'",2
"b'Semantic scene classification, categorizing images into one of a set of \nphysical (e.g., indoor/outdoor, orientation) or semantic categories (e.g., \nbeach or party), is a relatively new field. Most of the existing \ntechniques used primarily low-level features to classify scenes and \nachieved some success on constrained problems.  We report on the state of \nthe art, presenting summaries of major scene classification systems and \nidentifying the features and inference engines they use.'",1
"b'We lay out the plans for a series of psychophysics experiments on human\nshadow perceptions.  The Peg in Hole experiments are to find out\nwhether shadows play a role in human 3D perception and how important the\nrole is, compared with other depth cues such as stereoscopy.  We also\ndesign quantitative experiments to extract the psychometric curves for\nshadow perception versus various characteristics of scene geometry. \nThe curves will help us to decide different thresholds for our scene\nreconstruction algorithms.  Some background of psychophysics is included\nfor future reference.  Expected outputs of the experiments are described. \nSome implementation details are also discussed.'",1
"b'The receptive fields of neurons in the mammalian primary visual cortex\nare oriented not only in the domain of space, but in most cases, also in\nthe domain of space-time. While the orientation of a receptive field\nin space determines the selectivity of the neuron to image structures\nat a particular orientation, a receptive fieldUs orientation in space-time\ncharacterizes important additional properties such as velocity and\ndirection selectivity. Previous studies have focused on explaining the\nspatial receptive field properties of visual neurons by relating them\nto the statistical structure of static natural images. In this report,\nwe examine the possibility that the distinctive spatiotemporal properties\nof visual cortical neurons can be understood in terms of a statistically\nefficient strategy for encoding natural time varying images.\nWe describe an artificial neural network that attempts to accurately\nreconstruct its spatiotemporal input data while simultaneously reducing\nthe statistical dependencies between its outputs. The network utilizes\nspatiotemporally summating neurons and learns efficient sparse distributed\nrepresentations of its spatiotemporal input stream by using recurrent\nlateral inhibition and a simple threshold nonlinearity for rectification\nof neural responses. When exposed to natural time varying images,\nneurons in a simulated network developed localized receptive fields\noriented in both space and space-time, similar to the receptive fields\nof neurons in the primary visual cortex.'",0
"b'Since scalp EEG recordings are measured in microvolts, electrical\nsignals may easily interfere during an experiment. As Spehlmann discusses,\nsuch interference may be introduced through the lights in the recording room,\na nearby television, or even a computer monitor [Spehlmann, 1991]. Thus,\nwhen we consider performing EEG/EP/ERP experiments within a virtual reality\nhelmet containing an eye tracker, electrical interference becomes a real\npossibility. We tested the effects of wearing a VR4 virtual reality (VR)\nhelmet containing an ISCAN eye tracker while asking subjects to do a\ncontinuous performance task. The results of this task were then analyzed\nin the frequency domain and compared to results from the same experiment\nwhile looking at a computer screen in two different environments.\nResults indicate that in an environment with other computers, the vertical\nrefresh from the back of a nearby row of computer monitors added more noise\nto the signal than wearing the VR helmet and eye tracker. Even in an\nenvironment without other computers, the noise while wearing the VR helmet\nand eye tracker is not significantly different from the noise obtained\nwhile viewing a laptop computer screen in the same location.'",1
"b'This paper describes a prototype disambiguation module, KANKEI, which uses\ntwo corpora of the TRAINS project.  In ambiguous verb phrases of form\nV...NP PP or V...NP adverb(s), the two corpora have very different PP and\nadverb attachment patterns; in the first, the correct attachment is to the\nVP 88.7\\% of the time, while in the second, the correct attachment is to\nthe NP 73.5\\% of the time.  KANKEI uses various n-gram patterns of the\nphrase heads around these ambiguities, and assigns parse trees (with these\nambiguities) a score based on a linear combination of the frequencies with\nwhich these patterns appear with NP and VP attachments in the TRAINS\ncorpora.  Unlike previous statistical disambiguation systems, this technique\nthus combines evidence from bigrams, trigrams, and the 4-gram around an\nambiguous attachment.  In the current experiments, equal weights are used\nfor simplicity but results are still good on the TRAINS corpora (92.2\\% and\n92.4\\% accuracy).  Despite the large statistical differences in attachment\npreferences in the two corpora, training on the first corpus and testing\non the second gives an accuracy of 90.9\\%.  These results suggest that our\ntechnique captures attachment patterns that are useful across corpora.'",0
"b'The recognition of nonrigid motion, particularly that arising from\nhuman movement (and by extension from the locomotory activity of animals)\nhas typically made use of high-level parametric models representing the\nvarious body parts (legs, arms, trunk, head, etc.) and their connections\nto each other. Such model-based recognition has been successful in some cases;\nhowever, the methods are often difficult to apply to real-world scenes,\nand are severely limited in their generalizability.\nThe first problem arises from the difficulty of acquiring and tracking the\nrequisite model parts, usually specific joints such as knees, elbows\nor ankles. This generally requires some prior high-level understanding\nand segmentation of the scene, or initialization by a human operator.\nThe second problem is due to the fact that the human model is not\nmuch good for dogs or birds; for each new type of motion, a new model\nmust be hand-crafted. In this paper, we show that the recognition of\nhuman or animal locomotion, and, in fact, any repetitive activity, can\nbe done using low-level, non-parametric representations.\nSuch an approach has the advantage that the same underlying representation\nis used for all examples, and no individual tailoring of models or prior\nscene understanding is required. We show in particular that repetitive\nmotion is such a strong cue that the moving actor can be segmented,\nnormalized spatially and temporally, and recognized by matching against\na spatio-temporal template of motion features.\nWe have implemented a real-time system that can recognize and classify\nrepetitive motion activities in normal gray-scale image sequences.\nResults on a number of real-world sequences are described.'",1
"b'Our goal is to isolate and ultimately identify objects in\ncluttered and possibly partially-obscuring background environments.\nMultiple images (usually six in our case) of a scene, including\nat least five flash images with different flash locations,\nlocate depth edges in the scene. Morphological processing turns\nthe collection of edges into a collection of regions. These regions\nare candidates for non-background status, and can be compared by\ncolor and shape analysis to background regions. Further, we think the\nedges, labeled with depth and color information, will provide a\nricher and more reliable set of inputs to an object recognizer\nlike that of Nelson and Selinger, which so far has only had\nintensity edges to work with.'",1
"b'A king in a directed graph is a vertex from which each vertex in\nthe graph can be reached via paths of length at most two.  There is a\nbroad literature on tournaments (completely oriented digraphs), and it\nhas been known for more than half a century that all tournaments have\nat least one king [Lan53].  Recently, kings have proven useful in\ntheoretical computer science, in particular in the study of the\ncomplexity of reachability problems [NT05] and semifeasible sets\n[HNP98, HT06, HOZZ06].\n\nIn this paper, we study the complexity of recognizing kings.  For each\nsuccinctly specified family of tournaments, the king problem is\nalready known to belong to $\\Pi_2^{\\mathrm p}$ [HOZZ06].  We prove\nthat the complexity of kingship problems is a rich enough vocabulary\nto pinpoint every nontrivial many-one degree in $\\Pi_2^{\\mathrm p}$.\nThat is, we show that \\emph{every} set in $\\Pi_2^{\\mathrm p}$ other\nthan $\\emptyset$ and $\\Sigma^*$ is equivalent to a king problem under\n$\\leq_{\\mathrm m}^{\\mathrm p}$-reductions.  Indeed, we show that the\nequivalence can even be instantiated via relatively simple padding,\nand holds even if the notion of kings is redefined to refer to\n$k$-kings (for any fixed $k \\geq 2$)---vertices from which the all\nvertices can be reached via paths of length at most $k$.  In contrast,\nwe prove that recognizing whether a given vertex is a source (i.e.,\nthere exists a $k$ such that it is a $k$-king) yields languages that\nalso fall within $\\Pi_2^{\\mathrm p}$, yet cannot be $\\Pi_2^{\\mathrm\np}$-complete---or even $\\Class{NP}$-hard---unless $\\Class{P} =\n\\Class{NP}$.\n\nUsing these and related techniques, we obtain a broad range of\nadditional results about the complexity of king problems, diameter\nproblems, and radius problems.  It follows easily from our proof\napproach that the problem of testing kingship in succinctly specified\ngraphs (which need not be tournaments) is $\\Pi_2^{\\mathrm\np}$-complete.  We show that the radius problem for arbitrary\nsuccinctly represented graphs is $\\Sigma_3^{\\mathrm p}$-complete, but\nthat in contrast the diameter problem for arbitrary succinctly\nrepresented graphs (or even tournaments) is $\\Pi_2^{\\mathrm\np}$-complete.'",3
"b""This paper is concerned with the computational aspects of approval\nvoting and some of its variants, with a particular focus on the\ncomplexity of problems that model various ways of tampering with the\noutcome of an election: manipulation, control, and bribery.  For\nexample, in control settings, the election's chair seeks to alter the\noutcome of an election via control actions such as\nadding/deleting/partitioning either candidates or voters. In\nparticular, sincere-strategy preference-based approval voting (SP-AV),\na variant of approval voting proposed by Brams and Sanver [BS06], is\ncomputationally resistant to 19 of the 22 common types of control.\nThus, among those natural voting systems for which winner\ndetermination is easy, SP-AV is the system currently known to display\nthe broadest resistance to control.  We also present the known\ncomplexity results for various types of bribery.  Finally, we study\nlocal search heuristics for minimax approval voting, a variant of\napproval voting proposed by Brams, Kilgour, and Sanver [BKS04] (see\nalso [BKS07a,BKS07b]) for the purpose of electing a committee of fixed\nsize.""",3
"b""We present an approach for building an affine representation of an\nunknown curved object viewed under orthographic projection from images of\nits occluding contour. It is based on the observation that the projection\nof a point on a curved, featureless surface can be computed along a special\nviewing direction that {\\em does not} belong to the point's tangent plane.\nWe show that by circumnavigating the object on the tangent plane of\nselected surface points, we can (1) compute two orthogonal projections of\nevery point projecting to the occluding contour during this motion, and\n(2) compute the affine coordinates of these points. Our approach demonstrates\nthat affine shape of curved objects can be computed {\\em directly}, i.e.,\nwithout Euclidean calibration or image velocity and acceleration measurements.""",1
"b'Reasoning about temporal information is an important task in many\nareas of Artificial Intelligence.  In this paper we address the\nproblem of scalability in temporal reasoning by providing a collection\nof new algorithms for efficiently managing large sets of qualitative\ntemporal relations.  We focus on the class of relations forming the\nPoint Algebra (PA-relations) and on a major extension to include\nbinary disjunctions of PA-relations (PA-disjunctions). Such\ndisjunctions add a great deal of expressive power, including the\nability to stipulate disjointness of temporal intervals, which is\nimportant in planning applications.\n\nOur representation of time is based on timegraphs, graphs\npartitioned into a set of chains on which the search is supported by a\nmetagraph data structure. The approach is an extension of the time\nrepresentation proposed by Schubert, Taugher and Miller in the context\nof story comprehension.  The algorithms herein enable construction of\na timegraph from a given set of PA-relations, querying a timegraph,\nand efficiently checking the consistency of a timegraph augmented by a\nset of PA-disjunctions.  Experimental results illustrate the\nefficiency of the proposed approach.'",0
"b""Domain-independent planning is a notoriously hard search problem.\nSeveral systematic search techniques have been proposed in the context of\nvarious formalisms. However, despite their theoretical completeness,\nin practice these algorithms are incomplete because for many problems\nthe search space is too large to be (even partially) explored, and a plan\ncannot be found in reasonable time (if one exists).\nIn this paper we propose a new search method in the context of\nBlum and Furst's planning graph approach, which is based on local search.\nLocal search techniques are incomplete, but in practice they can\nefficiently solve problems that are unsolvable for current systematic\nsearch methods. We introduce three particular heuristics to guide\nthe local search (Walkplan, Tabuplan and T-Walkplan), and we propose\ntwo methods for combining local and systematic search.\nOur techniques are implemented in a system called GPG, which can be used\nfor both plan-generation and plan-adaptation tasks.\nExperimental results show that GPG can efficiently solve problems\nthat are very hard for the systematic search of IPP and Graphplan,\nincluding Kautz and Selman's Logistics-d.""",0
"b""We describe and demonstrate a construct termed a ``virtual tool''\nthat provides a flexible interface to sensory-motor control.\nThis interface is, from a user standpoint, substantially less complex\nand more application-oriented than the raw devices.\nThe basic idea is to use extra degrees of freedom present in a flexible system,\nin conjunction with sophisticated sensing (e.g. vision),\nto dynamically configure or ``tailor'' a manipulator so that it is\nmatched to a particular situation and operation.\nThis ``virtual tool'' is created by imposing customized,\nsensory modulated constraints between various degrees of freedom in the system.\nThe remaining degrees of freedom constitute a small set of control\nparameters that are fitted to a particular operation.\nWe argue that, within the confines of fairly broad application domains,\na small set of ``tool classes'' can be defined that will serve as a\ngeneral purpose sensory-motor toolbox for a wide variety of applications.\nWe further argue that such class definitions can be made portable\nnot only across tasks, but across platforms as well.\nThe implementation of a number of basic tool classes, on various platforms,\nusing vision and other sensory modalities, is described, and their use in\nperforming multi-stage sensory-modulated manipulation tasks is illustrated.""",1
"b'Previous work by Talbot and Osborne (2007a) explored the use of\nrandomized storage mechanisms in language modeling. These structures\n%trade a small amount of error for significant space savings,\nenabling the use of larger language models on relatively modest\nhardware.\n\nGoing beyond space efficient count storage, here we present the\nTransition Counter, an extended model for performing space efficient\ncounting over streams of \xc3\xaf\xc2\xac\xc2\x81nite length. Theoretical and initial\nexperimental results show the promise of approximate counting in the\ncontext of limited space.'",0
b'In this report we describe a method for extracting curves from an image\nusing directional pixel variances instead of gradient measures as low-level\nboundary evidence. The advantage of the variance over the image gradient\nis that we can accurately compute the direction of a local edge even if\na sudden contrast change occurs in the background. This allows curves\nbelonging to object contours to be followed more easily. We compared our\nmethod to a similar method based on the image gradient and we found that\nit obtains better results when run on synthetic and natural images.\nOur method also improved the performance of a contour-based 3D object\nrecognition system in cluttered images.',1
"b""This report compares two formalisms for uncertain inference,\ncombinatorial semantics and Dempster-Shafer belief function theory,\non the basis of an example from the domain of medical diagnosis. \nWe review Shafer's example about the imaginary disease ploxoma\nand show how it would be represented in combinatorial semantics.\nWe conclude that belief function theory has a qualitative advantage\nbecause it offers greater flexibility of expression\nand provides results about more specific classes of patients.\nNevertheless, a quantitative comparison reveals that the inferences\nsanctioned by combinatorial semantics are\nmore reliable than those of belief function theory.""",0
"b'The Conservation Laboratory of the George Eastman House\nInternational Museum of Photography and Film (GEH) and the Department\nof Computer Science at the University of Rochester (URCS) are\ncollaborating on the problems of preservation and access to daguerreotypes.\nParallel (cluster) computation provides high speed image processing to\nfind, classify, and ultimately to eliminate defects and artifacts of\ndeterioration. This TR describes early low-level techniques and applies them to\nscanner lighting,  dust, and scratch defects.'",1
"b""We prove that every distributional problem solvable in polynomial\ntime on the average with respect to the uniform distribution has a\nfrequently self-knowingly correct polynomial-time algorithm.  We also\nstudy some features of probability weight of correctness with respect\nto generalizations of Procaccia and Rosenschein's junta\ndistributions [PR07b].""",3
"b'Using entropy of traffic distributions has been shown to aid\na wide variety of network monitoring applications such as anomaly\ndetection, clustering to reveal interesting patterns, and traffic\nclassification. However, realizing this potential benefit in practice\nrequires accurate algorithms that can operate on high-speed links,\nwith low CPU and memory requirements. Estimating the entropy in a\nstreaming model to enable such fine-grained traffic analysis has been\na challenging problem. We give lower bounds for this problem,\nshowing that neither approximation nor randomization alone will\nlet us compute the entropy efficiently.\n\nWe present two algorithms for randomly approximating the entropy\nin a time and space efficient manner, applicable for use on\nvery high speed (greater than OC-48) links. Our first algorithm for\nentropy estimation, inspired by the seminal work of Alon et al. for\nestimating frequency moments, has strong theoretical guarantees on\nthe error and resource usage. Our second algorithm utilizes the\nobservation that the efficiency can be substantially enhanced by\nseparating the high-frequency items (or elephants), from the\nlow-frequency items (or mice). Evaluations on real-world traffic\ntraces from different deployment scenarios demonstrate the utility\nof our approaches.'",3
"b'Shadows provide valuable information about the scene geometry, especially\nthe whereabout of the light source.  This paper investigates the geometry of\npoint light sources and cast shadows.  It is known that there is redundancy\nin the object-shadow correspondences.  We explicitly show that no matter\nhow many such correspondences are available, it is impossible to locate a\npoint light source from shadows with a single view.  We discuss the\nsimilarity between a point light source and a conventional pinhole camera\nand show that the above conclusion is in accordance to traditional camera\nself calibration theory.  With more views, however, the light source can be\nlocated by triangulation.  We proceed to solve the problem of establishing\ncorrespondences between the images of an object with extended size and\nits cast shadow. We prove that a supporting line, which, put\nsimply, is a tangent line of the image regions of the object and its\nshadow, provides one correspondence.  We give an efficient algorithm to\nfind supporting lines and prove that at most two supporting lines can be\nfound.  The intersection of these two lines gives the direction\nof the point light source.  All this can be done without any knowledge\nof the object. Experiment results using real images are shown.'",1
"b""We study the complexity of the following problem: Given two\nweighted voting games G' and G'' that each contain a player p, in\nwhich of these games is p's power index value higher? We study this\nproblem with respect to both the Shapley-Shubik power index [SS54]\nand the Banzhaf power index [Ban65,DS79]. Our main result is that for\nboth of these power indices the problem is complete for probabilistic\npolynomial time (i.e., is $\\pp$-complete). We apply our results to\npartially resolve some recently proposed problems regarding the\ncomplexity of weighted voting games. We also study the complexity of\nthe raw Shapley-Shubik power index. Deng and Papadimitriou [DP94]\nshowed that the raw Shapley-Shubik power index is #P-metric-complete.\nWe strengthen this by showing that the raw Shapley-Shubik power index\nis many-one complete for #P. And our strengthening cannot possibly be further\nimproved to parsimonious completeness, since we observe that, in\ncontrast with the raw Banzhaf power index, the raw Shapley-Shubik\npower index is not #P-parsimonious-complete.""",3
"b'The responses of visual cortical neurons during\nfixation tasks can be significantly modulated by stimuli from beyond\nthe classical receptive field.  Modulatory effects in neural\nresponses have also been recently reported in a task where a monkey\nfreely views a natural scene. In this paper, we describe a\nhierarchical network model of visual recognition that explains these\nexperimental observations by using a form of the extended Kalman\nfilter as given by the Minimum Description Length (MDL) principle.\nThe model dynamically combines input-driven bottom-up signals with\nexpectation-driven top-down signals to predict current recognition\nstate.  Synaptic weights in the model are adapted in a Hebbian\nmanner according to a learning rule also derived from the MDL\nprinciple. The resulting prediction/learning scheme can be viewed as\nimplementing a form of the Expectation-Maximization (EM) algorithm.\nThe architecture of the model posits an active computational role\nfor the reciprocal connections between adjoining visual cortical\nareas in determining neural response properties.  In particular, the\nmodel demonstrates the possible role of feedback from higher cortical\nareas in mediating neurophysiological effects due to stimuli from\nbeyond the classical receptive field.  Simulations of the model are\nprovided that help explain the experimental observations regarding\nneural responses in both free viewing and fixating conditions.'",0
"b'In this report we describe an experiment designed to:\nevaluate the performance of the TRAINS-96 system as a whole;\nexamine the utility of a new robust post-parser module, recently\nadded to the TRAINS system; and explore the benefit to the user of\nreceiving system feedback on speech input.\nThe evaluation uses the same task-based methodology as was used for\nthe TRAINS-95 evaluation [Sikorski and Allen 96], in which the user and\ncomputer cooperatively solve a given problem.  Success is measured in\nterms of task performance measures such as time to completion of a\ntask, and the quality of the final plan produced.'",0
"b'A king in a directed graph is a node from which each node in the graph\ncan be reached via paths of length at most two.  There is a broad\nliterature on tournaments (completely oriented digraphs), and it has\nbeen known for more than half a century that all tournaments have at\nleast one king [Lan53].  Recently, kings have proven useful in\ntheoretical computer science, in particular in the study of the\ncomplexity of the semifeasible sets [HNP98,HT05] and in the study of\nthe complexity of reachability problems [Tan01,NT02].\n\nIn this paper, we study the complexity of recognizing kings.  For each\nsuccinctly specified family of tournaments, the king problem is known\nto belong to $\\Pi_2^p$ [HOZZ].  We prove that this bound is optimal:\nWe construct a succinctly specified tournament family whose king\nproblem is $\\Pi_2^p$-complete.  It follows easily from our proof\napproach that the problem of testing kingship in succinctly specified\ngraphs (which need not be tournaments) is $\\Pi_2^p$-complete.  We also\nobtain $\\Pi_2^p$-completeness results for k-kings in succinctly\nspecified j-partite tournaments, $k,j \\geq 2$, and we generalize our\nmain construction to show that $\\Pi_2^p$-completeness holds for\ntesting k-kingship in succinctly specified families of tournaments for\nall $k \\geq 2$.'",3
"b'When one works with a system that utilizes inheritance hierarchies the\nfollowing problem often arises.  A new object is introduced and it\nmust be integrated into a hierarchy; under which classes in the\nhierarchy should the new object be positioned?  In this paper, I\nformalize this problem for feature-based default inheritance\nhierarchies.  Since it turns out to be NP-complete, I present an\napproximation algorithm for it.  I show that this algorithm is\nefficient and look at some of the possible problematic situations for\nthe algorithm.  Although more analysis and experimentation are needed,\nthese preliminary results show that the algorithm warrants such efforts.'",0
"b'The process of adding to the common ground between conversational\nparticipants (called grounding) has previously been either\noversimplified or studied in an off-line manner. This dissertation\npresents a computational theory, in which a protocol is\npresented which can be used to determine, for any given state of the\nconversation, whether material has been grounded or what it would take\nto ground the material. This protocol is related to the mental states\nof participating agents, showing the motivations for performing\nparticular grounding acts and what their effects will be.\n\nWe extend speech act theory to account for levels of action both above\nand below the sentence level, including the level of grounding acts\ndescribed above. Traditional illocutionary acts are now seen to be\nmulti-agent acts which must be grounded to have their usual effects.\n\nA conversational agent model is provided, showing how grounding fits in\nnaturally with the other functions that an agent must perform\nin engaging in conversation. These ideas are implemented within the\nTRAINS conversation system.\n\nAlso presented is a situation-theoretic model of plan execution\nrelations, giving definitions of what it means for an action to begin,\ncontinue, complete, or repair the execution of a plan. This framework\nis then used to provide precise definitions of the grounding acts in\nterms of agents executing a general communication plan in which\none agent must present the content and another acknowledge it.'",0
"b'Based on the observation that the unpredictable nature of\nconversational speech makes it almost impossible to reliably\nmodel sequential word constraints, the notion of\n{\\em word set error criteria} is proposed for improved recognition\nof spontaneous dialogues. The single pass Adaptive Boosting (AB)\nalgorithm enables the language model weights to be tuned using the\n{\\em word set error} criteria. In the two pass version of the\nalgorithm, the basic idea is to predict a {\\em set} of words\nbased on some {\\em a priori} information, and perform a re-scoring\npass wherein the probabilities of the words in the predicted word set\nare amplified or {\\em boosted} in some manner. An adaptive\ngradient descent procedure for tuning the {\\em word boosting}\nfactor has been formulated which enables the boost factors to be\nincrementally adjusted to maximize accuracy of the speech recognition\nsystem outputs on held-out training data using the word set error\ncriteria. Two novel models which predict the required word sets\nhave been presented: {\\em utterance triggers} which capture\nwithin-utterance long-distance word inter-dependencies, and\n{\\em dialogue triggers} which capture local temporal\ndialogue-oriented word relations. The proposed Trigger and\nAdaptive Boosting (TAB) algorithm, and the single pass\nAdaptive Boosting (AB) algorithm  have been experimentally tested\non a subset of the TRAINS-93 spontaneous dialogues and the TRAINS-95\nsemi-spontaneous corpus, and have resulted in improved performances.'",0
"b'This thesis describes research which attempts to remove some of\nthe barriers to creating true conversational agents---autonomous agents\nwhich can communicate with humans in natural language. First,\nin order to help bridge the gap between research in\nthe natural language and agents communities, we define a model of\nagent-agent collaborative problem solving which formalizes agent\ncommunication at the granularity of human communication. We then\naugment the model to define an agent-based model of dialogue, which\nis able to describe a much wider range of dialogue phenomena than\nplan-based models. The model also defines a declarative representation\nof communicative intentions for individual utterances.\n\nRecognition of these intentions from utterances will require\nan augmentation of already intractable plan and intention recognition\nalgorithms. The second half of the thesis describes research in\napplying statistical corpus-based methods to goal recognition,\na special case of plan recognition.\n\nBecause of the paucity of data in the plan recognition community,\nwe have generated two corpora in distinct domains. We also define\nan algorithm which can stochastically generate artificial corpora\nto be used in learning. We then describe and evaluate fast statistical\nalgorithms for both flat and hierarchical recognition of goal schemas and\ntheir parameter values. The recognition algorithms are more scalable\nthan previous work and are able to recognize goal parameter values\nas well as schemas.'",0
"b'Reasoning about semantic classes and determining compatibility\nof the words in a given context is an important procedure used in many\nmodules of natural language understanding systems. However, most existing\nsystems do not devote much attention to their ontological knowledge\nrepresentations, resulting in implementations that are not portable to\nother domains.  At the same time, statistical methods are more robust\nand less labor-intensive to develop, but typically result in models that\nare not easily interpretable by humans.  We propose a semantic feature\nrepresentation for use in practical dialogue systems and argue that it\ncan offer advantages in terms of lexicon development and portability---in\nparticular for defining selectional restrictions---and can also be useful\nfor other system modules that do logical inference.  We then propose to\ndevelop statistical methods allowing us to learn parts of our representation\nfrom corpus data.'",0
"b""Image-based object recognition systems developed recently don't require\nthe construction of a 3D geometric model, allowing recognition of objects\nfor which current geometric recognition technologies do not apply.\nSuch systems are typically trained with labeled, clean views that cover\nthe whole viewing sphere and can sometimes handle generic, visually similar\nclasses with moderate variation.  It has been little explored whether\nsuch systems can be trained from imagery that is unlabeled, and whether\nthey can be trained from imagery that is not trivially segmentable.\n\nIn this report we investigate how an object recognition system developed\npreviously can be trained from clean images of objects with minimal\nsupervision. After training this system on a single or a small number of\nviews of each object, a simple learning algorithm is able to attract\nadditional views to the object representation, building clusters of views\nbelonging to the same object. We explore how the learning performance\nimproves by extending the set of views, introducing a small amount of\nsupervision, or using more complicated learning algorithms.""",1
"b'Software Transactional Memory (STM) systems, if they support\ncondition synchronization, typically do so through a retry mechanism.  Using\nretry, a transaction explicitly self aborts and deschedules itself when it\ndiscovers that a precondition for its operation does not hold.  The underlying\nimplementation may then track the set of locations read by the\nretrying transaction, and refrain from scheduling the transaction for\nre-execution until at least one location in the set has been modified\nby another transaction.\n\nWhile retry is elegant and simple, the conventional implementation has\nseveral potential drawbacks that may limit both its efficiency and its\ngenerality.  In this note, we present a retry mechanism based on Bloom\nfilters that is entirely orthogonal to TM implementation.  Our retry\nis compatible with hardware, software, and hybrid TM implementations,\nand has no impact on memory management or on the cache behavior of\nshared locations.  It does, however, serialize writer transactions\nafter their commit point when there are retrying transactions. We\ndescribe our mechanism and compare it to an optimized version\nof the conventional implementation.'",2
"b""There are four major dialog-specific challenges in processing\nnatural language: 1) determining an utteranceUs speech act,\n2) finding utterance boundaries, 3) allowing for the possibility that\nspeakers may continue each other's utterances and interrupt each other,\nand 4) handling speech repairs and editing terms (uh, I mean).\nWe worked with the Multiparty Discourse Group to develop the Backward-\nand Forward-Looking annotation scheme that unlike many current speech act\ntaxonomies allows utterance multi-functionality to be captured.\nTo help with challenge 2, we use a statistical utterance boundary detector.\nTo handle challenges 3 and 4, we developed a unique parsing framework in\nwhich metarules specify allowable forms of phrase breakage and interleaving.\nA stream of words tagged with their speakers are given to the parser.\nSecond speaker continuations are naturally allowed and metarules allow\nphrase structure to be formed around second speaker interruptions.\nSimilarly, metarules allow phrase structure to be formed around\nspeech repairs and editing terms. The parser can thus include repairs\nand editing terms in its output, allowing higher-level reasoning processes\nto make inferences about hesitations and false starts in the input.\nWe have also shown that the parser can use its knowledge of grammar\nand the syntactic structure of the input to improve pre-parser\nspeech repair identification.""",0
"b'Recent systems for semantic role labeling are very dependent on the\nspecific predicates and corpora on which they are trained, but\nlabeling new data is expensive. We study which features and \nclassifiers are best able to generalize to unseen predicates from new\nsemantic frames. We find that automatically derived cluster\ninformation is especially helpful in this setting, and that a relatively \nsimple a posteriori classifier outperforms Maximum Entropy.'",0
"b'The usefulness of accurate sequence information is re-evaluated in this\npaper. A novel idea, called phonetic set hashing, of transforming\nphone sequences to words is then suggested. Phone sequences are mapped\nonto the corresponding phone sets, and the latter used as keys for\nindexing appropriate words. By using data-driven training strategies,\nthe problem of word segmentation has been alleviated. The robustness of\nphone set hashing towards insertion, deletion, and substitution errors has\nalso been studied. Experiments with subsets of the TIMIT database indicate\nthat phone set hashing is a simple, fast scheme for word pre-selection.'",0
"b'Many electoral bribery, control, and manipulation problems (which\nwe will refer to in general as ""manipulative actions"" problems) are\nNP-hard in the general case.  It has recently been noted that many\nof these problems fall into polynomial time if the electorate is\nsingle-peaked (i.e., is polarized along some axis/issue).  However,\nreal-world electorates are not truly single-peaked.  There are\nusually some mavericks, and so real-world electorates tend to merely\nbe nearly single-peaked.  This paper studies the complexity of\nmanipulative-action algorithms for elections over nearly\nsingle-peaked electorates, for various notions of nearness and\nvarious election systems.  We provide instances where even one\nmaverick jumps the manipulative-action complexity up to $\\np$-hardness,\nbut we also provide many instances where a reasonable number\nof mavericks can be tolerated without increasing the\nmanipulative-action complexity.'",3
"b""Visual cognition depends critically on the\nmoment-to-moment orientation of gaze. Gaze is changed by \nsaccades, rapid eye movements that orient the fovea over targets\nof interest in a visual scene.  Saccades are ballistic; a\nprespecified target location is computed prior to the movement and\nvisual feedback is precluded.  Once a target is fixated, gaze is\ntypically held for about 300 milliseconds, although it can be held\nfor both longer and shorter intervals. Despite these distinctive\nproperties, there has been no specific computational model of the\ngaze targeting strategy employed by the human visual system during\nvisual cognitive tasks.  This paper proposes such a model that uses\niconic scene representations derived from oriented spatiochromatic\nfilters at multiple scales. Visual search for a target object\nproceeds in a coarse-to-fine fashion with the target's largest scale\nfilter responses being compared first. Task-relevant target\nlocations are represented as saliency maps which are used to program\neye movements. Once fixated, targets are remembered by using spatial\nmemory in the form of object-centered maps.  The model was\nempirically tested by comparing its performance with actual eye\nmovement data from human subjects in natural visual search tasks.\nExperimental results indicate excellent agreement between eye\nmovements predicted by the model and those recorded from human subjects.""",1
"b'This thesis describes an implemented technique for resolving\nanaphoric pronouns referring to both individual and abstract entities.\nThe model defines rules for evoking high-order entities from discourse\nand also a pronoun resolution method that is appropriate for both\ndemonstrative and personal pronouns.  It correctly interprets 72% of\nthe pronouns, while a previous leading technique is correct on only 37%,\nwhen tested on a corpus of task-oriented spoken dialog.'",0
"b""This report is a user's manual for the TRAINS-95 parsing system.\nAn accompanying report describes the grammar used in TRAINS-95, and the\nrobust speech act interpretation system, which takes the chart and\nproduces a series of speech acts that best characterize it. The parser is\nbased on the bottom-up parser described in Natural Language Understanding,\nSecond Ed. (Allen, 1994, Chapters 3, 4, and 5). It uses the same formats\nfor the grammar and the lexical entries, and the same basic bottom-up\nalgorithm. There are a number of extensions beyond the basic system\ndescribed in the book, each of which will be discussed in this report,\nincluding: (1) support for parsing word lattices; (2) best-first parsing\nusing context-free probabilistic rules; (3) incremental (word by word)\nparser with backup for corrections; (4) hierarchical feature values and\nextended unification options; (5) a hierarchical lexicon entry format\nthat simplifies defining large lexicons; and (6) procedural attachment\nto chart actions.""",0
"b'We propose a 3-D object reconstruction method using a\nstationary camera and a planar mirror. No calibration is required.\nThe mirror provides the extra views needed for a multiple-view\nreconstruction. We examine the imaging geometry of the camera-mirror\nsetup and prove a theorem that gives us the point correspondences\nto compute the orientation of the mirror. The correspondences are\nderived from the convex hull of the silhouettes of the images of\nthe object and its mirror reflection. The distance between the mirror\nand the camera can be then obtained by a single object point and a pair of\npoints on the mirror surface. After the pose of the mirror is determined,\nwe have multiple calibrated views of the object. We show two\nreconstruction methods that utilize the special imaging geometry.\nThe system setup is simple. The algorithm is fast and easy to implement.'",1
"b'This paper examines the nature of visual representations\nthat direct ongoing performance in sensorimotor tasks.\nPerformance of such natural tasks requires relating visual information\nfrom different gaze positions. To explore this we used the technique of\nmaking task relevant display changes during saccadic eye movements.\nSubjects copied a pattern of colored blocks on a computer monitor,\nusing the mouse to drag the blocks across the screen.\nEye position was monitored using a dual-purkinje eye tracker,\nand the color of blocks in the pattern was changed at different points\nin task performance. When the target of the saccade changed color during\nthe saccade, the duration of fixations on the model pattern increased,\ndepending on the point in the task that the change was made.\nThus different fixations on the same visual stimulus served a\ndifferent purpose. The results also indicated that the visual information\nthat is retained across successive fixations depends on\nmoment by moment task demands. This is consistent with\nprevious suggestions that visual representations are limited\nand task dependent. Changes in blocks in addition to the saccade target\nled to greater increases in fixation duration. This indicated that\nsome global aspect of the pattern was retained across different fixations.\nFixation durations revealed effects of the display changes\nthat were not revealed in perceptual report. This can be understood\nby distinguishing between processes that operate at different levels\nof description and different time scales. Our conscious experience\nof the world may reflect events over a longer time scale than those\nunderlying the substructure of the perceptuo-motor machinery.'",0
"b'This report contains a small corpus of transcriptions of task oriented\nspoken conversations in the TRAINS domain. Included are 16 conversations,\namounting to over 80 minutes of speech. Also included are a description\nof the task and collection situation and the conventions used in\ntranscription and utterance segmentation.'",0
"b""We investigate issues related to two hard problems related to voting,\nthe optimal weighted lobbying problem and the winner problem for\nDodgson elections.  Regarding the former, Christian et al. [CFRS06]\nshowed that optimal lobbying is intractable in the sense of\nparameterized complexity.  We provide an efficient greedy algorithm\nthat achieves a logarithmic approximation ratio for this problem and\neven for a more general variant---optimal weighted lobbying.  We prove\nthat essentially no better approximation ratio than ours can be proven\nfor this greedy algorithm.\n\nThe problem of determining Dodgson winners is known to be complete for\nparallel access to NP [HHR97].  Homan and Hemaspaandra [HH06] proposed\nan efficient greedy heuristic for finding Dodgson winners with a\nguaranteed frequency of success, and their heuristic is a ``frequently\nself-knowingly correct algorithm.''  We prove that every\ndistributional problem solvable in polynomial time on the average with\nrespect to the uniform distribution has a frequently self-knowingly\ncorrect polynomial-time algorithm.  Furthermore, we study some\nfeatures of probability weight of correctness with respect to\nProcaccia and Rosenschein's junta distributions [PR07].""",3
"b'The current state of the art seems to favour blocking software\ntransactional memory (STM) implementations over nonblocking ones, and\na common belief is that nonblocking STMs fundamentally cannot be made\nto perform as well as blocking ones.  But this belief is based on\nexperience, intuition, and anecdote, not on rigorous analysis.\n\nWe believe there is still plenty of room for improvement in the\nperformance of nonblocking STMs and that, regardless of performance,\nblocking is unacceptable in some contexts.  It is therefore important\nto continue improving nonblocking STMs, both as a goal in its own\nright, as well as to inform research aimed at determining whether a\nfundamental gap exists between blocking and nonblocking STMs.\n\nWe describe a novel nonblocking copyback mechanism for a word-based\nsoftware transactional memory (STM), which closely follows simple and\nefficient blocking mechanisms in the common case.  Previous\nnonblocking copyback mechanisms impose significant overhead on the\ncommon case.  Our performance experiments show that this approach\nyields significant performance improvement over the previous best\nnonblocking word-based STM.  Our design approach can be applied to\nsome other blocking STMs to achieve nonblocking counterparts that\nperform similarly in the common case.'",2
"b""This paper presents an integrated approach to build an affect \nlexicon for emotion tagging of free text.  The primary linguistic\nresource for this lexicon includes electronic dictionaries,\non-line word association norms and a large scale commonsense corpus.\nOur main goal is to automatically collect frequently used affect words\nand phrases and also assess their emotion intensity. \nMultiple natural language processing techniques, like POS\ntagging, parsing, phrase chunking, constituent identification, are\nemployed.  We show examples of affect assessment by using this\nlexicon as well as syntactic processing.  Our\nsystem gives out plausible emotion analysis for test text.\nPotential applications includes building emotional virtual agents,\nestimating user's attitude, and assisting information retrieval.""",0
"b'Scene classification, the automatic categorization of images into semantic\nclasses such as beach, field, or party, is useful in applications such as\ncontent-based image organization and context-sensitive digital\nenhancement. Most current scene-classification systems use low-level\nfeatures and pattern recognition techniques; they achieve some success on\nlimited domains.\n\nSeveral contemporary classifiers, including some developed in Rochester,\nincorporate semantic material and object detectors. Classification\nperformance improves because because the gap between the features and the\nimage semantics is narrowed. We propose that spatial relationships between\nthe objects or materials can help by distinguishing between certain types\nof scenes and by mitigating the effects of detector failures. While past\nwork on spatial modeling has used logic- or rule-based models, we propose\na probabilistic framework to handle the loose spatial relationships that\nexist in many scene types.\n\nTo this end, we have developed MASSES, an experimental testbed that can\ngenerate virtual scenes. MASSES can be used to experiment with different\nspatial models, different detector characteristics, and different learning\nparameters. Using a tree-structured Bayesian network for inference on a\nseries of simulated natural scenes, we have shown that the presence of key\nspatial relationships are needed to disambiguate other types of scenes,\nachieving a gain of 7% in one case.\n\nHowever, our simple Bayes net is not expressive enough to model the faulty\ndetection at the level of individual regions. As future work, we propose\nfirst to evaluate full (DAG) Bayesian networks and Markov Random Fields as\npotential probabilistic frameworks. We then plan to extend the chosen\nframework for our problem. Finally, we will compare our results on real\nand simulated sets of images with those obtained by other systems using\nspatial features represented implicitly.'",1
"b'WordNet is a lexical database that, among other things, arranges\nEnglish nouns into a hierarchy ranked by specificity, providing\nlinks between a more general word and words that are specializations\nof it.  For example, the word ""mammal"" is linked (transitively via\nsome intervening words) to ""dog"" and to ""cat.""  This hierarchy\nbears some resemblance to the hierarchies of types (or properties,\nor predicates) often used in artificial intelligence systems.\nHowever, WordNet was not designed for such uses, and is organized in\na way that makes it far from ideal for them.  This report describes\nour attempts to arrive at a quantitative measure of the quality of\nthe information that can be extracted from WordNet by interpreting\nit as a formal taxonomy, and to design automatic techniques for improving\nthe quality by filtering out dubious assertions.'",0
"b'Object recognition from a single view fails when the available\nfeatures are not sufficient to determine the identity of a single object,\neither because of similarity with another object or because of feature\ncorruption due to clutter and occlusion. Active object recognition systems\nhave addressed this problem successfully, but they require complicated\nsystems with adjustable viewpoints that are not always available.\nIn this paper we investigate the performance gain available by combining\nthe results of a single view object recognition system applied to imagery\nobtained from multiple fixed cameras.  In particular, we address\nperformance in cluttered scenes with varying degrees of information\nabout relative camera pose.  We argue that a property common to many\nrecognition systems, which we term a weak target error, is responsible\nfor two interesting limitations of multi-view performance enhancement:\nthe lack of significant improvement in systems whose single-view\nperformance is weak, and the plateauing of performance improvement\nas additional multi-view constraints are added.'",1
"b'We present the Bitwise Bloom Filter, a data structure for\nmaintaining counts for a large number of items. The bitwise filter is\nan extension of the Bloom filter, a space-efficient data structure\nfor storing a large set efficiently by discarding the identity of the\nitems being held while still being able to determine whether it is in\nthe set or not with high probability. We show how this idea can be\nextended to maintaining counts of items by maintaining a separate\nBloom filter for every position in the bit representations of all the\ncounts. We give both theoretical analysis of the accuracy of the\nBitwise filter together with validation via experiments on real\nnetwork data.'",3
"b""Gait recognition is an important research problem in the field of\ncomputer vision. The goal is to identify people by analysis of gait\npatterns. Because the technique can be performed remotely, it has\nbeen applied to access control, surveillance, etc.\nMost research is based on the assumption that people's walking\ndirection is perpendicular to the camera axis. In this case the\nsilhouette can be extracted to identify individuals. This limits\nthe application and development of gait recognition. Consequently,\nwalking direction has recently become a popular and challenging\nresearch problem.\nAn improved gait recognition approach is proposed. It can give\nhigh recognition rates in cases where people's walking direction\nis not perpendicular to the camera axis. We describe a novel\napproach to walking direction computation using information about\ncamera position. The walking direction angle and camera affine\nprojection model are used to define features that can be related\nto a kinematic model of a human being. Support Vector Machine is\nused for classification and to evaluate the power of the approach.\nWe apply our method to real human walking image sequences, and\nachieve relatively high recognition rates. Our approach\nillustrates how changes in walking direction affect gait\nparameters in terms of recognition performance. We show that the\nuse of the walking direction algorithm improves recognition rates\nunder variation in viewing direction.""",1
"b""Problems for strict and convex Bayesianism are discussed.\nA set-based Bayesianism generalizing convex Bayesianism \nand intervalism is proposed. This approach abandons not only the strict\nBayesian requirement of a unique real-valued probability function \nin any decision-making context but also the requirement of convexity \nfor a set-based representation of uncertainty. \nLevi's E-admissibility decision criterion is retained \nand is shown to be applicable in the non-convex case.""",0
"b""In this paper we review and compare several techniques for model-based\npose recovery (extrinsic camera calibration) from monocular images. We\nclassify the solutions reported in the literature as analytical\nperspective, affine and numerical perspective. We also present\nreformulations for two of the most important numerical perspective\nsolutions: Lowe's algorithm and Phong-Horaud's algorithm. Our\nimprovement to Lowe's algorithm consists of eliminating some\nsimplifying assumptions on its projective equations. A careful\nexperimental evaluation reveals that the resulting fully projective\nalgorithm has superexponential convergence properties for a wide range\nof initial solutions and, under realistic usage conditions, it is up to\nan order of magnitude more accurate than the original formulation, with\narguably better computation-time properties. Our extension to\nPhong-Horaud's algorithm is, to the best of our knowledge, the first\nmethod for independent orientation recovery that actually exploits the\ntheoretical advantages of point correspondences over line correspondences.\nWe show that in the context of a specific real-life application (visual\nnavigation), it is either more accurate than other similar techniques\nwith the same computational cost, or more efficient with the same accuracy.""",1
"b'Appearance-based object recognition systems rely on training from\nimagery, which allows the recognition of objects without requiring a 3d\ngeometric model.  It has been little explored whether such systems can be\ntrained from imagery that is unlabeled, and whether they can be trained\nfrom imagery that is not trivially segmentable.  In this paper we present\na method for minimally supervised training of a previously developed\nrecognition system from unlabeled and unsegmented imagery.  We show that\nthe system can successfully extend an object representation extracted\nfrom one black background image to contain object features extracted\nfrom unlabeled cluttered images and can use the extended representation\nto improve recognition performance on a test set.'",1
"b'We propose a means of extending Conditional Random Field modeling\nto decision-theoretic planning where valuation is dependent upon\nfully observable factors. Representation is discussed, and a\ncomparison with existing decision problem methodologies is presented.\nIncluded are exact and inexact message passing schemes for policy\nmaking, examples of decision making in practice, extensions to\nsolving general decision problems, and suggestions for future use.'",1
"b'The data layout of a program is critical to performance because it\ndetermines the spatial locality of the data access.  Most\nquantitative notions of spatial locality are based on the overall\nmiss rate and leave three questions not fully answered: how much can\nthe locality of a given data layout be improved, can a data layout\nbe improved if the miss rate cannot be lowered, and can the overall\nspatial locality be decomposed into smaller components?  This paper\ndescribes a new definition of spatial locality that addresses these\nquestions. The model is based on off-line profiling of a sequential\nexecution. It has been used to analyze the spatial locality of 14\nSPEC2000 benchmarks.'",2
"b'We propose and implement a novel method for visual space\ntrajectory planning, and adaptive high degree-of-freedom (DOF) visual\nfeedback control. The method requires no prior information either about the\nkinematics of the manipulator, or the placement or calibration of the\ncameras, and imposes no limitations on the number of degrees of freedom\ncontrolled or the number of kind of visual features utilized.\nThe approach provides not only a means of low-level servoing\nbut a means to integrate it with higher level visual space trajectory\nand task planning. We are thus able to specify and perform complex tasks\ncomposed of several primitive behaviors, using both visual servoing\nand open loop control, where the number of sensed and controlled signals\nvaries during the task. We report experimental results demonstrating\na factor of 5 improvement in the repeatability of manipulations\nusing a PUMA arm when comparing visual closed-loop to traditional\njoint level servoing. We also present experiment statistics showing\nthe advantages of adaptive over non-adaptive control systems, and of\nusing redundant visual information when performing manipulation tasks.\nFinally, we demonstrate usefulness of the approach by using it to specify\nand execute complex tasks involving real-world robot manipulation of rigid\nand non-rigid objects in up to 12 degrees of freedom. The manipulation\nis performed in the context of a semi-autonomous robot manipulation system.'",1
"b""Rhetorical (Rhet) is a programming / knowledge representation system\nthat offers a set of tools for building automated reasoning systems.\nIts emphasis is on flexibility of representation, allowing the user to\ndecide if the system will basically operate as a theorem prover, a\nframe-like system, or an associative network. Rhet may be used as the\nback-end to a user's programming system and handle the knowledge represen-\ntation chores, or it may be used as a full-blown programming language.\n\nRhet offers two major modes of inference: a horn clause theorem prover\n(backwards chaining mechanism) and a forward chaining mechanism. Both\nmodes use a common representation of facts, namely horn clauses with\nuniversally quantified, potentially type restricted, variables, and use\nthe unification algorithm. Additionally, they both share the following\nadditional specialized reasoning capabilities: (1) variables may be typed\nwith a fairly general type theory that allows a limited calculus of types\nincluding intersection and subtraction; (2) full reasoning about equality\nbetween ground terms; (3) reasoning within a context space, with access\nto axioms and terms in parent contexts; (4) escapes into Lisp for use as\nnecessary.""",0
"b""RPRS is a hierarchical plan recognition system built within the\nRHET knowledge representation system. It provides a powerful system for\nplan recognition based on the algorithms of Kautz, with the general\nreasoning capabilities of RHET. RPRS takes special advantage of Rhet's\ntype relations, constraints, equality, and contextual reasoning abilities.\n\nRPRS is also intended as a demonstration of the Rhet programming\nand knowledge representation system's hybrid reasoning capabilities.\nUtilizing the lisp interface to Rhet, RPRS allows the user to use\nthe Rhet structured type system to build plan types, and given some\nobservation or set of observations have Rhet derive the set of plans\nthat are consistent with these observations. Since RPRS includes the\nTEMPOS specialized reasoner for Rhet, steps and observations can have\nreference to time-intervals, and/or be temporally constrained with\nrespect to one another.""",0
"b'We present a representation of events and action based on interval\ntemporal logic that is significantly more expressive and more\nnatural than most previous AI approaches. The representation is\nmotivated by work in natural language semantics and discourse,\ntemporal logic, and AI planning and plan recognition. The formal\nbasis of the representation is presented in detail, from the\naxiomatization of time periods to the relationship between actions\nand events and their effects. The power of the representation is\nillustrated by applying it to the axiomatization and solution of\nseveral standard problems from the AI literature on action and\nchange.  An approach to the frame problem based on explanation\nclosure is shown to be both powerful and natural when combined with\nour representational framework. We also discuss features of the\nlogic that are beyond the scope of many traditional representations,\nand describe our approach to difficult problems such as external\nevents and simultaneous actions.'",0
"b""After abandoning an attempt to build our own gasoline-powered\nautomated outdoor vehicle in 1995, we purchased two M68332-controlled\nwheelchairs for indoor and outdoor mobile robotics research.\nMuch of the first year has been spent on various infrastructure projects,\nseveral of which are described here. At this writing we are beginning\nto be in a position to do nontrivial applications and research\nusing these platforms. This compendium of facts and experiences is meant\nto be useful in getting to know the organization and capabilities\nof our mobile robots. We first cover the basic hardware and the\nserial protocol used to communicate between the main computing engine\nand the microcontroller responsible for sensor management, motor control,\nand low-level sensori-motor control loops. We describe the interface\nto the video digitizer, a low-level obstacle avoidance routine, and\na general software organization for a control architecture based on\nvideo streams. Dynamic nonholonomic models and a virtual environment\nfor debugging and experimenting with them are described next, followed up\nby a visual servoing application that uses ``engineered vision'' and\nspecial assumptions.""",1
"b""Rabi and Sherman [RS97,RS93] proved that the hardness of factoring\nis a sufficient condition for there to exist one-way functions (i.e.,\np-time computable, honest, p-time noninvertible functions; this paper is in\nthe worst-case model, not the average-case model) that are total,\ncommutative, and associative but not strongly noninvertible.  In this paper we\nimprove the sufficient condition to ``P does not equal NP.''\n\nMore generally, in this paper we completely characterize which types\nof one-way functions stand or fall together with (plain) one-way\nfunctions---equivalently, stand or fall together with P not equaling\nNP. We look at the four attributes used in Rabi and Sherman's seminal work\non algebraic properties of one-way functions (see [RS97,RS93]) and\nsubsequent papers---strongness (of noninvertibility), totality, commutativity,\nand associativity---and for each attribute, we allow it to be required to\nhold, required to fail, or ``don't care.'' In this categorization\nthere are 3^4 = 81 potential types of one-way functions.  We prove that each\nof these 81 feature-laden types stand or fall together with the existence\nof (plain) one-way functions.""",3
"b'Given a function based on the computation of an NP machine, can one in\ngeneral eliminate some solutions?  That is, can one in general\ndecrease the ambiguity?  This simple question remains, even after\nextensive study by many researchers over many years, mostly\nunanswered.  However, complexity-theoretic consequences and enabling\nconditions are known.  In this tutorial-style article we look at some\nof those, focusing on the most natural framings: reducing the number\nof solutions of NP functions, refining the solutions of NP functions,\nand subtracting from or otherwise shrinking #P functions.  We will see\nhow small advice strings are important here, but we also will see how\nincreasing advice size to achieve robustness is central to the proof\nof a key ambiguity-reduction result for NP functions.'",3
"b""We combine scene-space based methods with Bayesian modeling for\nrecovering the geometric (3d shape, appearance) and dynamic (motion,\ndeformation) properties of real-world scenes from noisy images.\nBayesian modeling in scene space helps establish a direct mathematical\nrelationship between the uncertainty in estimating scene properties\n(e.g., 3d shape and motion) and the uncertainty due to noise and errors\nin image measurements. This leads to algorithms that optimally recover\n3d scene properties directly from image intensities. We apply this\napproach to two specific problems.\n\nThe first problem we study is inferring 3d shape from a set of noisy images.\nWe derive a general probabilistic theory of occupancy and emptiness to\nspecify what one can infer about 3d shape for arbitrarily-shaped,\nLambertain scenes and arbitary viewpoint configurations. By modeling\nthe problem in scene space, we formalize the notions of visibility,\noccupancy, emptiness, and photo-consistency, leading to the Photo Hull\nDistribution, the tightest probabilistic bound on the scene's true shape\nthat is theoretically computable from the input images. We show how to\nexpress this distribution directly in terms of image measurements and\nrepresent it compactly by assigning an occupancy probability at every 3d\npoint.  We provide a stochastic algorithm that draws fair samples from\nthe Photo Hull Distribution and converges to an optiaml conservative\nestimate of the occupancy probability.  We present experimental\nresults for real, complex scenes.\n\nThe second problem we study is recovering nonrigid motion of deformable\nsurfaces from noisy video.  We develop linear methods for model-based\ntracking of nonrigid 3d objects in video. Uncertainty in image\nmeasurements is quantified and propagated through the inverse model\nto yield optimal 3d pose and deformation estimates directly from 2d\nimage intensities.  We obtain accurate and optimal closed-form\nnonrigid motion estimators by minimizing information loss from\nnon-reversible operations.  We demonstrate results with 3d nonrigid\ntracking, model refinement, and super-resolution texture lifting from\nlow-quality, low-resolution video.""",1
"b'We note that for each k \\in {0,1,2, ...} the following holds: NE\nhas (nonuniform) ACC^k circuits if and only if NE has P^{NE}-uniform\nACC^k circuits.  And we mention how to get analogous results for\nother circuit and complexity classes'",3
"b'In this paper we consider the problem of computing the 3D shape\nof an unknown, arbitrarily-shaped scene from multiple color photographs\ntaken at known but arbitrarily-distributed viewpoints. By studying the\nequivalence class of all 3D shapes that reproduce the input photographs,\nwe prove the existence of a special member of this class, the maximal\nphoto-consistent shape, that (1) can be computed from an arbitrary volume\nthat contains the scene, and (2) subsumes all other members of this class.\nWe then give a provably-correct algorithm, called Space Carving, for\ncomputing this shape and present experimental results from applying it to\nthe reconstruction of geometrically-complex scenes from several photographs.\nThe approach is specifically designed to (1) build 3D shapes that allow\nfaithful reproduction of all input photographs, (2) resolve the complex\ninteractions between occlusion, parallax, shading, and their effects on\narbitrary collections of photographs of a scene, and (3) follow a\n""least commitment"" approach to 3D shape recovery.'",1
"b'We show that by inferring parameter domains of planning operators,\ngiven the definitions of the operators and the initial and goal conditions,\nwe can often speed up the planning process by an order of magnitude or more.\nWe infer parameter domains by a polynomial-time algorithm that uses\nforward propagation of sets of constants occurring in the initial conditions\nand in operator postconditions. During planning, parameter domains can be\nused to prune operator instances whose parameter domains are inconsistent\nwith binding constraints, and to eliminate spurious ""clobbering threats""\nthat cannot, in fact, be realized without violating domain constraints.\nWe illustrate these applications with examples from the UCPOP test suite\nand from the Rochester TRAINS transportation planning domain.'",0
"b'Recent neurophysiological experiments appear to indicate that the\nresponses of visual cortical neurons in a monkey freely viewing a\nnatural scene can sometimes differ substantially from those obtained when\nthe same image subregions are flashed during a conventional fixation task.\nThese new findings attain significance from the fact that\nneurophysiological research in the past has been based predominantly\non cell recordings obtained during fixation tasks, under the\nassumption that these data would be useful in predicting responses\nin more general situations. We describe a hierarchical model of\nvisual memory that reconciles the two differing experimental results\nmentioned above by predicting neural responses in both\nfixating and free-viewing conditions.\nThe model dynamically combines input-driven bottom-up\nsignals with expectation-driven top-down signals to achieve optimal\nestimation of current state using a Kalman filter based framework.\nThe architecture of the model posits a role for the reciprocal\nconnections between adjoining visual cortical areas\nin determining neural response properties.'",1
"b'The use of multi-core, multi-processor machines is opening new\nopportunities for software speculation, where program code is\nspeculatively executed to improve performance at the additional cost\nof monitoring and error recovery. In this paper we describe\na new system that uses software speculation to support unsafely\noptimized code. We open a fast, unsafe track of execution but\nrun the correct code on other processors to ensure correctness.\nWe have developed an analytical model to measure the effect of\nmajor parameters including the speed of the fast track, its\nsuccess rate, and its overheads. We have implemented a prototype\nand verified the correctness and performance using a\nsynthetic benchmark on a 4-CPU machine.'",2
"b""This dissertation describes the formal foundations and implementation\nof a commonsense, mixed-initiative plan reasoning system. By ``plan\nreasoning'' I mean the complete range of cognitive tasks that people\nperform with plans including, for example, plan construction\n(planning), plan recognition, plan evaluation and comparison, and plan\nrepair (replanning), among other things.  ``Mixed-initiative'' means\nthat several participants can each make contributions to the plan\nunder development through some form of communication.  ``Commonsense''\nmeans that the system represents plans and their constituents at a\nlevel that is ``natural'' to us in the sense that they can be\ndescribed and discussed in language. In addition, the reasoning that\nthe system performs includes those conclusions that we would take to\nbe sanctioned by common sense, including especially those conclusions\nthat are defeasible given additional knowledge or time spent reasoning.\n\nThe main theses of this dissertation are the following:\n(1) Any representation of plans sufficient for commonsense plan\n  reasoning must be based on an expressive and natural representation\n  of such underlying phenomena as time, properties, events, and\n  actions.\n(2) For mixed-initiative planning, plans should be viewed as\n  arguments that a certain course of action under certain conditions\n  will achieve certain goals.\nThese theses are defended by presenting, first, a representation of\nevents and actions based on interval temporal logic and, second, a\nrepresentation of plans as arguments in a formal system of defeasible\nreasoning that explicitly constructs arguments.  These two aspects of\ncommonsense plan reasoning are combined and implemented in the TRAINS\ndomain plan reasoner, which is also described in detail.\n\nThe emphasis in this dissertation is on breadth, taking as its data\nhuman communicative and plan reasoning abilities and developing\nformalisms that characterize these abilities and systems that\napproximate them.  I therefore draw on literature from a broad range\nof disciplines in the development of these ideas, including:\nphilosophy of language, linguistics and AI work on knowledge\nrepresentation for the representation of events and actions,\nphilosophical logic and AI work on nonmonotonic reasoning for\nrepresenting defeasible knowledge and reasoning about it, and, of\ncourse, AI work on planning and plan recognition itself.""",0
"b'This paper studies the notions of autoreducibility and\nlength-decreasing self-reducibility of\nfunctions and languages. Recently Glasser et al. have shown\nthat for many classes C,\nincluding PSPACE and NP, it holds that all nontrivial\ncomplete languages are polynomial-time\nmany-one autoreducible. In contrast, this paper shows that\nfor many classes C such that P is a\nsubset of C (e.g., PSPACE and NP) some complete languages\nin C are not polynomial-time\nlength-decreasing self-reducible unless C is a subset of P\nand for classes C such that  L is a\nsubset of C and C is a subset of P (e.g., P and NL)\nsome complete languages in C are not\nlogarithmic-space length-decreasing self-reducible\nunless C is a subset of L.\n\nThis paper also shows that contrast between autoreducibility\nand length-decreasing self-reducibility\nfor the case of functions. In particular, the paper shows that\nmany function complexity classes FC\n(including well-studied #P, SpanP, and GapP and not-so-well-studied\nbut highly natural #PE and\nTotP) have the property that all complete functions in FC\nare polynomial-time Turing-autoreducible.\nFor #P and TotP, the autoreductions can be made to be\npolynomial-time one-Turing (one query per input).\n\nThese results show that, under reasonable assumptions, the notions of\nlength-decreasing self-reducibility\nand autoreducibility differ both on complete languages and on\ncomplete functions. In a similar vein,\nthis paper shows that under reasonable assumptions autoreducibility\nand random-self-reducibility differ with respect to functions.'",3
"b""The centering framework explains local discourse coherence\nby relating a speaker's focus of attention and the forms of referring\nexpressions.  Although this framework has proven useful in single-speaker\ndiscourse, its utility for multi-party discourse has not been shown.\nIt is unclear how to adapt it to handle discourse phenomena such as\nturn-taking, acknowledgments, first and second person pronouns, and\ndisfluencies. This paper reports our experiments applying three naive\nmodels of centering theory for dialog. These results will be used as a\nbaseline for future, more sophisticated models.""",0
"b'We propose a wide-ranging knowledge representation formalism\ndesigned expressly to support many different forms of reasoning about plans.\nWe begin with an event-based language based on the interval\ntemporal logic. The language supports reasoning about action attempts\nand composite actions, both of which are given axiomatic definitions.\nWe then define a representation for plans viewed as arguments\nthat a certain course of action under certain explicit conditions\nwill achieve certain goals. We can represent both correct\nand incorrect plans, and reason about why they might or might not fail.\nAn important aspect of this work is the formal characterization of plan\nreasoning as assumption-based reasoning, to make the non-deductive aspects\nof plan reasoning explicit. A preliminary implementation of these ideas\nhas already been built as the plan reasoning component of the TRAINS system.'",0
"b'We study the dynamics of visual cue integration in a\ntracking / identification task, where subjects track a target object\namong distractors and identify the target after an occlusion.\nObjects are defined by three different attributes (color, shape, size)\nwhich change randomly within a singe trial. When the attributes differ\nin their reliability (two change frequently, one is stable) our results\nshow that subjects rapidly re-weight the different cues, putting more\nemphasis on the stable cue. The re-weighting takes place in less than one\nsecond. Our results suggest that cue integration can exhibit adaptive\nphenomena on a very fast time scale.  We propose a probabilistic model\nwith temporal dynamics that accounts for the observed effect.'",1
"b'In 1992, Bartholdi, Tovey, and Trick\n opened the study of control attacks on elections---attempts to\n improve the election outcome by such actions as adding/deleting\n candidates or voters.  That work has led to many results on how\n algorithms can be used to find attacks on elections and how\n complexity-theoretic hardness results can be used as shields against\n attacks. However, all the work in this line has assumed that the\n attacker employs just a single type of attack.  In this paper, we\n model and study the case in which the attacker launches a\n multipronged (i.e., multimode) attack.  We do so to more\n realistically capture the richness of real-life settings. For\n example, an attacker might simultaneously try to suppress some\n voters, attract new voters into the election, and introduce a\n spoiler candidate. Our model provides a unified framework for such\n varied attacks, and by constructing polynomial-time multiprong\n attack algorithms we prove that for various election systems even\n such concerted, flexible attacks can be perfectly planned in\n deterministic polynomial time.'",3
"b'Virtual reality (VR) provides immersive and\ncontrollable experimental environments. It expands the\nbounds of possible evoked potential (EP) experiments by providing\ncomplex, dynamic environments in order to study cognition without\nsacrificing environmental control. The addition of quick, on-line\nanalysis enables feedback to subjects, making the system we present\nideal for safe Brain Computer Interface (BCI) research. In this\ncontext, we describe an experiment to recognize the\nexistence of P300 EP epochs at red stoplights and the absence\nof this signal at yellow stoplights in a virtual driving\nenvironment. In order to determine the plausibility of single trial\non-line P300 epoch analysis in the artifact ridden driving\nenvironment, we have compared the use of\nIndependent Component Analysis (ICA), a Kalman filter, a robust\nKalman filter, and correlation with the stoplight averages for \nrecognition ability off-line. We report that while all methods perform\nbetter than correlation, the robust Kalman filter gives the highest\nrecognition accuracy, and we discuss future work in this context.'",1
"b'Given a p-order A over a universe of strings (i.e., a transitive,\nreflexive, antisymmetric relation such that if (x, y) is an element of\nA then |x| is polynomially bounded by |y|), an interval size function\nof A returns, for each string x in the universe, the number of strings\nin the interval between strings b(x) and t(x) (with respect to A),\nwhere b(x) and t(x) are functions that are polynomial-time computable\nin the length of x.\n\nBy choosing sets of interval size functions based on feasibility\nrequirements for their underlying p-orders, we obtain new\ncharacterizations of complexity classes. We prove that the set of all\ninterval size functions whose underlying p-orders are polynomial-time\ndecidable is exactly #P.  We show that the interval size functions for\norders with polynomial-time adjacency checks are closely related to\nthe class FPSPACE(poly).  Indeed, FPSPACE(poly) is exactly the class\nof all nonnegative functions that are an interval size function minus\na polynomial-time computable function.\n\nWe study two important functions in relation to interval size\nfunctions.  The function #DIV maps each natural number n to the number\nof nontrivial divisors of n.  We show that #DIV is an interval size\nfunction of a polynomial-time decidable partial p-order with\npolynomial-time adjacency checks.  The function #MONSAT maps each\nmonotone boolean formula F to the number of satisfying assignments of\nF. We show that #MONSAT is an interval size function of a\npolynomial-time decidable total p-order with polynomial-time adjacency\nchecks.\n\nFinally, we explore the related notion of cluster computation.'",3
"b'Human beings have the innate ability to educe meaning from a mass\nof data by discovering and exploiting regularities in it.  Patterns in\nthe world seem to ""jump out"" at us; they seem obvious.  In this paper,\nwe present a system to discover laws in richly structured worlds that is\ninspired by this form of human reasoning. Much previous work in rule\ndiscovery has worked with impoverished domains describable as a list of\n(object, value) pairs. Such representations admit of relatively\nefficient algorithms, but are too poor to describe interesting features\nof the real world and of many logical systems.\n\nWe survey more recent work in the field of relational data mining that\nseeks to extend these algorithms to richer domains. Previous approaches\nto this problem have worked by searching the space of syntactically\ncorrect rule-statements for those that satisfy certain criteria. Their\nsearch is guided by linguistic and declarative bias; they hypothesize\nthe possible rules in some order and then test each one.\n\nWe argue that the space of possible rules is too large to be searched\neffectively in this manner.  We propose an alternative, data-driven\nsearch paradigm, in which the search is guided not by relationships\nbetween the forms of the hypothesized rules, but by correlations in\nthe data they represent.  We argue that such pattern-driven search enables\nthe detection of richer and more powerful hypotheses, including those\ninvolving equality and nested quantification.\n\nWe present a prototype system that incorporates our ideas, and the\nresults obtained when it is applied to the problem of detecting\ninvariants in arbitrary planning worlds. Finally, we discuss ways of\nextending the approach to more realistic domains, and of extending the\ndiscovery process by enabling it to create new concepts as necessary\nto better describe the data.'",0
"b""In this paper we present a kinematic method for 6-degree-of-freedom\nmanipulation of rigid objects using a dextrous robotic hand. Our method\nrequires no prior models of the objects being manipulated; instead\nit obtains all the information needed directly from the hand's sensors.\nIts low computational cost makes real-time performance easy to achieve.\n\nWe present experimental results showing the implementation of our method\nusing the Utah/MIT dextrous hand. We also show that adding a Cartesian\ncontroller significantly improves the accuracy of the manipulation.""",1
"b""When we work with information from multiple sources, the formats of\nthe knowledge bases may not be uniform.  It would be desirable to be\nable to combine a knowledge base of default rules with one containing\nautoepistemic formulas.  Previous works on relating default logic and\nautoepistemic logic mostly impose some constraints on autoepistemic\nlogic, and thus are not suitable for combining the two logics.  We first\npresent a fixed point formulation of autoepistemic logic analogous to\nthat of default logic.  Then we introduce a possible world framework\nwith a partition structure, which corresponds to our intuitive notion\nof accessibility as linking alternate ``possible'' worlds.  We show that\nboth default logic and autoepistemic logic can be characterized using\nthis framework, and the constraints imposed on the possible world\nstructures correspond to the requirements in the fixed point formulations.\nCasting both default logic and autoepistemic logic in a common framework\nis important for developing a semantics applicable to the two logics,\nboth separately and combined.""",0
"b""Natural language generation is a knowledge-intensive, goal-directed\nprocess involving many interacting choices. Some questions that a\ngeneration system must answer include: (1) What information needs to be\nincluded in the output to satisfy the speaker's or writer's communicative\ngoals? (2) How should a discourse contribution be structured to ensure\nits coherence? (3) Which modalities should be used to maximize the\ninformation exchange? (4) How can output be tailored to specific users?\nIn this paper, we examine some aspects of natural language generation that\nconstrain the planning process, including theories of discourse structure,\nmodels of discourse context and of users, and multimodal generation.""",0
"b'This document describes a new pattern matching engine used as\npart of the discourse reasoning components in the TRAINS-96 system.\nIts dominant characteristics are simplicity, efficiency, and\nan economical model for driving the search engine.'",0
"b""Limiting the amount of memory available to a program can hamstring its\nperformance, however in a garbage collected environment allowing too\nlarge of a heap size can also be detrimental. Because garbage collection\nwill occasionally access the entire heap, having a significant amount of\nvirtual memory becomes expensive. Determining the appropriate size for\na program's heap is not only important, but difficult in light of\nvarious virtual machines, operating systems, and levels of\nmulti-programming with which the program may be run.\n\nWe present a model for program memory usage with which we can show\nhow effective  multi-programming is likely to be.\nIn addition, we present an automated system for adding control\nat the program level that allows runtime adaptation of a program's\nheap size. The process is fully automatic and requires no\nextra coding on the part of programmers. \nWe discuss two adaptive schemes: The first acts independently,\nand while performing competitively, the system behaves politely in a\nmulti-programmed environment. The second scheme explicitly\ncooperates when multiple instances are running. Both schemes are\nevaluated in terms of their response time, throughput, and fairness.""",2
"b""We study the robustness---the invariance under definition changes---of\nthe cluster class CL#P [HHKW05].  This class contains each #P function\nthat is computed by a balanced Turing machine whose accepting paths\nalways form a cluster with respect to some length-respecting total\norder with efficient adjacency checks.  The definition of CL#P is\nheavily influenced by the defining paper's focus on (global) orders.\nIn contrast, we define a cluster class, CLU#P, to capture what seems\nto us a more natural model of cluster computing.  We prove that the\nnaturalness is costless: CL#P = CLU#P.  Then we exploit the more\nnatural, flexible features of CLU#P to prove new robustness results\nfor CL#P and to expand what is known about the closure properties of\nCL#P.\n\nThe complexity of recognizing edges---of an ordered collection of\ncomputation paths or of a cluster of accepting computation paths---is\ncentral to this study.  Most particularly, our proofs exploit the\npower of unique discovery of edges---the ability of nondeterministic\nfunctions to, in certain settings, discover on exactly one (in some\ncases, on at most one) computation path a critical piece of\ninformation regarding edges of orderings or clusters.""",3
"b""This tutorial is dedicated to our long-suffering 442 students,\nand to the excellent authors from whom I shamelessly cribbed this work.\nIt is a pure cut-and-paste job from my favorite sources on this material.\nThis is not my own work---think of me as an editor working without his\nauthors' permissions.  Readers should know that original authors are\nusually easier to understand than rehashed versions.  If this presentation\nhelps you, good.  If not it at least helped me sort a few things out.\n\nI assume knowledge of all necessary linear systems theory,\ndifferential equations, statistics, control theory, etc.\nWe start with the ideas of filtering, smoothing, prediction, and state\nestimation.  Wiener filtering and its associated intellectual\nframework follows, with a brief foray into ARMA filtering.  The idea\nof recursive estimation is introduced to give some motivation for the\nslog ahead, and then we start with basic concepts in maximum\nlikelihood, maximum a posteriori, and least-squares estimation.  The\nstrategy is to work toward the Kalman filtering equations by showing\nhow they are simply related to general least-squares estimation.\nAfter Kalman filtering, some simpler versions of recursive filters are\npresented.  There are appendices on the orthogonality principle, the\nmatrix inversion lemma, singular value decomposition, partial C\nand LISP code, and a worked example.""",1
"b'It seems to be a common feeling that animals learn to see, and this\nfeeling, together with the re-emergence of computer learning paradigms\nthat mimic many forms of human learning, has raised hopes that learning\nis the key to the computer vision problem. Indeed, it seems clear that\nNature does not ""program"" all our visual capabilities into the genome,\nand we certainly know that programming a computer with a closed-form\nsolution to the vision problem is a daunting task.\n\nThe aim of this informal and elementary report (basically a term paper)\nis to cast doubt on the idea that biological systems learn to see.\nThe complex process of development, beginning at fertilization and\nending with a mature individual, could be considered to have genetic\n(""nature"") and learning (""nurture"") processes as logical endpoints or\nopposite poles. This report mostly considers what goes on between those\nendpoints, and is meant to raise the possibility that some of the least\nunderstood processes in biology are responsible for visual capabilities.'",0
"b'There has been much research in recent decades aimed at discovering\nwhat the underlying principles are, if any, that drive the brain.\nAs the cortex appears to be basically uniform, it seems that if there is\nan underlying principle, it is ubiquitous.\nHowever, the principles which have been proposed to explain the brain\nhave largely been specialized principles, which each explain\na particular aspect of the brain.\n\nPrinciples such as efficient coding, predictive coding, and temporal\ninvariance have been proposed to explain sensory coding, and have\nsucceeded to some measure in reproducing the receptive field properties\nof neurons in the visual cortex. Bayesian surprise has been offered\nas an explanation of attention, and has enjoyed some success in modeling\nhuman saccades, while reinforcement learning and intelligent adaptive\ncuriosity have been aimed at explaining how actions are chosen.\n\nIn this dissertation we propose a novel principle which we call\npredictive action. It is an information theoretic principle which\nunifies all of the above proposals. We show its relationship to\neach of the above proposals, and give several algorithms which\napproximate predictive action for specific environments. We hope that\nthis principle will allow not only for a greater understanding of\nthe brain, but also serve as a principled basis for the design of future\nalgorithms to solve a broad range of problems in artificial intelligence.'",1
"b'Coarse-grained task parallelism exists in sequential code and can\nbe leveraged to boost the use of chip multi-processors.  However, large\ntasks may execute thousands of lines of code and are often too complex\nto analyze and manage statically.  This report describes a programming\nsystem called \\emph{suggestible parallelization}.  It consists of a\nprogramming interface and a support system.  The interface is a small\nlanguage with three primitives for marking possibly parallel tasks and\ntheir possible dependences.  The support system is implemented in\nsoftware and ensures correct parallel execution through speculative\nparallelization, speculative communication and speculative memory\nallocation.  It manages parallelism dynamically to tolerate unevenness\nin task size, inter-task delay and hardware speed.\nWhen evaluated using four full-size benchmark applications,\nsuggestible parallelization obtains up to a 6 times speedup over 10\nprocessors for sequential legacy applications up to 35 thousand lines\nin size.  The overhead of software speculation is not excessively high\ncompared to unprotected parallel execution.'",2
"b""Reinforcement learning is a machine learning framework in which\nan agent manipulates its environment through a series of actions,\nand in response to each action, receives a reward value. The agent\nstores its knowledge about how to choose reward-maximizing actions in\na mapping from agent-internal states to actions.\n\nAgents often struggle with two opposite, yet intertwined, problems\nregarding their internal state space. First, the agent's state space\nmay have too many distinctions---meaning that an abundance of perceptual\ndata has resulted in a state space so large that it overwhelms the agent's\nlimited resources for computation, storage and learning experience.\nThis problem can often be solved if the agent uses selective perception\nto prune away unnecessary distinctions, and focus its attention only on\ncertain features. Second, even though there are too many distinctions, the\nagent's state space may simultaneously contain too few distinctions---meaning\nthat perceptual limitations (such as field of view, acuity and occlusions),\nhave temporarily hidden crucial features of the environment from the agent.\nThis problem, called hidden state, can often be solved by using memory of\nfeatures from previous views to augment the agent's perceptual inputs.\n\nThis dissertation presents algorithms that use selective perception and\nshort-term memory to simultaneously prune and augment the state space\nprovided by the agent's perceptual inputs. During learning, the agent\nselects task-relevant state distinctions with a utile distinction test\nthat uses robust statistics to determine when a distinction helps the agent\npredict reward. The dissertation also advocates using instance-based\n(or memory-based) learning for making efficient use of accumulated\nexperience, and using a tree structure to hold variable-length memories.\nFour new algorithms are shown to perform a variety of tasks well---in some\ncases with more than an order-of-magnitude better performance than\nprevious algorithms.""",1
"b'Research in Information Extraction has been overly focused on the\nextraction of facts concerning individuals as compared to general knowledge\npertaining to classes of entities and events. In addition, preference has been\ngiven to simple techniques in order to enable high volume throughput.\n\nIn what follows we give examples of existing work in the field of\nknowledge acquisition, then follow with ideas on areas for exploration beyond\nthe current state of the art, specifically with respect to the extraction\nof conditional knowledge, making use of deeper linguistic analysis than\nis currently the norm.'",0
"b'In order to understand natural language, it is necessary to understand\nthe intentions behind it, (i.e., why an utterance was spoken).  We model\ndialogue as collaboration between agents. Communicative intentions\ncan then be seen as how an agent is trying to affect the collaboration.\nMost previous work on intention-recognition approaches to dialogue\nhas focused on only a small subset of agent collaboration paradigms\n(i.e., master-slave), and thus is unable to account for dialogues in\nother paradigms, such as mixed-initiative collaboration.  Previous work\nhas also either modeled dialogues where the agents are only planning\nor dialogues where agents are only acting. This restricts dialogue-model\ncoverage to only those cases and does not model dialogues where collaboration\nabout acting and planning occurs.\n\nIn this paper, we present a collaborative problem-solving model of dialogue.\nThis model is able to account for a much wider array of dialogues than\nprevious models have covered.  It covers the spectrum of collaboration\nparadigms (from master-slave to mixed-initiative) as well as dialogues\nwhere interleaved acting and planning are taking place.\n\nWe propose, for future research, to complete this model and to build a\ndomain-independent intention-recognition system based on it for use\nwithin the TRIPS dialogue system.'",0
"b'To meet the demands of driving in complex environments, the perception\nsubsystem of an intelligent vehicle must be able to extract the information\nneeded for behaviors from the input video stream. An attractive way of\nachieving this is to have a library of basic image processing sub-functions\n(visual routines), which can be composed to subserve more elaborate\ngoal-directed programs. The crucial compositional capability allows the\nvisual routines to span the huge space of different task goals.\n\nThe visual routines presented here are developed in a unique platform.\nThe view from a car driving in a simulated world is fed into a Datacube\npipeline video processor. The integration of photo-realistic simulation and\nreal-time image processing represents a proof of concept for a new system\ndesign that allows testing computer vision algorithms under controllable\nconditions, thus leading to rapid prototyping. In addition to the simulations,\nthe routines are also tested on similar images generated by driving in the\nreal world to assure the generalizability of the simulation.\n\nThe simulator can also be used with human subjects who can drive a kart\nthrough the virtual environment while wearing head mounted displays (HMDs).\nA unique feature of the driving simulator we have built is the ability\nto track eye movements within a freely moving HMD. This allows the assessment\nof exigencies in complex situations that can be used to guide the development\nof automated routines.'",1
